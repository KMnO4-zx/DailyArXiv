# Daily Papers
The project automatically fetches the latest papers from arXiv based on keywords.

The subheadings in the README file represent the search keywords.

Only the most recent articles for each keyword are retained, up to a maximum of 100 papers.

You can click the 'Watch' button to receive daily email notifications.

Last update: 2025-11-14

## Geoscience
| **Title** | **Date** | **KiMi** | **Abstract** | **Comment** |
| --- | --- | --- | --- | --- |
| **[Machine Learning for the Geosciences: Challenges and Opportunities](https://arxiv.org/pdf/1711.04708v1)** | 2017-11-16 | [papers-cool](https://papers.cool/arxiv/1711.04708v1) | <details><summary>Show</summary><p>Geosciences is a field of great societal relevance that requires solutions to several urgent problems facing our humanity and the planet. As geosciences enters the era of big data, machine learning (ML) -- that has been widely successful in commercial domains -- offers immense potential to contribute to problems in geosciences. However, problems in geosciences have several unique challenges that are seldom found in traditional applications, requiring novel problem formulations and methodologies in machine learning. This article introduces researchers in the machine learning (ML) community to these challenges offered by geoscience problems and the opportunities that exist for advancing both machine learning and geosciences. We first highlight typical sources of geoscience data and describe their properties that make it challenging to use traditional machine learning techniques. We then describe some of the common categories of geoscience problems where machine learning can play a role, and discuss some of the existing efforts and promising directions for methodological development in machine learning. We conclude by discussing some of the emerging research themes in machine learning that are applicable across all problems in the geosciences, and the importance of a deep collaboration between machine learning and geosciences for synergistic advancements in both disciplines.</p></details> | <details><summary>Under...</summary><p>Under review at IEEE Transactions on Knowledge and Data Engineering</p></details> |
| **[Coarse-to-fine Task-driven Inpainting for Geoscience Images](https://arxiv.org/pdf/2211.11059v3)** | 2022-12-07 | [papers-cool](https://papers.cool/arxiv/2211.11059v3) | <details><summary>Show</summary><p>The processing and recognition of geoscience images have wide applications. Most of existing researches focus on understanding the high-quality geoscience images by assuming that all the images are clear. However, in many real-world cases, the geoscience images might contain occlusions during the image acquisition. This problem actually implies the image inpainting problem in computer vision and multimedia. To the best of our knowledge, all the existing image inpainting algorithms learn to repair the occluded regions for a better visualization quality, they are excellent for natural images but not good enough for geoscience images by ignoring the geoscience related tasks. This paper aims to repair the occluded regions for a better geoscience task performance with the advanced visualization quality simultaneously, without changing the current deployed deep learning based geoscience models. Because of the complex context of geoscience images, we propose a coarse-to-fine encoder-decoder network with coarse-to-fine adversarial context discriminators to reconstruct the occluded image regions. Due to the limited data of geoscience images, we use a MaskMix based data augmentation method to exploit more information from limited geoscience image data. The experimental results on three public geoscience datasets for remote sensing scene recognition, cross-view geolocation and semantic segmentation tasks respectively show the effectiveness and accuracy of the proposed method.</p></details> |  |
| **[K2: A Foundation Language Model for Geoscience Knowledge Understanding and Utilization](https://arxiv.org/pdf/2306.05064v2)** | 2023-09-15 | [papers-cool](https://papers.cool/arxiv/2306.05064v2) | <details><summary>Show</summary><p>Large language models (LLMs) have achieved great success in general domains of natural language processing. In this paper, we bring LLMs to the realm of geoscience with the objective of advancing research and applications in this field. To this end, we present the first-ever LLM in geoscience, K2, alongside a suite of resources developed to further promote LLM research within geoscience. For instance, we have curated the first geoscience instruction tuning dataset, GeoSignal, which aims to align LLM responses to geoscience-related user queries. Additionally, we have established the first geoscience benchmark, GeoBench, to evaluate LLMs in the context of geoscience. In this work, we experiment with a complete recipe to adapt a pre-trained general-domain LLM to the geoscience domain. Specifically, we further train the LLaMA-7B model on 5.5B tokens of geoscience text corpus, including over 1 million pieces of geoscience literature, and utilize GeoSignal's supervised data to fine-tune the model. Moreover, we share a protocol that can efficiently gather domain-specific data and construct domain-supervised data, even in situations where manpower is scarce. Meanwhile, we equip K2 with the abilities of using tools to be a naive geoscience aide. Experiments conducted on the GeoBench demonstrate the effectiveness of our approach and datasets on geoscience knowledge understanding and utilization.We open-source all the training data and K2 model checkpoints at https://github.com/davendw49/k2.</p></details> |  |
| **[GeoGalactica: A Scientific Large Language Model in Geoscience](https://arxiv.org/pdf/2401.00434v2)** | 2024-04-16 | [papers-cool](https://papers.cool/arxiv/2401.00434v2) | <details><summary>Show</summary><p>Large language models (LLMs) have achieved huge success for their general knowledge and ability to solve a wide spectrum of tasks in natural language processing (NLP). Due to their impressive abilities, LLMs have shed light on potential inter-discipline applications to foster scientific discoveries of a specific domain by using artificial intelligence (AI for science, AI4S). In the meantime, utilizing NLP techniques in geoscience research and practice is wide and convoluted, contributing from knowledge extraction and document classification to question answering and knowledge discovery. In this work, we take the initial step to leverage LLM for science, through a rather straightforward approach. We try to specialize an LLM into geoscience, by further pre-training the model with a vast amount of texts in geoscience, as well as supervised fine-tuning (SFT) the resulting model with our custom collected instruction tuning dataset. These efforts result in a model GeoGalactica consisting of 30 billion parameters. To our best knowledge, it is the largest language model for the geoscience domain. More specifically, GeoGalactica is from further pre-training of Galactica. We train GeoGalactica over a geoscience-related text corpus containing 65 billion tokens, preserving as the largest geoscience-specific text corpus. Then we fine-tune the model with 1 million pairs of instruction-tuning data consisting of questions that demand professional geoscience knowledge to answer. In this technical report, we will illustrate in detail all aspects of GeoGalactica, including data collection, data cleaning, base model selection, pre-training, SFT, and evaluation. We open-source our data curation tools and the checkpoints of GeoGalactica during the first 3/4 of pre-training.</p></details> |  |
| **[High Definition image classification in Geoscience using Machine Learning](https://arxiv.org/pdf/2010.03965v1)** | 2020-10-09 | [papers-cool](https://papers.cool/arxiv/2010.03965v1) | <details><summary>Show</summary><p>High Definition (HD) digital photos taken with drones are widely used in the study of Geoscience. However, blurry images are often taken in collected data, and it takes a lot of time and effort to distinguish clear images from blurry ones. In this work, we apply Machine learning techniques, such as Support Vector Machine (SVM) and Neural Network (NN) to classify HD images in Geoscience as clear and blurry, and therefore automate data cleaning in Geoscience. We compare the results of classification based on features abstracted from several mathematical models. Some of the implementation of our machine learning tool is freely available at: https://github.com/zachgolden/geoai.</p></details> | 8 pages, 14 figures |
| **[Causal Inference in Geosciences with Kernel Sensitivity Maps](https://arxiv.org/pdf/2012.14303v1)** | 2020-12-29 | [papers-cool](https://papers.cool/arxiv/2012.14303v1) | <details><summary>Show</summary><p>Establishing causal relations between random variables from observational data is perhaps the most important challenge in today's Science. In remote sensing and geosciences this is of special relevance to better understand the Earth's system and the complex and elusive interactions between processes. In this paper we explore a framework to derive cause-effect relations from pairs of variables via regression and dependence estimation. We propose to focus on the sensitivity (curvature) of the dependence estimator to account for the asymmetry of the forward and inverse densities of approximation residuals. Results in a large collection of 28 geoscience causal inference problems demonstrate the good capabilities of the method.</p></details> | <details><summary>arXiv...</summary><p>arXiv admin note: substantial text overlap with arXiv:1611.00555, arXiv:2012.05150</p></details> |
| **[70 years of machine learning in geoscience in review](https://arxiv.org/pdf/2006.13311v3)** | 2020-09-30 | [papers-cool](https://papers.cool/arxiv/2006.13311v3) | <details><summary>Show</summary><p>This review gives an overview of the development of machine learning in geoscience. A thorough analysis of the co-developments of machine learning applications throughout the last 70 years relates the recent enthusiasm for machine learning to developments in geoscience. I explore the shift of kriging towards a mainstream machine learning method and the historic application of neural networks in geoscience, following the general trend of machine learning enthusiasm through the decades. Furthermore, this chapter explores the shift from mathematical fundamentals and knowledge in software development towards skills in model validation, applied statistics, and integrated subject matter expertise. The review is interspersed with code examples to complement the theoretical foundations and illustrate model validation and machine learning explainability for science. The scope of this review includes various shallow machine learning methods, e.g. Decision Trees, Random Forests, Support-Vector Machines, and Gaussian Processes, as well as, deep neural networks, including feed-forward neural networks, convolutional neural networks, recurrent neural networks and generative adversarial networks. Regarding geoscience, the review has a bias towards geophysics but aims to strike a balance with geochemistry, geostatistics, and geology, however excludes remote sensing, as this would exceed the scope. In general, I aim to provide context for the recent enthusiasm surrounding deep learning with respect to research, hardware, and software developments that enable successful application of shallow and deep machine learning in all disciplines of Earth science.</p></details> | <details><summary>36 pa...</summary><p>36 pages, 17 figures, book chapter</p></details> |
| **[AI Security for Geoscience and Remote Sensing: Challenges and Future Trends](https://arxiv.org/pdf/2212.09360v2)** | 2023-07-14 | [papers-cool](https://papers.cool/arxiv/2212.09360v2) | <details><summary>Show</summary><p>Recent advances in artificial intelligence (AI) have significantly intensified research in the geoscience and remote sensing (RS) field. AI algorithms, especially deep learning-based ones, have been developed and applied widely to RS data analysis. The successful application of AI covers almost all aspects of Earth observation (EO) missions, from low-level vision tasks like super-resolution, denoising and inpainting, to high-level vision tasks like scene classification, object detection and semantic segmentation. While AI techniques enable researchers to observe and understand the Earth more accurately, the vulnerability and uncertainty of AI models deserve further attention, considering that many geoscience and RS tasks are highly safety-critical. This paper reviews the current development of AI security in the geoscience and RS field, covering the following five important aspects: adversarial attack, backdoor attack, federated learning, uncertainty and explainability. Moreover, the potential opportunities and trends are discussed to provide insights for future research. To the best of the authors' knowledge, this paper is the first attempt to provide a systematic review of AI security-related research in the geoscience and RS community. Available code and datasets are also listed in the paper to move this vibrant field of research forward.</p></details> |  |
| **[Interpretable Geoscience Artificial Intelligence (XGeoS-AI): Application to Demystify Image Recognition](https://arxiv.org/pdf/2311.04940v2)** | 2024-05-08 | [papers-cool](https://papers.cool/arxiv/2311.04940v2) | <details><summary>Show</summary><p>As Earth science enters the era of big data, artificial intelligence (AI) not only offers great potential for solving geoscience problems, but also plays a critical role in accelerating the understanding of the complex, interactive, and multiscale processes of Earth's behavior. As geoscience AI models are progressively utilized for significant predictions in crucial situations, geoscience researchers are increasingly demanding their interpretability and versatility. This study proposes an interpretable geoscience artificial intelligence (XGeoS-AI) framework to unravel the mystery of image recognition in the Earth sciences, and its effectiveness and versatility is demonstrated by taking computed tomography (CT) image recognition as an example. Inspired by the mechanism of human vision, the proposed XGeoS-AI framework generates a threshold value from a local region within the whole image to complete the recognition. Different kinds of artificial intelligence (AI) methods, such as Support Vector Regression (SVR), Multilayer Perceptron (MLP), Convolutional Neural Network (CNN), can be adopted as the AI engines of the proposed XGeoS-AI framework to efficiently complete geoscience image recognition tasks. Experimental results demonstrate that the effectiveness, versatility, and heuristics of the proposed framework have great potential in solving geoscience image recognition problems. Interpretable AI should receive more and more attention in the field of the Earth sciences, which is the key to promoting more rational and wider applications of AI in the field of Earth sciences. In addition, the proposed interpretable framework may be the forerunner of technological innovation in the Earth sciences.</p></details> | <details><summary>there...</summary><p>there are some erros in the results, and a newer revision is still preparing</p></details> |
| **[Is Artificial Intelligence Reshaping the Landscape of the International Academic Community of Geosciences?](https://arxiv.org/pdf/2508.20117v2)** | 2025-09-05 | [papers-cool](https://papers.cool/arxiv/2508.20117v2) | <details><summary>Show</summary><p>Through bibliometric analysis and topic modeling, we find that artificial intelligence (AI) is positively transforming geosciences research, with a notable increase in AI-related scientific output in recent years. We are encouraged to observe that earth scientists from developing countries have gained better visibility in the recent AI for Science (AI4S) paradigm and that AI is also improving the landscape of international collaboration in geoscience-related research.</p></details> | <details><summary>misco...</summary><p>miscommunication in the authorization process from the first author</p></details> |
| **[Data Assimilation in the Geosciences - An overview on methods, issues and perspectives](https://arxiv.org/pdf/1709.02798v3)** | 2018-06-11 | [papers-cool](https://papers.cool/arxiv/1709.02798v3) | <details><summary>Show</summary><p>We commonly refer to state-estimation theory in geosciences as data assimilation. This term encompasses the entire sequence of operations that, starting from the observations of a system, and from additional statistical and dynamical information (such as a dynamical evolution model), provides an estimate of its state. Data assimilation is standard practice in numerical weather prediction, but its application is becoming widespread in many other areas of climate, atmosphere, ocean and environment modeling; in all circumstances where one intends to estimate the state of a large dynamical system based on limited information. While the complexity of data assimilation, and of the methods thereof, stands on its interdisciplinary nature across statistics, dynamical systems and numerical optimization, when applied to geosciences an additional difficulty arises by the continually increasing sophistication of the environmental models. Thus, in spite of data assimilation being nowadays ubiquitous in geosciences, it has so far remained a topic mostly reserved to experts. We aim this overview article at geoscientists with a background in mathematical and physical modeling, who are interested in the rapid development of data assimilation and its growing domains of application in environmental science, but so far have not delved into its conceptual and methodological complexities.</p></details> | <details><summary>79 pa...</summary><p>79 pages, 10 figures, Invited review</p></details> |
| **[When Geoscience Meets Foundation Models: Towards General Geoscience Artificial Intelligence System](https://arxiv.org/pdf/2309.06799v5)** | 2024-11-13 | [papers-cool](https://papers.cool/arxiv/2309.06799v5) | <details><summary>Show</summary><p>Artificial intelligence (AI) has significantly advanced Earth sciences, yet its full potential in to comprehensively modeling Earth's complex dynamics remains unrealized. Geoscience foundation models (GFMs) emerge as a paradigm-shifting solution, integrating extensive cross-disciplinary data to enhance the simulation and understanding of Earth system dynamics. These data-centric AI models extract insights from petabytes of structured and unstructured data, effectively addressing the complexities of Earth systems that traditional models struggle to capture. The unique strengths of GFMs include flexible task specification, diverse input-output capabilities, and multi-modal knowledge representation, enabling analyses that surpass those of individual data sources or traditional AI methods. This review not only highlights the key advantages of GFMs, but also presents essential techniques for their construction, with a focus on transformers, pre-training, and adaptation strategies. Subsequently, we examine recent advancements in GFMs, including large language models, vision models, and vision-language models, particularly emphasizing the potential applications in remote sensing. Additionally, the review concludes with a comprehensive analysis of the challenges and future trends in GFMs, addressing five critical aspects: data integration, model complexity, uncertainty quantification, interdisciplinary collaboration, and concerns related to privacy, trust, and security. This review offers a comprehensive overview of emerging geoscientific research paradigms, emphasizing the untapped opportunities at the intersection of advanced AI techniques and geoscience. It examines major methodologies, showcases advances in large-scale models, and discusses the challenges and prospects that will shape the future landscape of GFMs.</p></details> | <details><summary>accpe...</summary><p>accpeted by IEEE Geoscience and Remote Sensing Magazine</p></details> |
| **[When Geoscience Meets Generative AI and Large Language Models: Foundations, Trends, and Future Challenges](https://arxiv.org/pdf/2402.03349v1)** | 2025-02-18 | [papers-cool](https://papers.cool/arxiv/2402.03349v1) | <details><summary>Show</summary><p>Generative Artificial Intelligence (GAI) represents an emerging field that promises the creation of synthetic data and outputs in different modalities. GAI has recently shown impressive results across a large spectrum of applications ranging from biology, medicine, education, legislation, computer science, and finance. As one strives for enhanced safety, efficiency, and sustainability, generative AI indeed emerges as a key differentiator and promises a paradigm shift in the field. This paper explores the potential applications of generative AI and large language models in geoscience. The recent developments in the field of machine learning and deep learning have enabled the generative model's utility for tackling diverse prediction problems, simulation, and multi-criteria decision-making challenges related to geoscience and Earth system dynamics. This survey discusses several GAI models that have been used in geoscience comprising generative adversarial networks (GANs), physics-informed neural networks (PINNs), and generative pre-trained transformer (GPT)-based structures. These tools have helped the geoscience community in several applications, including (but not limited to) data generation/augmentation, super-resolution, panchromatic sharpening, haze removal, restoration, and land surface changing. Some challenges still remain such as ensuring physical interpretation, nefarious use cases, and trustworthiness. Beyond that, GAI models show promises to the geoscience community, especially with the support to climate change, urban science, atmospheric science, marine science, and planetary science through their extraordinary ability to data-driven modeling and uncertainty quantification.</p></details> |  |
| **[Particle filters for high-dimensional geoscience applications: a review](https://arxiv.org/pdf/1807.10434v2)** | 2019-04-16 | [papers-cool](https://papers.cool/arxiv/1807.10434v2) | <details><summary>Show</summary><p>Particle filters contain the promise of fully nonlinear data assimilation. They have been applied in numerous science areas, but their application to the geosciences has been limited due to their inefficiency in high-dimensional systems in standard settings. However, huge progress has been made, and this limitation is disappearing fast due to recent developments in proposal densities, the use of ideas from (optimal) transportation, the use of localisation and intelligent adaptive resampling strategies. Furthermore, powerful hybrids between particle filters and ensemble Kalman filters and variational methods have been developed. We present a state of the art discussion of present efforts of developing particle filters for highly nonlinear geoscience state-estimation problems with an emphasis on atmospheric and oceanic applications, including many new ideas, derivations, and unifications, highlighting hidden connections, and generating a valuable tool and guide for the community. Initial experiments show that particle filters can be competitive with present-day methods for numerical weather prediction suggesting that they will become mainstream soon.</p></details> | <details><summary>Revie...</summary><p>Review paper, 36 pages, 9 figures, Resubmitted to Q.J.Royal Meteorol. Soc</p></details> |
| **[Physically Interpretable Neural Networks for the Geosciences: Applications to Earth System Variability](https://arxiv.org/pdf/1912.01752v2)** | 2020-10-28 | [papers-cool](https://papers.cool/arxiv/1912.01752v2) | <details><summary>Show</summary><p>Neural networks have become increasingly prevalent within the geosciences, although a common limitation of their usage has been a lack of methods to interpret what the networks learn and how they make decisions. As such, neural networks have often been used within the geosciences to most accurately identify a desired output given a set of inputs, with the interpretation of what the network learns used as a secondary metric to ensure the network is making the right decision for the right reason. Neural network interpretation techniques have become more advanced in recent years, however, and we therefore propose that the ultimate objective of using a neural network can also be the interpretation of what the network has learned rather than the output itself. We show that the interpretation of neural networks can enable the discovery of scientifically meaningful connections within geoscientific data. In particular, we use two methods for neural network interpretation called backwards optimization and layerwise relevance propagation, both of which project the decision pathways of a network back onto the original input dimensions. To the best of our knowledge, LRP has not yet been applied to geoscientific research, and we believe it has great potential in this area. We show how these interpretation techniques can be used to reliably infer scientifically meaningful information from neural networks by applying them to common climate patterns. These results suggest that combining interpretable neural networks with novel scientific hypotheses will open the door to many new avenues in neural network-related geoscience research.</p></details> | <details><summary>The s...</summary><p>The second version of this manuscript is currently under review at the Journal of Advances in Modeling Earth Systems (JAMES)</p></details> |
| **[RAG for Geoscience: What We Expect, Gaps and Opportunities](https://arxiv.org/pdf/2508.11246v1)** | 2025-08-18 | [papers-cool](https://papers.cool/arxiv/2508.11246v1) | <details><summary>Show</summary><p>Retrieval-Augmented Generation (RAG) enhances language models by combining retrieval with generation. However, its current workflow remains largely text-centric, limiting its applicability in geoscience. Many geoscientific tasks are inherently evidence-hungry. Typical examples involve imputing missing observations using analog scenes, retrieving equations and parameters to calibrate models, geolocating field photos based on visual cues, or surfacing historical case studies to support policy analyses. A simple ``retrieve-then-generate'' pipeline is insufficient for these needs. We envision Geo-RAG, a next-generation paradigm that reimagines RAG as a modular retrieve $\rightarrow$ reason $\rightarrow$ generate $\rightarrow$ verify loop. Geo-RAG supports four core capabilities: (i) retrieval of multi-modal Earth data; (ii) reasoning under physical and domain constraints; (iii) generation of science-grade artifacts; and (iv) verification of generated hypotheses against numerical models, ground measurements, and expert assessments. This shift opens new opportunities for more trustworthy and transparent geoscience workflows.</p></details> |  |
| **[Data Centred Intelligent Geosciences: Research Agenda and Opportunities, Position Paper](https://arxiv.org/pdf/2209.02384v1)** | 2022-09-07 | [papers-cool](https://papers.cool/arxiv/2209.02384v1) | <details><summary>Show</summary><p>This paper describes and discusses our vision to develop and reason about best practices and novel ways of curating data-centric geosciences knowledge (data, experiments, models, methods, conclusions, and interpretations). This knowledge is produced from applying statistical modelling, Machine Learning, and modern data analytics methods on geo-data collections. The problems address open methodological questions in model building, models' assessment, prediction, and forecasting workflows.</p></details> |  |
| **[Neural Network Attribution Methods for Problems in Geoscience: A Novel Synthetic Benchmark Dataset](https://arxiv.org/pdf/2103.10005v2)** | 2022-06-14 | [papers-cool](https://papers.cool/arxiv/2103.10005v2) | <details><summary>Show</summary><p>Despite the increasingly successful application of neural networks to many problems in the geosciences, their complex and nonlinear structure makes the interpretation of their predictions difficult, which limits model trust and does not allow scientists to gain physical insights about the problem at hand. Many different methods have been introduced in the emerging field of eXplainable Artificial Intelligence (XAI), which aim at attributing the network s prediction to specific features in the input domain. XAI methods are usually assessed by using benchmark datasets (like MNIST or ImageNet for image classification). However, an objective, theoretically derived ground truth for the attribution is lacking for most of these datasets, making the assessment of XAI in many cases subjective. Also, benchmark datasets specifically designed for problems in geosciences are rare. Here, we provide a framework, based on the use of additively separable functions, to generate attribution benchmark datasets for regression problems for which the ground truth of the attribution is known a priori. We generate a large benchmark dataset and train a fully connected network to learn the underlying function that was used for simulation. We then compare estimated heatmaps from different XAI methods to the ground truth in order to identify examples where specific XAI methods perform well or poorly. We believe that attribution benchmarks as the ones introduced herein are of great importance for further application of neural networks in the geosciences, and for more objective assessment and accurate implementation of XAI methods, which will increase model trust and assist in discovering new science.</p></details> | <details><summary>This ...</summary><p>This is an updated preprint version of the manuscript. This work has been published (open access) in the journal Environmental Data Science with doi: https://doi.org/10.1017/eds.2022.7. Please cite the published version. The dataset of this work is published at: https://mlhub.earth/data/csu_synthetic_attribution</p></details> |
| **[Causal Inference in Geoscience and Remote Sensing from Observational Data](https://arxiv.org/pdf/2012.05150v1)** | 2020-12-10 | [papers-cool](https://papers.cool/arxiv/2012.05150v1) | <details><summary>Show</summary><p>Establishing causal relations between random variables from observational data is perhaps the most important challenge in today's \blue{science}. In remote sensing and geosciences this is of special relevance to better understand the Earth's system and the complex interactions between the governing processes. In this paper, we focus on observational causal inference, thus we try to estimate the correct direction of causation using a finite set of empirical data. In addition, we focus on the more complex bivariate scenario that requires strong assumptions and no conditional independence tests can be used. In particular, we explore the framework of (non-deterministic) additive noise models, which relies on the principle of independence between the cause and the generating mechanism. A practical algorithmic instantiation of such principle only requires 1) two regression models in the forward and backward directions, and 2) the estimation of {\em statistical independence} between the obtained residuals and the observations. The direction leading to more independent residuals is decided to be the cause. We instead propose a criterion that uses the {\em sensitivity} (derivative) of the dependence estimator, the sensitivity criterion allows to identify samples most affecting the dependence measure, and hence the criterion is robust to spurious detections. We illustrate performance in a collection of 28 geoscience causal inference problems, in a database of radiative transfer models simulations and machine learning emulators in vegetation parameter modeling involving 182 problems, and in assessing the impact of different regression models in a carbon cycle problem. The criterion achieves state-of-the-art detection rates in all cases, it is generally robust to noise sources and distortions.</p></details> |  |
| **[StefaLand: An Efficient Geoscience Foundation Model That Improves Dynamic Land-Surface Predictions](https://arxiv.org/pdf/2509.17942v2)** | 2025-09-30 | [papers-cool](https://papers.cool/arxiv/2509.17942v2) | <details><summary>Show</summary><p>Stewarding natural resources, mitigating floods, droughts, wildfires, and landslides, and meeting growing demands require models that can predict climate-driven land-surface responses and human feedback with high accuracy. Traditional impact models, whether process-based, statistical, or machine learning, struggle with spatial generalization due to limited observations and concept drift. Recently proposed vision foundation models trained on satellite imagery demand massive compute and are ill-suited for dynamic land-surface prediction. We introduce StefaLand, a generative spatiotemporal earth foundation model centered on landscape interactions. StefaLand improves predictions on four tasks and five datasets: streamflow, soil moisture, and soil composition, compared to prior state-of-the-art. Results highlight its ability to generalize across diverse, data-scarce regions and support broad land-surface applications. The model builds on a masked autoencoder backbone that learns deep joint representations of landscape attributes, with a location-aware architecture fusing static and time-series inputs, attribute-based representations that drastically reduce compute, and residual fine-tuning adapters that enhance transfer. While inspired by prior methods, their alignment with geoscience and integration in one model enables robust performance on dynamic land-surface tasks. StefaLand can be pretrained and finetuned on academic compute yet outperforms state-of-the-art baselines and even fine-tuned vision foundation models. To our knowledge, this is the first geoscience land-surface foundation model that demonstrably improves dynamic land-surface interaction predictions and supports diverse downstream applications.</p></details> |  |
| **[Investigating the fidelity of explainable artificial intelligence methods for applications of convolutional neural networks in geoscience](https://arxiv.org/pdf/2202.03407v2)** | 2022-09-07 | [papers-cool](https://papers.cool/arxiv/2202.03407v2) | <details><summary>Show</summary><p>Convolutional neural networks (CNNs) have recently attracted great attention in geoscience due to their ability to capture non-linear system behavior and extract predictive spatiotemporal patterns. Given their black-box nature however, and the importance of prediction explainability, methods of explainable artificial intelligence (XAI) are gaining popularity as a means to explain the CNN decision-making strategy. Here, we establish an intercomparison of some of the most popular XAI methods and investigate their fidelity in explaining CNN decisions for geoscientific applications. Our goal is to raise awareness of the theoretical limitations of these methods and gain insight into the relative strengths and weaknesses to help guide best practices. The considered XAI methods are first applied to an idealized attribution benchmark, where the ground truth of explanation of the network is known a priori, to help objectively assess their performance. Secondly, we apply XAI to a climate-related prediction setting, namely to explain a CNN that is trained to predict the number of atmospheric rivers in daily snapshots of climate simulations. Our results highlight several important issues of XAI methods (e.g., gradient shattering, inability to distinguish the sign of attribution, ignorance to zero input) that have previously been overlooked in our field and, if not considered cautiously, may lead to a distorted picture of the CNN decision-making strategy. We envision that our analysis will motivate further investigation into XAI fidelity and will help towards a cautious implementation of XAI in geoscience, which can lead to further exploitation of CNNs and deep learning for prediction problems.</p></details> |  |
| **[Prototype-Based Methods in Explainable AI and Emerging Opportunities in the Geosciences](https://arxiv.org/pdf/2410.19856v1)** | 2024-10-29 | [papers-cool](https://papers.cool/arxiv/2410.19856v1) | <details><summary>Show</summary><p>Prototype-based methods are intrinsically interpretable XAI methods that produce predictions and explanations by comparing input data with a set of learned prototypical examples that are representative of the training data. In this work, we discuss a series of developments in the field of prototype-based XAI that show potential for scientific learning tasks, with a focus on the geosciences. We organize the prototype-based XAI literature into three themes: the development and visualization of prototypes, types of prototypes, and the use of prototypes in various learning tasks. We discuss how the authors use prototype-based methods, their novel contributions, and any limitations or challenges that may arise when adapting these methods for geoscientific learning tasks. We highlight differences between geoscientific data sets and the standard benchmarks used to develop XAI methods, and discuss how specific geoscientific applications may benefit from using or modifying existing prototype-based XAI techniques.</p></details> | <details><summary>Accep...</summary><p>Accepted at AI for Science Workshop-Oral (Attention Track), Proceedings of 41st International Conference on Machine Learning (ICML) 2024</p></details> |
| **[Time-Varying Confounding Bias in Observational Geoscience with Application to Induced Seismicity](https://arxiv.org/pdf/2510.16360v1)** | 2025-10-21 | [papers-cool](https://papers.cool/arxiv/2510.16360v1) | <details><summary>Show</summary><p>Evidence derived primarily from physical models has identified saltwater disposal as the dominant causal factor that contributes to induced seismicity. To complement physical models, statistical/machine learning (ML) models are designed to measure associations from observational data, either with parametric regression models or more flexible ML models. However, it is often difficult to interpret the statistical significance of a parameter or the predicative power of a model as evidence of causation. We adapt a causal inference framework with the potential outcomes perspective to explicitly define what we meant by causal effect and declare necessary identification conditions to recover unbiased causal effect estimates. In particular, we illustrate the threat of time-varying confounding in observational longitudinal geoscience data through simulations and adapt established statistical methods for longitudinal analysis from the causal interference literature to estimate the effect of wastewater disposal on earthquakes in the Fort-Worth Basin of North Central Texas from 2013 to 2016.</p></details> |  |
| **[Power-law size distributions in geoscience revisited](https://arxiv.org/pdf/1810.07868v2)** | 2019-04-29 | [papers-cool](https://papers.cool/arxiv/1810.07868v2) | <details><summary>Show</summary><p>The size or energy of diverse structures or phenomena in geoscience appears to follow power-law distributions. A rigorous statistical analysis of such observations is tricky, though. Observables can span several orders of magnitude, but the range for which the power law may be valid is typically truncated, usually because the smallest events are too tiny to be detected and the largest ones are limited by the system size. We revisit several examples of proposed power-law distributions dealing with potentially damaging natural phenomena. Adequate fits of the distributions of sizes are especially important in these cases, given that they may be used to assess long-term hazard. After reviewing the theoretical background for power-law distributions, we improve an objective statistical fitting method and apply it to diverse data sets. The method is described in full detail and it is easy to implement. Our analysis elucidates the range of validity of the power-law fit and the corresponding exponent, and whether a power-law tail is improved by a truncated log-normal. We confirm that impact fireballs and Californian earthquakes show untruncated power-law behavior, whereas global earthquakes follow a double power law. Rain precipitation over space and time and tropical cyclones show a truncated power-law regime. Karst sinkholes and wildfires, in contrast, are better described by truncated log-normals, although wildfires also may show power-law regimes. Our conclusions only apply to the analyzed data sets, but show the potential of applying this robust statistical technique in the future.</p></details> |  |
| **[Advanced analysis of temporal data using Fisher-Shannon information: theoretical development and application in geosciences](https://arxiv.org/pdf/1912.02452v2)** | 2021-01-13 | [papers-cool](https://papers.cool/arxiv/1912.02452v2) | <details><summary>Show</summary><p>Complex non-linear time series are ubiquitous in geosciences. Quantifying complexity and non-stationarity of these data is a challenging task, and advanced complexity-based exploratory tool are required for understanding and visualizing such data. This paper discusses the Fisher-Shannon method, from which one can obtain a complexity measure and detect non-stationarity, as an efficient data exploration tool. The state-of-the-art studies related to the Fisher-Shannon measures are collected, and new analytical formulas for positive unimodal skewed distributions are proposed. Case studies on both synthetic and real data illustrate the usefulness of the Fisher-Shannon method, which can find application in different domains including time series discrimination and generation of times series features for clustering, modeling and forecasting. The paper is accompanied with Python and R libraries for the non-parametric estimation of the proposed measures.</p></details> | 18 pages, 5 figures |
| **[Beyond Visuals : Examining the Experiences of Geoscience Professionals With Vision Disabilities in Accessing Data Visualizations](https://arxiv.org/pdf/2207.13220v1)** | 2022-07-28 | [papers-cool](https://papers.cool/arxiv/2207.13220v1) | <details><summary>Show</summary><p>Data visualizations are ubiquitous in all disciplines and have become the primary means of analysing data and communicating insights. However, the predominant reliance on visual encoding of data continues to create accessibility barriers for people who are blind/vision impaired resulting in their under representation in Science, Technology, Engineering and Mathematics (STEM) disciplines. This research study seeks to understand the experiences of professionals who are blind/vision impaired in one such STEM discipline (geosciences) in accessing data visualizations. In-depth, semi-structured interviews with seven professionals were conducted to examine the accessibility barriers and areas for improvement to inform accessibility research pertaining to data visualizations through a socio-technical lens. A reflexive thematic analysis revealed the negative impact of visualizations in influencing their career path, lack of data exploration tools for research, barriers in accessing works of peers and mismatched pace of visualization and accessibility research. The article also includes recommendations from the participants to address some of these accessibility barriers.</p></details> |  |
| **[GeoRSMLLM: A Multimodal Large Language Model for Vision-Language Tasks in Geoscience and Remote Sensing](https://arxiv.org/pdf/2503.12490v1)** | 2025-03-18 | [papers-cool](https://papers.cool/arxiv/2503.12490v1) | <details><summary>Show</summary><p>The application of Vision-Language Models (VLMs) in remote sensing (RS) has demonstrated significant potential in traditional tasks such as scene classification, object detection, and image captioning. However, current models, which excel in Referring Expression Comprehension (REC), struggle with tasks involving complex instructions (e.g., exists multiple conditions) or pixel-level operations like segmentation and change detection. In this white paper, we provide a comprehensive hierarchical summary of vision-language tasks in RS, categorized by the varying levels of cognitive capability required. We introduce the Remote Sensing Vision-Language Task Set (RSVLTS), which includes Open-Vocabulary Tasks (OVT), Referring Expression Tasks (RET), and Described Object Tasks (DOT) with increased difficulty, and Visual Question Answering (VQA) aloneside. Moreover, we propose a novel unified data representation using a set-of-points approach for RSVLTS, along with a condition parser and a self-augmentation strategy based on cyclic referring. These features are integrated into the GeoRSMLLM model, and this enhanced model is designed to handle a broad range of tasks of RSVLTS, paving the way for a more generalized solution for vision-language tasks in geoscience and remote sensing.</p></details> |  |
| **[Differentiable modeling to unify machine learning and physical models and advance Geosciences](https://arxiv.org/pdf/2301.04027v2)** | 2023-12-29 | [papers-cool](https://papers.cool/arxiv/2301.04027v2) | <details><summary>Show</summary><p>Process-Based Modeling (PBM) and Machine Learning (ML) are often perceived as distinct paradigms in the geosciences. Here we present differentiable geoscientific modeling as a powerful pathway toward dissolving the perceived barrier between them and ushering in a paradigm shift. For decades, PBM offered benefits in interpretability and physical consistency but struggled to efficiently leverage large datasets. ML methods, especially deep networks, presented strong predictive skills yet lacked the ability to answer specific scientific questions. While various methods have been proposed for ML-physics integration, an important underlying theme -- differentiable modeling -- is not sufficiently recognized. Here we outline the concepts, applicability, and significance of differentiable geoscientific modeling (DG). "Differentiable" refers to accurately and efficiently calculating gradients with respect to model variables, critically enabling the learning of high-dimensional unknown relationships. DG refers to a range of methods connecting varying amounts of prior knowledge to neural networks and training them together, capturing a different scope than physics-guided machine learning and emphasizing first principles. Preliminary evidence suggests DG offers better interpretability and causality than ML, improved generalizability and extrapolation capability, and strong potential for knowledge discovery, while approaching the performance of purely data-driven ML. DG models require less training data while scaling favorably in performance and efficiency with increasing amounts of data. With DG, geoscientists may be better able to frame and investigate questions, test hypotheses, and discover unrecognized linkages.</p></details> |  |
| **[HexaShrink, an exact scalable framework for hexahedral meshes with attributes and discontinuities: multiresolution rendering and storage of geoscience models](https://arxiv.org/pdf/1903.07614v2)** | 2019-05-07 | [papers-cool](https://papers.cool/arxiv/1903.07614v2) | <details><summary>Show</summary><p>With huge data acquisition progresses realized in the past decades and acquisition systems now able to produce high resolution grids and point clouds, the digitization of physical terrains becomes increasingly more precise. Such extreme quantities of generated and modeled data greatly impact computational performances on many levels of high-performance computing (HPC): storage media, memory requirements, transfer capability, and finally simulation interactivity, necessary to exploit this instance of big data. Efficient representations and storage are thus becoming "enabling technologies'' in HPC experimental and simulation science. We propose HexaShrink, an original decomposition scheme for structured hexahedral volume meshes. The latter are used for instance in biomedical engineering, materials science, or geosciences. HexaShrink provides a comprehensive framework allowing efficient mesh visualization and storage. Its exactly reversible multiresolution decomposition yields a hierarchy of meshes of increasing levels of details, in terms of either geometry, continuous or categorical properties of cells. Starting with an overview of volume meshes compression techniques, our contribution blends coherently different multiresolution wavelet schemes in different dimensions. It results in a global framework preserving discontinuities (faults) across scales, implemented as a fully reversible upscaling at different resolutions. Experimental results are provided on meshes of varying size and complexity. They emphasize the consistency of the proposed representation, in terms of visualization, attribute downsampling and distribution at different resolutions. Finally, HexaShrink yields gains in storage space when combined to lossless compression techniques.</p></details> |  |
| **[A novel approach for estimating functions in the multivariate setting based on an adaptive knot selection for B-splines with an application to a chemical system used in geoscience](https://arxiv.org/pdf/2306.00686v3)** | 2024-01-26 | [papers-cool](https://papers.cool/arxiv/2306.00686v3) | <details><summary>Show</summary><p>In this paper, we will outline a novel data-driven method for estimating functions in a multivariate nonparametric regression model based on an adaptive knot selection for B-splines. The underlying idea of our approach for selecting knots is to apply the generalized lasso, since the knots of the B-spline basis can be seen as changes in the derivatives of the function to be estimated. This method was then extended to functions depending on several variables by processing each dimension independently, thus reducing the problem to a univariate setting. The regularization parameters were chosen by means of a criterion based on EBIC. The nonparametric estimator was obtained using a multivariate B-spline regression with the corresponding selected knots. Our procedure was validated through numerical experiments by varying the number of observations and the level of noise to investigate its robustness. The influence of observation sampling was also assessed and our method was applied to a chemical system commonly used in geoscience. For each different framework considered in this paper, our approach performed better than state-of-the-art methods. Our completely data-driven method is implemented in the glober R package which is available on the Comprehensive R Archive Network (CRAN).</p></details> | 29 pages, 27 figures |

## Spatial
| **Title** | **Date** | **KiMi** | **Abstract** | **Comment** |
| --- | --- | --- | --- | --- |
| **[From Spatial Relations to Spatial Configurations](https://arxiv.org/pdf/2007.09557v1)** | 2020-07-21 | [papers-cool](https://papers.cool/arxiv/2007.09557v1) | <details><summary>Show</summary><p>Spatial Reasoning from language is essential for natural language understanding. Supporting it requires a representation scheme that can capture spatial phenomena encountered in language as well as in images and videos. Existing spatial representations are not sufficient for describing spatial configurations used in complex tasks. This paper extends the capabilities of existing spatial representation languages and increases coverage of the semantic aspects that are needed to ground the spatial meaning of natural language text in the world. Our spatial relation language is able to represent a large, comprehensive set of spatial concepts crucial for reasoning and is designed to support the composition of static and dynamic spatial configurations. We integrate this language with the Abstract Meaning Representation(AMR) annotation schema and present a corpus annotated by this extended AMR. To exhibit the applicability of our representation scheme, we annotate text taken from diverse datasets and show how we extend the capabilities of existing spatial representation languages with the fine-grained decomposition of semantics and blend it seamlessly with AMRs of sentences and discourse representations as a whole.</p></details> |  |
| **[Spatial+: a novel approach to spatial confounding](https://arxiv.org/pdf/2009.09420v1)** | 2023-10-02 | [papers-cool](https://papers.cool/arxiv/2009.09420v1) | <details><summary>Show</summary><p>In spatial regression models, collinearity between covariates and spatial effects can lead to significant bias in effect estimates. This problem, known as spatial confounding, is encountered modelling forestry data to assess the effect of temperature on tree health. Reliable inference is difficult as results depend on whether or not spatial effects are included in the model. The mechanism behind spatial confounding is poorly understood and methods for dealing with it are limited. We propose a novel approach, spatial+, in which collinearity is reduced by replacing the covariates in the spatial model by their residuals after spatial dependence has been regressed away. Using a thin plate spline model formulation, we recognise spatial confounding as a smoothing-induced bias identified by Rice (1986), and through asymptotic analysis of the effect estimates, we show that spatial+ avoids the bias problems of the spatial model. This is also demonstrated in a simulation study. Spatial+ is straight-forward to implement using existing software and, as the response variable is the same as that of the spatial model, standard model selection criteria can be used for comparisons. A major advantage of the method is also that it extends to models with non-Gaussian response distributions. Finally, while our results are derived in a thin plate spline setting, the spatial+ methodology transfers easily to other spatial model formulations.</p></details> |  |
| **[What is "Spatial" about Spatial Computing?](https://arxiv.org/pdf/2508.20477v2)** | 2025-09-01 | [papers-cool](https://papers.cool/arxiv/2508.20477v2) | <details><summary>Show</summary><p>Recent advancements in geographic information systems and mixed reality technologies have positioned spatial computing as a transformative paradigm in computational science. However, the field remains conceptually fragmented, with diverse interpretations across disciplines like Human-Computer Interaction, Geographic Information Science, and Computer Science, which hinders a comprehensive understanding of spatial computing and poses challenges for its coherent advancement and interdisciplinary integration. In this paper, we trace the origins and historical evolution of spatial computing and examine how "spatial" is understood, identifying two schools of thought: "spatial" as the contextual understanding of space, where spatial data guides interaction in the physical world; and "spatial" as a mixed space for interaction, emphasizing the seamless integration of physical and digital environments to enable embodied engagement. By synthesizing these perspectives, we propose spatial computing as a computational paradigm that redefines the interplay between environment, computation, and human experience, offering a holistic lens to enhance its conceptual clarity and inspire future technological innovations that support meaningful interactions with and shaping of environments.</p></details> |  |
| **[Spatial Statistics](https://arxiv.org/pdf/2105.07216v1)** | 2021-05-18 | [papers-cool](https://papers.cool/arxiv/2105.07216v1) | <details><summary>Show</summary><p>Spatial statistics is an area of study devoted to the statistical analysis of data that have a spatial label associated with them. Geographers often refer to the "location information" associated with the "attribute information," whose study defines a research area called "spatial analysis." Many of the ways to manipulate spatial data are driven by algorithms with no uncertainty quantification associated with them. When a spatial analysis is statistical, that is, it incorporates uncertainty quantification, it falls in the research area called spatial statistics. The primary feature of spatial statistical models is that nearby attribute values are more statistically dependent than distant attribute values; this is a paraphrasing of what is sometimes called the First Law of Geography (Tobler, 1970).</p></details> |  |
| **[Alleviating Spatial Confounding in Spatial Frailty Models](https://arxiv.org/pdf/2008.06911v1)** | 2020-08-18 | [papers-cool](https://papers.cool/arxiv/2008.06911v1) | <details><summary>Show</summary><p>Spatial confounding is how is called the confounding between fixed and spatial random effects. It has been widely studied and it gained attention in the past years in the spatial statistics literature, as it may generate unexpected results in modeling. The projection-based approach, also known as restricted models, appears as a good alternative to overcome the spatial confounding in generalized linear mixed models. However, when the support of fixed effects is different from the spatial effect one, this approach can no longer be applied directly. In this work, we introduce a method to alleviate the spatial confounding for the spatial frailty models family. This class of models can incorporate spatially structured effects and it is usual to observe more than one sample unit per area which means that the support of fixed and spatial effects differs. In this case, we introduce a two folded projection-based approach projecting the design matrix to the dimension of the space and then projecting the random effect to the orthogonal space of the new design matrix. To provide fast inference in our analysis we employ the integrated nested Laplace approximation methodology. The method is illustrated with an application with lung and bronchus cancer in California - US that confirms that the methodology efficiency.</p></details> | <details><summary>21 pa...</summary><p>21 pages, 5 figures, 4 tables</p></details> |
| **[A simplified spatial+ approach to mitigate spatial confounding in multivariate spatial areal models](https://arxiv.org/pdf/2308.11260v2)** | 2024-01-08 | [papers-cool](https://papers.cool/arxiv/2308.11260v2) | <details><summary>Show</summary><p>Spatial areal models encounter the well-known and challenging problem of spatial confounding. This issue makes it arduous to distinguish between the impacts of observed covariates and spatial random effects. Despite previous research and various proposed methods to tackle this problem, finding a definitive solution remains elusive. In this paper, we propose a simplified version of the spatial+ approach that involves dividing the covariate into two components. One component captures large-scale spatial dependence, while the other accounts for short-scale dependence. This approach eliminates the need to separately fit spatial models for the covariates. We apply this method to analyse two forms of crimes against women, namely rapes and dowry deaths, in Uttar Pradesh, India, exploring their relationship with socio-demographic covariates. To evaluate the performance of the new approach, we conduct extensive simulation studies under different spatial confounding scenarios. The results demonstrate that the proposed method provides reliable estimates of fixed effects and posterior correlations between different responses.</p></details> |  |
| **[Consistency of common spatial estimators under spatial confounding](https://arxiv.org/pdf/2308.12181v4)** | 2024-09-19 | [papers-cool](https://papers.cool/arxiv/2308.12181v4) | <details><summary>Show</summary><p>This paper addresses the asymptotic performance of popular spatial regression estimators of the linear effect of an exposure on an outcome under ``spatial confounding" -- the presence of an unmeasured spatially-structured variable influencing both the exposure and the outcome. We first show that the estimators from ordinary least squares (OLS) and restricted spatial regression are asymptotically biased under spatial confounding. We then prove a novel main result on the consistency of the generalized least squares (GLS) estimator using a Gaussian process (GP) working covariance matrix in the presence of spatial confounding under infill (fixed domain) asymptotics. The result holds under very general conditions -- for any exposure with some non-spatial variation (noise), for any spatially continuous fixed confounder function, using any Matrn or square exponential kernel used to construct the GLS estimator, and without requiring Gaussianity of errors. Finally, we prove that spatial estimators from GLS, GP regression, and spline models that are consistent under confounding by a fixed function will also be consistent under endogeneity or confounding by a random function, i.e., a stochastic process. We conclude that, contrary to claims in some literature on spatial confounding, traditional spatial estimators are capable of estimating linear exposure effects under spatial confounding as long as there is some noise in the exposure. We support our theoretical arguments with simulation studies.</p></details> | <details><summary>revis...</summary><p>revision including new simulation</p></details> |
| **[Spatial Preference Rewarding for MLLMs Spatial Understanding](https://arxiv.org/pdf/2510.14374v1)** | 2025-10-17 | [papers-cool](https://papers.cool/arxiv/2510.14374v1) | <details><summary>Show</summary><p>Multimodal large language models~(MLLMs) have demonstrated promising spatial understanding capabilities, such as referencing and grounding object descriptions. Despite their successes, MLLMs still fall short in fine-grained spatial perception abilities, such as generating detailed region descriptions or accurately localizing objects. Additionally, they often fail to respond to the user's requirements for desired fine-grained spatial understanding. This issue might arise because existing approaches primarily focus on tuning MLLMs to model pre-annotated instruction data to inject spatial knowledge, without direct supervision of MLLMs' actual responses. We address this issue by SPR, a Spatial Preference Rewarding~(SPR) approach that enhances MLLMs' spatial capabilities by rewarding MLLMs' detailed responses with precise object localization over vague or inaccurate responses. With randomly selected image regions and region descriptions from MLLMs, SPR introduces semantic and localization scores to comprehensively evaluate the text quality and localization quality in MLLM-generated descriptions. We also refine the MLLM descriptions with better localization accuracy and pair the best-scored refinement with the initial descriptions of the lowest score for direct preference optimization, thereby enhancing fine-grained alignment with visual input. Extensive experiments over standard referring and grounding benchmarks show that SPR improves MLLM spatial understanding capabilities effectively with minimal overhead in training. Data and code will be released at https://github.com/hanqiu-hq/SPR</p></details> | ICCV 2025 |
| **[Discussion of the manuscript: Spatial+ a novel approach to spatial confounding](https://arxiv.org/pdf/2107.01644v1)** | 2021-07-06 | [papers-cool](https://papers.cool/arxiv/2107.01644v1) | <details><summary>Show</summary><p>I congratulate Dupont, Wood and Augustin (DWA hereon) for providing an easy-to-implement method for estimation in the presence of spatial confounding, and for addressing some of the complicated aspects on the topic. The method regresses the covariate of interest on spatial basis functions and uses the residuals of this model in an outcome regression. The authors show that, if the covariate is not completely spatial, this approach leads to consistent estimation of the conditional association between the exposure and the outcome. Below I discuss conceptual and operational issues that are fundamental to inference in spatial settings: (i) the target quantity and its interpretability, (ii) the non-spatial aspect of covariates and their relative spatial scales, and (iii) the impact of spatial smoothing. While DWA provide some insights on these issues, I believe that the audience might benefit from a deeper discussion. In what follows, I focus on the setting where a researcher is interested in interpreting the relationship between a given covariate and an outcome. I refer to the covariate of interest as the exposure to differentiate it from the rest.</p></details> |  |
| **[Spatially Regularized Gaussian Mixtures for Clustering Spatial Transcriptomic Data](https://arxiv.org/pdf/2510.19108v1)** | 2025-10-23 | [papers-cool](https://papers.cool/arxiv/2510.19108v1) | <details><summary>Show</summary><p>Spatial transcriptomics measures the expression of thousands of genes in a tissue sample while preserving its spatial structure. This class of technologies has enabled the investigation of the spatial variation of gene expressions and their impact on specific biological processes. Identifying genes with similar expression profiles is of utmost importance, thus motivating the development of flexible methods leveraging spatial data structure to cluster genes. Here, we propose a modeling framework for clustering observations measured over numerous spatial locations via Gaussian processes. Rather than specifying their covariance kernels as a function of the spatial structure, we use it to inform a generalized Cholesky decomposition of their precision matrices. This approach prevents issues with kernel misspecification and facilitates the estimation of a non-stationarity spatial covariance structure. Applied to spatial transcriptomic data, our model identifies gene clusters with distinctive spatial correlation patterns across tissue areas comprising different cell types, like tumoral and stromal areas.</p></details> | <details><summary>to be...</summary><p>to be published in Journal of Classification</p></details> |
| **[Entity-oriented spatial coding and discrete topological spatial relations](https://arxiv.org/pdf/1601.03817v1)** | 2016-01-18 | [papers-cool](https://papers.cool/arxiv/1601.03817v1) | <details><summary>Show</summary><p>Based on a newly proposed spatial data model - spatial chromatic model (SCM), we developed a spatial coding scheme, called full-coded ordinary arranged chromatic diagram (full-OACD). Full-OACD is a type of spatial tessellation, where space is partitioned into a number of subspaces such as cells, edges, and vertexes. These subspaces are called spatial particles and assigned with unique codes - chromatic codes. The generation, structures, computations, and properties of full-OACD are introduced and relations between chromatic codes and particle spatial topology are investigated, indicating that chromatic codes provide a potential useful and meaningful tool not only for spatial analysis in geographical information science, but also for other relevant disciplines such as discrete mathematics, topology, and computer science.</p></details> |  |
| **[Demystifying Spatial Confounding](https://arxiv.org/pdf/2309.16861v3)** | 2025-07-15 | [papers-cool](https://papers.cool/arxiv/2309.16861v3) | <details><summary>Show</summary><p>Spatial confounding is a fundamental issue in spatial regression models which arises because spatial random effects, included to approximate unmeasured spatial variation, are typically not independent of covariates in the model. This can lead to significant bias in covariate effect estimates. The problem is complex and has been the topic of extensive research with sometimes puzzling and seemingly contradictory results. Here, we develop a broad theoretical framework that brings mathematical clarity to the mechanisms of spatial confounding, providing explicit analytical expressions for the resulting bias. We see that the problem is directly linked to spatial smoothing and identify exactly how the size and occurrence of bias relate to the features of the spatial model as well as the underlying confounding scenario. Using our results, we can explain subtle and counter-intuitive behaviours. Finally, we propose a general approach for dealing with spatial confounding bias in practice, applicable for any spatial model specification. When a covariate has non-spatial information, we show that a general form of the so-called spatial+ method can be used to eliminate bias. When no such information is present, the situation is more challenging but, under the assumption of unconfounded high frequencies, we develop a procedure in which multiple capped versions of spatial+ are applied to assess the bias in this case. We illustrate our approach with an application to air temperature in Germany.</p></details> |  |
| **[Acquiring Common Sense Spatial Knowledge through Implicit Spatial Templates](https://arxiv.org/pdf/1711.06821v3)** | 2020-03-09 | [papers-cool](https://papers.cool/arxiv/1711.06821v3) | <details><summary>Show</summary><p>Spatial understanding is a fundamental problem with wide-reaching real-world applications. The representation of spatial knowledge is often modeled with spatial templates, i.e., regions of acceptability of two objects under an explicit spatial relationship (e.g., "on", "below", etc.). In contrast with prior work that restricts spatial templates to explicit spatial prepositions (e.g., "glass on table"), here we extend this concept to implicit spatial language, i.e., those relationships (generally actions) for which the spatial arrangement of the objects is only implicitly implied (e.g., "man riding horse"). In contrast with explicit relationships, predicting spatial arrangements from implicit spatial language requires significant common sense spatial understanding. Here, we introduce the task of predicting spatial templates for two objects under a relationship, which can be seen as a spatial question-answering task with a (2D) continuous output ("where is the man w.r.t. a horse when the man is walking the horse?"). We present two simple neural-based models that leverage annotated images and structured text to learn this task. The good performance of these models reveals that spatial locations are to a large extent predictable from implicit spatial language. Crucially, the models attain similar performance in a challenging generalized setting, where the object-relation-object combinations (e.g.,"man walking dog") have never been seen before. Next, we go one step further by presenting the models with unseen objects (e.g., "dog"). In this scenario, we show that leveraging word embeddings enables the models to output accurate spatial predictions, proving that the models acquire solid common sense spatial knowledge allowing for such generalization.</p></details> | <details><summary>To ap...</summary><p>To appear at AAAI 2018 Conference</p></details> |
| **[Nonnegative spatial factorization](https://arxiv.org/pdf/2110.06122v1)** | 2021-10-13 | [papers-cool](https://papers.cool/arxiv/2110.06122v1) | <details><summary>Show</summary><p>Gaussian processes are widely used for the analysis of spatial data due to their nonparametric flexibility and ability to quantify uncertainty, and recently developed scalable approximations have facilitated application to massive datasets. For multivariate outcomes, linear models of coregionalization combine dimension reduction with spatial correlation. However, their real-valued latent factors and loadings are difficult to interpret because, unlike nonnegative models, they do not recover a parts-based representation. We present nonnegative spatial factorization (NSF), a spatially-aware probabilistic dimension reduction model that naturally encourages sparsity. We compare NSF to real-valued spatial factorizations such as MEFISTO and nonspatial dimension reduction methods using simulations and high-dimensional spatial transcriptomics data. NSF identifies generalizable spatial patterns of gene expression. Since not all patterns of gene expression are spatial, we also propose a hybrid extension of NSF that combines spatial and nonspatial components, enabling quantification of spatial importance for both observations and features. A TensorFlow implementation of NSF is available from https://github.com/willtownes/nsf-paper .</p></details> |  |
| **[Re-thinking Spatial Confounding in Spatial Linear Mixed Models](https://arxiv.org/pdf/2301.05743v2)** | 2024-06-25 | [papers-cool](https://papers.cool/arxiv/2301.05743v2) | <details><summary>Show</summary><p>In the last two decades, considerable research has been devoted to a phenomenon known as spatial confounding. Spatial confounding is thought to occur when there is multicollinearity between a covariate and the random effect in a spatial regression model. This multicollinearity is considered highly problematic when the inferential goal is estimating regression coefficients and various methodologies have been proposed to attempt to alleviate it. Recently, it has become apparent that many of these methodologies are flawed, yet the field continues to expand. In this paper, we offer a novel perspective of synthesizing the work in the field of spatial confounding. We propose that at least two distinct phenomena are currently conflated with the term spatial confounding. We refer to these as the ``analysis model'' and the ``data generation'' types of spatial confounding. We show that these two issues can lead to contradicting conclusions about whether spatial confounding exists and whether methods to alleviate it will improve inference. Our results also illustrate that in most cases, traditional spatial linear mixed models do help to improve inference on regression coefficients. Drawing on the insights gained, we offer a path forward for research in spatial confounding.</p></details> | <details><summary>38 pa...</summary><p>38 pages main text; 8 figures; code available upon request</p></details> |
| **[Spatially Clustered Regression](https://arxiv.org/pdf/2011.01493v2)** | 2021-04-29 | [papers-cool](https://papers.cool/arxiv/2011.01493v2) | <details><summary>Show</summary><p>Spatial regression or geographically weighted regression models have been widely adopted to capture the effects of auxiliary information on a response variable of interest over a region. In contrast, relationships between response and auxiliary variables are expected to exhibit complex spatial patterns in many applications. This paper proposes a new approach for spatial regression, called spatially clustered regression, to estimate possibly clustered spatial patterns of the relationships. We combine K-means-based clustering formulation and penalty function motivated from a spatial process known as Potts model for encouraging similar clustering in neighboring locations. We provide a simple iterative algorithm to fit the proposed method, scalable for large spatial datasets. Through simulation studies, the proposed method demonstrates its superior performance to existing methods even under the true structure does not admit spatial clustering. Finally, the proposed method is applied to crime event data in Tokyo and produces interpretable results for spatial patterns. The R code is available at https://github.com/sshonosuke/SCR.</p></details> | 28 pages, 6 figures |
| **[Spatial LibriSpeech: An Augmented Dataset for Spatial Audio Learning](https://arxiv.org/pdf/2308.09514v1)** | 2023-08-21 | [papers-cool](https://papers.cool/arxiv/2308.09514v1) | <details><summary>Show</summary><p>We present Spatial LibriSpeech, a spatial audio dataset with over 650 hours of 19-channel audio, first-order ambisonics, and optional distractor noise. Spatial LibriSpeech is designed for machine learning model training, and it includes labels for source position, speaking direction, room acoustics and geometry. Spatial LibriSpeech is generated by augmenting LibriSpeech samples with 200k+ simulated acoustic conditions across 8k+ synthetic rooms. To demonstrate the utility of our dataset, we train models on four spatial audio tasks, resulting in a median absolute error of 6.60 on 3D source localization, 0.43m on distance, 90.66ms on T30, and 2.74dB on DRR estimation. We show that the same models generalize well to widely-used evaluation datasets, e.g., obtaining a median absolute error of 12.43 on 3D source localization on TUT Sound Events 2018, and 157.32ms on T30 estimation on ACE Challenge.</p></details> |  |
| **[Visual Spatial Tuning](https://arxiv.org/pdf/2511.05491v1)** | 2025-11-10 | [papers-cool](https://papers.cool/arxiv/2511.05491v1) | <details><summary>Show</summary><p>Capturing spatial relationships from visual inputs is a cornerstone of human-like general intelligence. Several previous studies have tried to enhance the spatial awareness of Vision-Language Models (VLMs) by adding extra expert encoders, which brings extra overhead and usually harms general capabilities. To enhance the spatial ability in general architectures, we introduce Visual Spatial Tuning (VST), a comprehensive framework to cultivate VLMs with human-like visuospatial abilities, from spatial perception to reasoning. We first attempt to enhance spatial perception in VLMs by constructing a large-scale dataset termed VST-P, which comprises 4.1 million samples spanning 19 skills across single views, multiple images, and videos. Then, we present VST-R, a curated dataset with 135K samples that instruct models to reason in space. In particular, we adopt a progressive training pipeline: supervised fine-tuning to build foundational spatial knowledge, followed by reinforcement learning to further improve spatial reasoning abilities. Without the side-effect to general capabilities, the proposed VST consistently achieves state-of-the-art results on several spatial benchmarks, including $34.8\%$ on MMSI-Bench and $61.2\%$ on VSIBench. It turns out that the Vision-Language-Action models can be significantly enhanced with the proposed spatial tuning paradigm, paving the way for more physically grounded AI.</p></details> |  |
| **[Regionalization of Multiscale Spatial Processes using a Criterion for Spatial Aggregation Error](https://arxiv.org/pdf/1502.01974v2)** | 2015-12-11 | [papers-cool](https://papers.cool/arxiv/1502.01974v2) | <details><summary>Show</summary><p>The modifiable areal unit problem and the ecological fallacy are known problems that occur when modeling multiscale spatial processes. We investigate how these forms of spatial aggregation error can guide a regionalization over a spatial domain of interest. By "regionalization" we mean a specification of geographies that define the spatial support for areal data. This topic has been studied vigorously by geographers, but has been given less attention by spatial statisticians. Thus, we propose a criterion for spatial aggregation error (CAGE), which we minimize to obtain an optimal regionalization. To define CAGE we draw a connection between spatial aggregation error and a new multiscale representation of the Karhunen-Loeve (K-L) expansion. This relationship between CAGE and the multiscale K-L expansion leads to illuminating theoretical developments including: connections between spatial aggregation error, squared prediction error, spatial variance, and a novel extension of Obled-Creutin eigenfunctions. The effectiveness of our approach is demonstrated through an analysis of two datasets, one using the American Community Survey and one related to environmental ocean winds.</p></details> |  |
| **[Spatial-MLLM: Boosting MLLM Capabilities in Visual-based Spatial Intelligence](https://arxiv.org/pdf/2505.23747v1)** | 2025-05-30 | [papers-cool](https://papers.cool/arxiv/2505.23747v1) | <details><summary>Show</summary><p>Recent advancements in Multimodal Large Language Models (MLLMs) have significantly enhanced performance on 2D visual tasks. However, improving their spatial intelligence remains a challenge. Existing 3D MLLMs always rely on additional 3D or 2.5D data to incorporate spatial awareness, restricting their utility in scenarios with only 2D inputs, such as images or videos. In this paper, we present Spatial-MLLM, a novel framework for visual-based spatial reasoning from purely 2D observations. Unlike conventional video MLLMs which rely on CLIP-based visual encoders optimized for semantic understanding, our key insight is to unleash the strong structure prior from the feed-forward visual geometry foundation model. Specifically, we propose a dual-encoder architecture: a pretrained 2D visual encoder to extract semantic features, and a spatial encoder-initialized from the backbone of the visual geometry model-to extract 3D structure features. A connector then integrates both features into unified visual tokens for enhanced spatial understanding. Furthermore, we propose a space-aware frame sampling strategy at inference time, which selects the spatially informative frames of a video sequence, ensuring that even under limited token length, the model focuses on frames critical for spatial reasoning. Beyond architecture improvements, we construct the Spatial-MLLM-120k dataset and train the model on it using supervised fine-tuning and GRPO. Extensive experiments on various real-world datasets demonstrate that our spatial-MLLM achieves state-of-the-art performance in a wide range of visual-based spatial understanding and reasoning tasks. Project page: https://diankun-wu.github.io/Spatial-MLLM/.</p></details> | 21 pages |
| **[An Overview of Spatial Econometrics](https://arxiv.org/pdf/1605.03486v1)** | 2016-05-12 | [papers-cool](https://papers.cool/arxiv/1605.03486v1) | <details><summary>Show</summary><p>This paper offers an expository overview of the field of spatial econometrics. It first justifies the necessity of special statistical procedures for the analysis of spatial data and then proceeds to describe the fundamentals of these procedures. In particular, this paper covers three crucial techniques for building models with spatial data. First, we discuss how to create a spatial weights matrix based on the distances between each data point in a dataset. Next, we describe the conventional methods to formally detect spatial autocorrelation, both global and local. Finally, we outline the chief components of a spatial autoregressive model, noting the circumstances under which it would be appropriate to incorporate each component into a model. This paper seeks to offer a concise introduction to spatial econometrics that will be accessible to interested individuals with a background in statistics or econometrics.</p></details> |  |
| **[On Cokriging, Neural Networks, and Spatial Blind Source Separation for Multivariate Spatial Prediction](https://arxiv.org/pdf/2007.03747v1)** | 2024-04-12 | [papers-cool](https://papers.cool/arxiv/2007.03747v1) | <details><summary>Show</summary><p>Multivariate measurements taken at irregularly sampled locations are a common form of data, for example in geochemical analysis of soil. In practical considerations predictions of these measurements at unobserved locations are of great interest. For standard multivariate spatial prediction methods it is mandatory to not only model spatial dependencies but also cross-dependencies which makes it a demanding task. Recently, a blind source separation approach for spatial data was suggested. When using this spatial blind source separation method prior the actual spatial prediction, modelling of spatial cross-dependencies is avoided, which in turn simplifies the spatial prediction task significantly. In this paper we investigate the use of spatial blind source separation as a pre-processing tool for spatial prediction and compare it with predictions from Cokriging and neural networks in an extensive simulation study as well as a geochemical dataset.</p></details> |  |
| **[Spatial Transcriptomics Analysis of Spatially Dense Gene Expression Prediction](https://arxiv.org/pdf/2503.01347v2)** | 2025-08-05 | [papers-cool](https://papers.cool/arxiv/2503.01347v2) | <details><summary>Show</summary><p>Spatial transcriptomics (ST) measures gene expression at fine-grained spatial resolution, offering insights into tissue molecular landscapes. Previous methods for spatial gene expression prediction typically crop spots of interest from histopathology slide images, and train models to map each spot to a corresponding gene expression profile. However, these methods inherently lose the spatial resolution in gene expression: 1) each spot often contains multiple cells with distinct gene expression profiles; 2) spots are typically defined at fixed spatial resolutions, limiting the ability to predict gene expression at varying scales. To address these limitations, this paper presents PixNet, a dense prediction network capable of predicting spatially resolved gene expression across spots of varying sizes and scales directly from histopathology slide images. Different from previous methods that map individual spots to gene expression values, we generate a spatially dense continuous gene expression map from the histopathology slide image, and aggregate values within spots of interest to predict the gene expression. Our PixNet outperforms state-of-the-art methods on four common ST datasets in multiple spatial scales. The source code will be publicly available.</p></details> |  |
| **[Autocart -- spatially-aware regression trees for ecological and spatial modeling](https://arxiv.org/pdf/2101.08258v1)** | 2021-01-22 | [papers-cool](https://papers.cool/arxiv/2101.08258v1) | <details><summary>Show</summary><p>Many ecological and spatial processes are complex in nature and are not accurately modeled by linear models. Regression trees promise to handle the high-order interactions that are present in ecological and spatial datasets, but fail to produce physically realistic characterizations of the underlying landscape. The "autocart" (autocorrelated regression trees) R package extends the functionality of previously proposed spatial regression tree methods through a spatially aware splitting function and novel adaptive inverse distance weighting method in each terminal node. The efficacy of these autocart models, including an autocart extension of random forest, is demonstrated on multiple datasets. This highlights the ability of autocart to model complex interactions between spatial variables while still providing physically realistic representations of the landscape.</p></details> | 20 pages, 10 figures |
| **[Spatial Symmetry Driven Pruning Strategies for Efficient Declarative Spatial Reasoning](https://arxiv.org/pdf/1506.04945v1)** | 2015-06-17 | [papers-cool](https://papers.cool/arxiv/1506.04945v1) | <details><summary>Show</summary><p>Declarative spatial reasoning denotes the ability to (declaratively) specify and solve real-world problems related to geometric and qualitative spatial representation and reasoning within standard knowledge representation and reasoning (KR) based methods (e.g., logic programming and derivatives). One approach for encoding the semantics of spatial relations within a declarative programming framework is by systems of polynomial constraints. However, solving such constraints is computationally intractable in general (i.e. the theory of real-closed fields). We present a new algorithm, implemented within the declarative spatial reasoning system CLP(QS), that drastically improves the performance of deciding the consistency of spatial constraint graphs over conventional polynomial encodings. We develop pruning strategies founded on spatial symmetries that form equivalence classes (based on affine transformations) at the qualitative spatial level. Moreover, pruning strategies are themselves formalised as knowledge about the properties of space and spatial symmetries. We evaluate our algorithm using a range of benchmarks in the class of contact problems, and proofs in mereology and geometry. The empirical results show that CLP(QS) with knowledge-based spatial pruning outperforms conventional polynomial encodings by orders of magnitude, and can thus be applied to problems that are otherwise unsolvable in practice.</p></details> | <details><summary>22 pa...</summary><p>22 pages. Accepted for publication at: COSIT 2015 - Conference on Spatial Information Theory XII (COSIT), Santa Fe, New Mexico, USA ,October 2015</p></details> |
| **[Spatial Process Generation](https://arxiv.org/pdf/1308.0399v1)** | 2013-08-05 | [papers-cool](https://papers.cool/arxiv/1308.0399v1) | <details><summary>Show</summary><p>The generation of random spatial data on a computer is an important tool for understanding the behavior of spatial processes. In this paper we describe how to generate realizations from the main types of spatial processes, including Gaussian and Markov random fields, point processes, spatial Wiener processes, and Levy fields. Concrete MATLAB code is provided.</p></details> | <details><summary>41 pa...</summary><p>41 pages, 31 figures, 13 matlab programs, 6 algorithms</p></details> |
| **[Spatial Regression and the Bayesian Filter](https://arxiv.org/pdf/1706.04651v2)** | 2017-08-02 | [papers-cool](https://papers.cool/arxiv/1706.04651v2) | <details><summary>Show</summary><p>Regression for spatially dependent outcomes poses many challenges, for inference and for computation. Non-spatial models and traditional spatial mixed-effects models each have their advantages and disadvantages, making it difficult for practitioners to determine how to carry out a spatial regression analysis. We discuss the data-generating mechanisms implicitly assumed by various popular spatial regression models, and discuss the implications of these assumptions. We propose Bayesian spatial filtering as an approximate middle way between non-spatial models and traditional spatial mixed models. We show by simulation that our Bayesian spatial filtering model has several desirable properties and hence may be a useful addition to a spatial statistician's toolkit.</p></details> |  |
| **[SpatialNLI: A Spatial Domain Natural Language Interface to Databases Using Spatial Comprehension](https://arxiv.org/pdf/1908.10917v1)** | 2019-09-12 | [papers-cool](https://papers.cool/arxiv/1908.10917v1) | <details><summary>Show</summary><p>A natural language interface (NLI) to databases is an interface that translates a natural language question to a structured query that is executable by database management systems (DBMS). However, an NLI that is trained in the general domain is hard to apply in the spatial domain due to the idiosyncrasy and expressiveness of the spatial questions. Inspired by the machine comprehension model, we propose a spatial comprehension model that is able to recognize the meaning of spatial entities based on the semantics of the context. The spatial semantics learned from the spatial comprehension model is then injected to the natural language question to ease the burden of capturing the spatial-specific semantics. With our spatial comprehension model and information injection, our NLI for the spatial domain, named SpatialNLI, is able to capture the semantic structure of the question and translate it to the corresponding syntax of an executable query accurately. We also experimentally ascertain that SpatialNLI outperforms state-of-the-art methods.</p></details> | 10 pages |
| **[A Spatial-Temporal Attentive Network with Spatial Continuity for Trajectory Prediction](https://arxiv.org/pdf/2003.06107v3)** | 2021-10-15 | [papers-cool](https://papers.cool/arxiv/2003.06107v3) | <details><summary>Show</summary><p>It remains challenging to automatically predict the multi-agent trajectory due to multiple interactions including agent to agent interaction and scene to agent interaction. Although recent methods have achieved promising performance, most of them just consider spatial influence of the interactions and ignore the fact that temporal influence always accompanies spatial influence. Moreover, those methods based on scene information always require extra segmented scene images to generate multiple socially acceptable trajectories. To solve these limitations, we propose a novel model named spatial-temporal attentive network with spatial continuity (STAN-SC). First, spatial-temporal attention mechanism is presented to explore the most useful and important information. Second, we conduct a joint feature sequence based on the sequence and instant state information to make the generative trajectories keep spatial continuity. Experiments are performed on the two widely used ETH-UCY datasets and demonstrate that the proposed model achieves state-of-the-art prediction accuracy and handles more complex scenarios.</p></details> | <details><summary>bad m...</summary><p>bad model settings and unclear results</p></details> |
| **[Spatial Strength Centrality and the Effect of Spatial Embeddings on Network Architecture](https://arxiv.org/pdf/1910.01174v2)** | 2020-07-01 | [papers-cool](https://papers.cool/arxiv/1910.01174v2) | <details><summary>Show</summary><p>For many networks, it is useful to think of their nodes as being embedded in a latent space, and such embeddings can affect the probabilities for nodes to be adjacent to each other. In this paper, we extend existing models of synthetic networks to spatial network models by first embedding nodes in Euclidean space and then modifying the models so that progressively longer edges occur with progressively smaller probabilities. We start by extending a geographical fitness model by employing Gaussian-distributed fitnesses, and we then develop spatial versions of preferential attachment and configuration models. We define a notion of "spatial strength centrality" to help characterize how strongly a spatial embedding affects network structure, and we examine spatial strength centrality on a variety of real and synthetic networks.</p></details> |  |
| **[Single Cells Are Spatial Tokens: Transformers for Spatial Transcriptomic Data Imputation](https://arxiv.org/pdf/2302.03038v2)** | 2024-02-19 | [papers-cool](https://papers.cool/arxiv/2302.03038v2) | <details><summary>Show</summary><p>Spatially resolved transcriptomics brings exciting breakthroughs to single-cell analysis by providing physical locations along with gene expression. However, as a cost of the extremely high spatial resolution, the cellular level spatial transcriptomic data suffer significantly from missing values. While a standard solution is to perform imputation on the missing values, most existing methods either overlook spatial information or only incorporate localized spatial context without the ability to capture long-range spatial information. Using multi-head self-attention mechanisms and positional encoding, transformer models can readily grasp the relationship between tokens and encode location information. In this paper, by treating single cells as spatial tokens, we study how to leverage transformers to facilitate spatial tanscriptomics imputation. In particular, investigate the following two key questions: (1) $\textit{how to encode spatial information of cells in transformers}$, and (2) $\textit{ how to train a transformer for transcriptomic imputation}$. By answering these two questions, we present a transformer-based imputation framework, SpaFormer, for cellular-level spatial transcriptomic data. Extensive experiments demonstrate that SpaFormer outperforms existing state-of-the-art imputation algorithms on three large-scale datasets while maintaining superior computational efficiency.</p></details> |  |
| **[Spatially and Robustly Hybrid Mixture Regression Model for Inference of Spatial Dependence](https://arxiv.org/pdf/2109.00539v3)** | 2021-09-30 | [papers-cool](https://papers.cool/arxiv/2109.00539v3) | <details><summary>Show</summary><p>In this paper, we propose a Spatial Robust Mixture Regression model to investigate the relationship between a response variable and a set of explanatory variables over the spatial domain, assuming that the relationships may exhibit complex spatially dynamic patterns that cannot be captured by constant regression coefficients. Our method integrates the robust finite mixture Gaussian regression model with spatial constraints, to simultaneously handle the spatial nonstationarity, local homogeneity, and outlier contaminations. Compared with existing spatial regression models, our proposed model assumes the existence a few distinct regression models that are estimated based on observations that exhibit similar response-predictor relationships. As such, the proposed model not only accounts for nonstationarity in the spatial trend, but also clusters observations into a few distinct and homogenous groups. This provides an advantage on interpretation with a few stationary sub-processes identified that capture the predominant relationships between response and predictor variables. Moreover, the proposed method incorporates robust procedures to handle contaminations from both regression outliers and spatial outliers. By doing so, we robustly segment the spatial domain into distinct local regions with similar regression coefficients, and sporadic locations that are purely outliers. Rigorous statistical hypothesis testing procedure has been designed to test the significance of such segmentation. Experimental results on many synthetic and real-world datasets demonstrate the robustness, accuracy, and effectiveness of our proposed method, compared with other robust finite mixture regression, spatial regression and spatial segmentation methods.</p></details> | <details><summary>Accep...</summary><p>Accepted by ICDM IEEE 2021</p></details> |
| **[Robustness of Spatial Micronetworks](https://arxiv.org/pdf/1501.05976v1)** | 2015-06-03 | [papers-cool](https://papers.cool/arxiv/1501.05976v1) | <details><summary>Show</summary><p>Power lines, roadways, pipelines and other physical infrastructure are critical to modern society. These structures may be viewed as spatial networks where geographic distances play a role in the functionality and construction cost of links. Traditionally, studies of network robustness have primarily considered the connectedness of large, random networks. Yet for spatial infrastructure physical distances must also play a role in network robustness. Understanding the robustness of small spatial networks is particularly important with the increasing interest in microgrids, small-area distributed power grids that are well suited to using renewable energy resources. We study the random failures of links in small networks where functionality depends on both spatial distance and topological connectedness. By introducing a percolation model where the failure of each link is proportional to its spatial length, we find that, when failures depend on spatial distances, networks are more fragile than expected. Accounting for spatial effects in both construction and robustness is important for designing efficient microgrids and other network infrastructure.</p></details> | 15 pages, 8 figures |
| **[Spatial Policy: Guiding Visuomotor Robotic Manipulation with Spatial-Aware Modeling and Reasoning](https://arxiv.org/pdf/2508.15874v1)** | 2025-08-25 | [papers-cool](https://papers.cool/arxiv/2508.15874v1) | <details><summary>Show</summary><p>Vision-centric hierarchical embodied models have demonstrated strong potential for long-horizon robotic control. However, existing methods lack spatial awareness capabilities, limiting their effectiveness in bridging visual plans to actionable control in complex environments. To address this problem, we propose Spatial Policy (SP), a unified spatial-aware visuomotor robotic manipulation framework via explicit spatial modeling and reasoning. Specifically, we first design a spatial-conditioned embodied video generation module to model spatially guided predictions through a spatial plan table. Then, we propose a spatial-based action prediction module to infer executable actions with coordination. Finally, we propose a spatial reasoning feedback policy to refine the spatial plan table via dual-stage replanning. Extensive experiments show that SP significantly outperforms state-of-the-art baselines, achieving a 33.0% average improvement over the best baseline. With an 86.7% average success rate across 11 diverse tasks, SP substantially enhances the practicality of embodied models for robotic control applications. Code and checkpoints are maintained at https://plantpotatoonmoon.github.io/SpatialPolicy/.</p></details> |  |
| **[Spatial Deconfounder: Interference-Aware Deconfounding for Spatial Causal Inference](https://arxiv.org/pdf/2510.08762v1)** | 2025-10-13 | [papers-cool](https://papers.cool/arxiv/2510.08762v1) | <details><summary>Show</summary><p>Causal inference in spatial domains faces two intertwined challenges: (1) unmeasured spatial factors, such as weather, air pollution, or mobility, that confound treatment and outcome, and (2) interference from nearby treatments that violate standard no-interference assumptions. While existing methods typically address one by assuming away the other, we show they are deeply connected: interference reveals structure in the latent confounder. Leveraging this insight, we propose the Spatial Deconfounder, a two-stage method that reconstructs a substitute confounder from local treatment vectors using a conditional variational autoencoder (CVAE) with a spatial prior, then estimates causal effects via a flexible outcome model. We show that this approach enables nonparametric identification of both direct and spillover effects under weak assumptions--without requiring multiple treatment types or a known model of the latent field. Empirically, we extend SpaCE, a benchmark suite for spatial confounding, to include treatment interference, and show that the Spatial Deconfounder consistently improves effect estimation across real-world datasets in environmental health and social science. By turning interference into a multi-cause signal, our framework bridges spatial and deconfounding literatures to advance robust causal inference in structured data.</p></details> | <details><summary>24 pa...</summary><p>24 pages, 3 figures, 6 tables</p></details> |
| **[Spatial Networks](https://arxiv.org/pdf/1010.0302v2)** | 2015-05-20 | [papers-cool](https://papers.cool/arxiv/1010.0302v2) | <details><summary>Show</summary><p>Complex systems are very often organized under the form of networks where nodes and edges are embedded in space. Transportation and mobility networks, Internet, mobile phone networks, power grids, social and contact networks, neural networks, are all examples where space is relevant and where topology alone does not contain all the information. Characterizing and understanding the structure and the evolution of spatial networks is thus crucial for many different fields ranging from urbanism to epidemiology. An important consequence of space on networks is that there is a cost associated to the length of edges which in turn has dramatic effects on the topological structure of these networks. We will expose thoroughly the current state of our understanding of how the spatial constraints affect the structure and properties of these networks. We will review the most recent empirical observations and the most important models of spatial networks. We will also discuss various processes which take place on these spatial networks, such as phase transitions, random walks, synchronization, navigation, resilience, and disease spread.</p></details> | <details><summary>Revie...</summary><p>Review article, revised and augmented version, 86 pages, 86 figures, 338 references</p></details> |
| **[Spatial Product Partition Models](https://arxiv.org/pdf/1504.04489v1)** | 2015-04-20 | [papers-cool](https://papers.cool/arxiv/1504.04489v1) | <details><summary>Show</summary><p>When modeling geostatistical or areal data, spatial structure is commonly accommodated via a covariance function for the former and a neighborhood structure for the latter. In both cases the resulting spatial structure is a consequence of implicit spatial grouping in that observations near in space are assumed to behave similarly. It would be desirable to develop spatial methods that explicitly model the partitioning of spatial locations providing more control over resulting spatial structures and being able to better balance global vs local spatial dependence. To this end, we extend product partition models to a spatial setting so that the partitioning of locations into spatially dependent clusters is explicitly modeled. We explore the spatial structures that result from employing a spatial product partition model and demonstrate its flexibility in accommodating many types of spatial dependencies. We illustrate the method's utility through simulation studies and an education application.</p></details> |  |
| **[A memory-free spatial additive mixed modeling for big spatial data](https://arxiv.org/pdf/1907.11369v2)** | 2019-10-15 | [papers-cool](https://papers.cool/arxiv/1907.11369v2) | <details><summary>Show</summary><p>This study develops a spatial additive mixed modeling (AMM) approach estimating spatial and non-spatial effects from large samples, such as millions of observations. Although fast AMM approaches are already well-established, they are restrictive in that they assume an known spatial dependence structure. To overcome this limitation, this study develops a fast AMM with the estimation of spatial structure in residuals and regression coefficients together with non-spatial effects. We rely on a Moran coefficient-based approach to estimate the spatial structure. The proposed approach pre-compresses large matrices whose size grows with respect to the sample size N before the model estimation; thus, the computational complexity for the estimation is independent of the sample size. Furthermore, the pre-compression is done through a block-wise procedure that makes the memory consumption independent of N. Eventually, the spatial AMM is memory-free and fast even for millions of observations. The developed approach is compared to alternatives through Monte Carlo simulation experiments. The result confirms the accuracy and computational efficiency of the developed approach. The developed approaches are implemented in an R package spmoran.</p></details> |  |
| **[Deep spatial context: when attention-based models meet spatial regression](https://arxiv.org/pdf/2401.10044v2)** | 2024-03-12 | [papers-cool](https://papers.cool/arxiv/2401.10044v2) | <details><summary>Show</summary><p>We propose 'Deep spatial context' (DSCon) method, which serves for investigation of the attention-based vision models using the concept of spatial context. It was inspired by histopathologists, however, the method can be applied to various domains. The DSCon allows for a quantitative measure of the spatial context's role using three Spatial Context Measures: $SCM_{features}$, $SCM_{targets}$, $SCM_{residuals}$ to distinguish whether the spatial context is observable within the features of neighboring regions, their target values (attention scores) or residuals, respectively. It is achieved by integrating spatial regression into the pipeline. The DSCon helps to verify research questions. The experiments reveal that spatial relationships are much bigger in the case of the classification of tumor lesions than normal tissues. Moreover, it turns out that the larger the size of the neighborhood taken into account within spatial regression, the less valuable contextual information is. Furthermore, it is observed that the spatial context measure is the largest when considered within the feature space as opposed to the targets and residuals.</p></details> |  |
| **[Spatial-DISE: A Unified Benchmark for Evaluating Spatial Reasoning in Vision-Language Models](https://arxiv.org/pdf/2510.13394v2)** | 2025-10-24 | [papers-cool](https://papers.cool/arxiv/2510.13394v2) | <details><summary>Show</summary><p>Spatial reasoning ability is crucial for Vision Language Models (VLMs) to support real-world applications in diverse domains including robotics, augmented reality, and autonomous navigation. Unfortunately, existing benchmarks are inadequate in assessing spatial reasoning ability, especially the \emph{intrinsic-dynamic} spatial reasoning which is a fundamental aspect of human spatial cognition. In this paper, we propose a unified benchmark, \textbf{Spatial-DISE}, based on a cognitively grounded taxonomy that categorizes tasks into four fundamental quadrants: \textbf{I}ntrinsic-\textbf{S}tatic, Intrinsic-\textbf{D}ynamic, \textbf{E}xtrinsic-Static, and Extrinsic-Dynamic spatial reasoning. Moreover, to address the issue of data scarcity, we develop a scalable and automated pipeline to generate diverse and verifiable spatial reasoning questions, resulting in a new \textbf{Spatial-DISE} dataset that includes Spatial-DISE Bench (559 evaluation VQA pairs) and Spatial-DISE-12K (12K+ training VQA pairs). Our comprehensive evaluation across 28 state-of-the-art VLMs reveals that, current VLMs have a large and consistent gap to human competence, especially on multi-step multi-view spatial reasoning. Spatial-DISE offers a robust framework, valuable dataset, and clear direction for future research toward human-like spatial intelligence. Benchmark, dataset, and code will be publicly released.</p></details> | <details><summary>Proje...</summary><p>Project Page: https://shinmohuang.github.io/spatialdise_page/</p></details> |
| **[Deep Spatial Domain Generalization](https://arxiv.org/pdf/2210.00729v2)** | 2022-12-29 | [papers-cool](https://papers.cool/arxiv/2210.00729v2) | <details><summary>Show</summary><p>Spatial autocorrelation and spatial heterogeneity widely exist in spatial data, which make the traditional machine learning model perform badly. Spatial domain generalization is a spatial extension of domain generalization, which can generalize to unseen spatial domains in continuous 2D space. Specifically, it learns a model under varying data distributions that generalizes to unseen domains. Although tremendous success has been achieved in domain generalization, there exist very few works on spatial domain generalization. The advancement of this area is challenged by: 1) Difficulty in characterizing spatial heterogeneity, and 2) Difficulty in obtaining predictive models for unseen locations without training data. To address these challenges, this paper proposes a generic framework for spatial domain generalization. Specifically, We develop the spatial interpolation graph neural network that handles spatial data as a graph and learns the spatial embedding on each node and their relationships. The spatial interpolation graph neural network infers the spatial embedding of an unseen location during the test phase. Then the spatial embedding of the target location is used to decode the parameters of the downstream-task model directly on the target location. Finally, extensive experiments on thirteen real-world datasets demonstrate the proposed method's strength.</p></details> |  |
| **[A Survey on Spatial Co-location Patterns Discovery from Spatial Datasets](https://arxiv.org/pdf/1402.1327v1)** | 2014-02-07 | [papers-cool](https://papers.cool/arxiv/1402.1327v1) | <details><summary>Show</summary><p>Spatial data mining or Knowledge discovery in spatial database is the extraction of implicit knowledge, spatial relations and spatial patterns that are not explicitly stored in databases. Co-location patterns discovery is the process of finding the subsets of features that are frequently located together in the same geographic area. In this paper, we discuss the different approaches like Rule based approach, Join-less approach, Partial Join approach and Constraint neighborhood based approach for finding co-location patterns.</p></details> | 6 pages,8 figures |
| **[Spatial Transformer Networks](https://arxiv.org/pdf/1506.02025v3)** | 2016-02-05 | [papers-cool](https://papers.cool/arxiv/1506.02025v3) | <details><summary>Show</summary><p>Convolutional Neural Networks define an exceptionally powerful class of models, but are still limited by the lack of ability to be spatially invariant to the input data in a computationally and parameter efficient manner. In this work we introduce a new learnable module, the Spatial Transformer, which explicitly allows the spatial manipulation of data within the network. This differentiable module can be inserted into existing convolutional architectures, giving neural networks the ability to actively spatially transform feature maps, conditional on the feature map itself, without any extra training supervision or modification to the optimisation process. We show that the use of spatial transformers results in models which learn invariance to translation, scale, rotation and more generic warping, resulting in state-of-the-art performance on several benchmarks, and for a number of classes of transformations.</p></details> |  |
| **[SIRI: Spatial Relation Induced Network For Spatial Description Resolution](https://arxiv.org/pdf/2010.14301v1)** | 2020-10-28 | [papers-cool](https://papers.cool/arxiv/2010.14301v1) | <details><summary>Show</summary><p>Spatial Description Resolution, as a language-guided localization task, is proposed for target location in a panoramic street view, given corresponding language descriptions. Explicitly characterizing an object-level relationship while distilling spatial relationships are currently absent but crucial to this task. Mimicking humans, who sequentially traverse spatial relationship words and objects with a first-person view to locate their target, we propose a novel spatial relationship induced (SIRI) network. Specifically, visual features are firstly correlated at an implicit object-level in a projected latent space; then they are distilled by each spatial relationship word, resulting in each differently activated feature representing each spatial relationship. Further, we introduce global position priors to fix the absence of positional information, which may result in global positional reasoning ambiguities. Both the linguistic and visual features are concatenated to finalize the target localization. Experimental results on the Touchdown show that our method is around 24\% better than the state-of-the-art method in terms of accuracy, measured by an 80-pixel radius. Our method also generalizes well on our proposed extended dataset collected using the same settings as Touchdown.</p></details> | <details><summary>Accep...</summary><p>Accepted at NeurIPS 2020; Peiyao Wang and Weixin Luo made equal contribution</p></details> |
| **[Spatially-clustered spatial autoregressive models with application to agricultural market concentration in Europe](https://arxiv.org/pdf/2407.15874v1)** | 2025-01-09 | [papers-cool](https://papers.cool/arxiv/2407.15874v1) | <details><summary>Show</summary><p>In this paper, we present an extension of the spatially-clustered linear regression models, namely, the spatially-clustered spatial autoregression (SCSAR) model, to deal with spatial heterogeneity issues in clustering procedures. In particular, we extend classical spatial econometrics models, such as the spatial autoregressive model, the spatial error model, and the spatially-lagged model, by allowing the regression coefficients to be spatially varying according to a cluster-wise structure. Cluster memberships and regression coefficients are jointly estimated through a penalized maximum likelihood algorithm which encourages neighboring units to belong to the same spatial cluster with shared regression coefficients. Motivated by the increase of observed values of the Gini index for the agricultural production in Europe between 2010 and 2020, the proposed methodology is employed to assess the presence of local spatial spillovers on the market concentration index for the European regions in the last decade. Empirical findings support the hypothesis of fragmentation of the European agricultural market, as the regions can be well represented by a clustering structure partitioning the continent into three-groups, roughly approximated by a division among Western, North Central and Southeastern regions. Also, we detect heterogeneous local effects induced by the selected explanatory variables on the regional market concentration. In particular, we find that variables associated with social, territorial and economic relevance of the agricultural sector seem to act differently throughout the spatial dimension, across the clusters and with respect to the pooled model, and temporal dimension.</p></details> |  |
| **[A spatial dependence graph model for multivariate spatial hybrid processes](https://arxiv.org/pdf/1906.07798v1)** | 2019-06-20 | [papers-cool](https://papers.cool/arxiv/1906.07798v1) | <details><summary>Show</summary><p>This paper is concerned with the joint analysis of multivariate mixed-type spatial data, where some components are point processes and some are of lattice-type by nature. After a survey of statistical methods for marked spatial point and lattice processes, the class of multivariate spatial hybrid processes is defined and embedded within the framework of spatial dependence graph models. In this model, the point and lattice sub-processes are identified with nodes of a graph whereas missing edges represent conditional independence among the components. This finally leads to a general framework for any type of spatial data in a multivariate setting. We demonstrate the application of our method in the analysis of a multivariate point-lattice pattern on crime and ambulance service call-out incidents recorded in London, where the points are the locations of different pre-classified crime events and the lattice components report different aggregated incident rates at ward level.</p></details> | <details><summary>Submi...</summary><p>Submitted for publication</p></details> |
| **[Spatial 3D-LLM: Exploring Spatial Awareness in 3D Vision-Language Models](https://arxiv.org/pdf/2507.16524v1)** | 2025-07-23 | [papers-cool](https://papers.cool/arxiv/2507.16524v1) | <details><summary>Show</summary><p>New era has unlocked exciting possibilities for extending Large Language Models (LLMs) to tackle 3D vision-language tasks. However, most existing 3D multimodal LLMs (MLLMs) rely on compressing holistic 3D scene information or segmenting independent objects to perform these tasks, which limits their spatial awareness due to insufficient representation of the richness inherent in 3D scenes. To overcome these limitations, we propose Spatial 3D-LLM, a 3D MLLM specifically designed to enhance spatial awareness for 3D vision-language tasks by enriching the spatial embeddings of 3D scenes. Spatial 3D-LLM integrates an LLM backbone with a progressive spatial awareness scheme that progressively captures spatial information as the perception field expands, generating location-enriched 3D scene embeddings to serve as visual prompts. Furthermore, we introduce two novel tasks: 3D object distance measurement and 3D layout editing, and construct a 3D instruction dataset, MODEL, to evaluate the model's spatial awareness capabilities. Experimental results demonstrate that Spatial 3D-LLM achieves state-of-the-art performance across a wide range of 3D vision-language tasks, revealing the improvements stemmed from our progressive spatial awareness scheme of mining more profound spatial information. Our code is available at https://github.com/bjshuyuan/Spatial-3D-LLM.</p></details> | Accepted by ICME2025 |
| **[Nonstationary Spatial Process Models with Spatially Varying Covariance Kernels](https://arxiv.org/pdf/2203.11873v4)** | 2025-07-01 | [papers-cool](https://papers.cool/arxiv/2203.11873v4) | <details><summary>Show</summary><p>Building spatial process models that capture nonstationary behavior while delivering computationally efficient inference is challenging. Nonstationary spatially varying kernels (see, e.g., Paciorek, 2003) offer flexibility and richness, but computation is impeded by high-dimensional parameter spaces resulting from spatially varying process parameters. Matters are exacerbated if the number of locations recording measurements is massive. With limited theoretical tractability, obviating computational bottlenecks requires synergy between model construction and algorithm development. We build a class of scalable nonstationary spatial process models using spatially varying covariance kernels. We implement a Bayesian modeling framework using Hybrid Monte Carlo with nested interweaving. We conduct experiments on synthetic data sets to explore model selection and parameter identifiability, and assess inferential improvements accrued from nonstationary modeling. We illustrate strengths and pitfalls with a data set on remote sensed normalized difference vegetation index.</p></details> |  |
| **[DeepKriging: Spatially Dependent Deep Neural Networks for Spatial Prediction](https://arxiv.org/pdf/2007.11972v4)** | 2022-05-25 | [papers-cool](https://papers.cool/arxiv/2007.11972v4) | <details><summary>Show</summary><p>In spatial statistics, a common objective is to predict values of a spatial process at unobserved locations by exploiting spatial dependence. Kriging provides the best linear unbiased predictor using covariance functions and is often associated with Gaussian processes. However, when considering non-linear prediction for non-Gaussian and categorical data, the Kriging prediction is no longer optimal, and the associated variance is often overly optimistic. Although deep neural networks (DNNs) are widely used for general classification and prediction, they have not been studied thoroughly for data with spatial dependence. In this work, we propose a novel DNN structure for spatial prediction, where the spatial dependence is captured by adding an embedding layer of spatial coordinates with basis functions. We show in theory and simulation studies that the proposed DeepKriging method has a direct link to Kriging in the Gaussian case, and it has multiple advantages over Kriging for non-Gaussian and non-stationary data, i.e., it provides non-linear predictions and thus has smaller approximation errors, it does not require operations on covariance matrices and thus is scalable for large datasets, and with sufficiently many hidden neurons, it provides the optimal prediction in terms of model capacity. We further explore the possibility of quantifying prediction uncertainties based on density prediction without assuming any data distribution. Finally, we apply the method to predicting PM2.5 concentrations across the continental United States.</p></details> |  |
| **[Spatial Object Recommendation with Hints: When Spatial Granularity Matters](https://arxiv.org/pdf/2101.02969v1)** | 2021-01-11 | [papers-cool](https://papers.cool/arxiv/2101.02969v1) | <details><summary>Show</summary><p>Existing spatial object recommendation algorithms generally treat objects identically when ranking them. However, spatial objects often cover different levels of spatial granularity and thereby are heterogeneous. For example, one user may prefer to be recommended a region (say Manhattan), while another user might prefer a venue (say a restaurant). Even for the same user, preferences can change at different stages of data exploration. In this paper, we study how to support top-k spatial object recommendations at varying levels of spatial granularity, enabling spatial objects at varying granularity, such as a city, suburb, or building, as a Point of Interest (POI). To solve this problem, we propose the use of a POI tree, which captures spatial containment relationships between POIs. We design a novel multi-task learning model called MPR (short for Multi-level POI Recommendation), where each task aims to return the top-k POIs at a certain spatial granularity level. Each task consists of two subtasks: (i) attribute-based representation learning; (ii) interaction-based representation learning. The first subtask learns the feature representations for both users and POIs, capturing attributes directly from their profiles. The second subtask incorporates user-POI interactions into the model. Additionally, MPR can provide insights into why certain recommendations are being made to a user based on three types of hints: user-aspect, POI-aspect, and interaction-aspect. We empirically validate our approach using two real-life datasets, and show promising performance improvements over several state-of-the-art methods.</p></details> |  |
| **[Assessing the performance of spatial cross-validation approaches for models of spatially structured data](https://arxiv.org/pdf/2303.07334v1)** | 2023-03-14 | [papers-cool](https://papers.cool/arxiv/2303.07334v1) | <details><summary>Show</summary><p>Evaluating models fit to data with internal spatial structure requires specific cross-validation (CV) approaches, because randomly selecting assessment data may produce assessment sets that are not truly independent of data used to train the model. Many spatial CV methodologies have been proposed to address this by forcing models to extrapolate spatially when predicting the assessment set. However, to date there exists little guidance on which methods yield the most accurate estimates of model performance. We conducted simulations to compare model performance estimates produced by five common CV methods fit to spatially structured data. We found spatial CV approaches generally improved upon resubstitution and V-fold CV estimates, particularly when approaches which combined assessment sets of spatially conjunct observations with spatial exclusion buffers. To facilitate use of these techniques, we introduce the `spatialsample` package which provides tooling for performing spatial CV as part of the broader tidymodels modeling framework.</p></details> | <details><summary>18 pa...</summary><p>18 pages, 6 figures, 5 tables. Submitted to Environmental Modelling & Software</p></details> |
| **[Random Spatial Forests](https://arxiv.org/pdf/2006.00150v2)** | 2020-07-24 | [papers-cool](https://papers.cool/arxiv/2006.00150v2) | <details><summary>Show</summary><p>We introduce random spatial forests, a method of bagging regression trees allowing for spatial correlation. Our main contribution is the development of a computationally efficient tree building algorithm which selects each split of the tree adjusting for spatial correlation. We evaluate two different approaches for estimation of random spatial forests, a pseudo-likelihood approach combining random forests with kriging and a non-parametric version for a general class of spatial smoothers. We show improved prediction accuracy of our method compared to existing two-step approaches combining random forests and kriging across a range of numerical simulations and demonstrate its performance on elemental carbon, organic carbon, silicon, and sulfur measurements across the continental United States from 2009-2010.</p></details> |  |
| **[The Importance of Scale for Spatial-Confounding Bias and Precision of Spatial Regression Estimators](https://arxiv.org/pdf/1011.1139v1)** | 2010-11-05 | [papers-cool](https://papers.cool/arxiv/1011.1139v1) | <details><summary>Show</summary><p>Residuals in regression models are often spatially correlated. Prominent examples include studies in environmental epidemiology to understand the chronic health effects of pollutants. I consider the effects of residual spatial structure on the bias and precision of regression coefficients, developing a simple framework in which to understand the key issues and derive informative analytic results. When unmeasured confounding introduces spatial structure into the residuals, regression models with spatial random effects and closely-related models such as kriging and penalized splines are biased, even when the residual variance components are known. Analytic and simulation results show how the bias depends on the spatial scales of the covariate and the residual: one can reduce bias by fitting a spatial model only when there is variation in the covariate at a scale smaller than the scale of the unmeasured confounding. I also discuss how the scales of the residual and the covariate affect efficiency and uncertainty estimation when the residuals are independent of the covariate. In an application on the association between black carbon particulate matter air pollution and birth weight, controlling for large-scale spatial variation appears to reduce bias from unmeasured confounders, while increasing uncertainty in the estimated pollution effect.</p></details> | <details><summary>Publi...</summary><p>Published in at http://dx.doi.org/10.1214/10-STS326 the Statistical Science (http://www.imstat.org/sts/) by the Institute of Mathematical Statistics (http://www.imstat.org)</p></details> |
| **[Balancing spatial and non-spatial variation in varying coefficient modeling: a remedy for spurious correlation](https://arxiv.org/pdf/2005.09981v2)** | 2021-05-31 | [papers-cool](https://papers.cool/arxiv/2005.09981v2) | <details><summary>Show</summary><p>This study discusses the importance of balancing spatial and non-spatial variation in spatial regression modeling. Unlike spatially varying coefficients (SVC) modeling, which is popular in spatial statistics, non-spatially varying coefficients (NVC) modeling has largely been unexplored in spatial fields. Nevertheless, as we will explain, consideration of non-spatial variation is needed not only to improve model accuracy but also to reduce spurious correlation among varying coefficients, which is a major problem in SVC modeling. We consider a Moran eigenvector approach modeling spatially and non-spatially varying coefficients (S&NVC). A Monte Carlo simulation experiment comparing our S&NVC model with existing SVC models suggests both modeling accuracy and computational efficiency for our approach. Beyond that, somewhat surprisingly, our approach identifies true and spurious correlations among coefficients nearly perfectly, even when usual SVC models suffer from severe spurious correlations. It implies that S&NVC model should be used even when the analysis purpose is modeling SVCs. Finally, our S&NVC model is employed to analyze a residential land price dataset. Its results suggest existence of both spatial and non-spatial variation in regression coefficients in practice. The S&NVC model is now implemented in the R package spmoran.</p></details> |  |
| **[Spatial Cluster-based Copula Model to Interpolate Skewed Conditional Spatial Random Field](https://arxiv.org/pdf/2205.13024v1)** | 2022-05-27 | [papers-cool](https://papers.cool/arxiv/2205.13024v1) | <details><summary>Show</summary><p>Interpolating a skewed conditional spatial random field with missing data is cumbersome in the absence of Gaussianity assumptions. Maintaining spatial homogeneity and continuity around the observed random spatial point is also challenging, especially when interpolating along a spatial surface, focusing on the boundary points as a neighborhood. Otherwise, the point far away from one may appear the closest to another. As a result, importing the hierarchical clustering concept on the spatial random field is as convenient as developing the copula with the interface of the Expectation-Maximization algorithm and concurrently utilizing the idea of the Bayesian framework. This paper introduces a spatial cluster-based C-vine copula and a modified Gaussian kernel to derive a novel spatial probability distribution. Another investigation in this paper uses an algorithm in conjunction with a different parameter estimation technique to make spatial-based copula interpolation more compatible and efficient. We apply the proposed spatial interpolation approach to the air pollution of Delhi as a crucial circumstantial study to demonstrate this newly developed novel spatial estimation technique.</p></details> |  |
| **[Dimension Reduction for Spatially Correlated Data: Spatial Predictor Envelope](https://arxiv.org/pdf/2201.01919v1)** | 2022-01-07 | [papers-cool](https://papers.cool/arxiv/2201.01919v1) | <details><summary>Show</summary><p>Dimension reduction is an important tool for analyzing high-dimensional data. The predictor envelope is a method of dimension reduction for regression that assumes certain linear combinations of the predictors are immaterial to the regression. The method can result in substantial gains in estimation efficiency and prediction accuracy over traditional maximum likelihood and least squares estimates. While predictor envelopes have been developed and studied for independent data, no work has been done adapting predictor envelopes to spatial data. In this work, the predictor envelope is adapted to a popular spatial model to form the spatial predictor envelope (SPE). Maximum likelihood estimates for the SPE are derived, along with asymptotic distributions for the estimates given certain assumptions, showing the SPE estimates to be asymptotically more efficient than estimates of the original spatial model. The effectiveness of the proposed model is illustrated through simulation studies and the analysis of a geo-chemical data set.</p></details> |  |
| **[Measuring spatial association and testing spatial independence based on short time course data](https://arxiv.org/pdf/2303.16824v2)** | 2023-09-26 | [papers-cool](https://papers.cool/arxiv/2303.16824v2) | <details><summary>Show</summary><p>Spatial association measures for univariate static spatial data are widely used. When the data is in the form of a collection of spatial vectors with the same temporal domain of interest, we construct a measure of similarity between the regions' series, using Bergsma's correlation coefficient $$. Due to the special properties of $$, unlike other spatial association measures which test for spatial randomness, our statistic can account for spatial pairwise independence. We have derived the asymptotic behavior of our statistic under null (independence of the regions) and alternate cases (the regions are dependent). We explore the alternate scenario of spatial dependence further, using simulations for the SAR and SMA dependence models. Finally, we provide application to modelling and testing for the presence of spatial association in COVID-19 incidence data, by using our statistic on the residuals obtained after model fitting.</p></details> | <details><summary>Keywo...</summary><p>Keywords: Bergsma's correlation, spatial association measure, U-statistic, spatial autoregressive model, spatial moving average model</p></details> |
| **[Spatialize v1.0: A Python/C++ Library for Ensemble Spatial Interpolation](https://arxiv.org/pdf/2507.17867v2)** | 2025-07-29 | [papers-cool](https://papers.cool/arxiv/2507.17867v2) | <details><summary>Show</summary><p>In this paper, we present Spatialize, an open-source library that implements ensemble spatial interpolation, a novel method that combines the simplicity of basic interpolation methods with the power of classical geostatistical tools, like Kriging. It leverages the richness of stochastic modelling and ensemble learning, making it robust, scalable and suitable for large datasets. In addition, Spatialize provides a powerful framework for uncertainty quantification, offering both point estimates and empirical posterior distributions. It is implemented in Python 3.x, with a C++ core for improved performance, and is designed to be easy to use, requiring minimal user intervention. This library aims to bridge the gap between expert and non-expert users of geostatistics by providing automated tools that rival traditional geostatistical methods. Here, we present a detailed description of Spatialize along with a wealth of examples of its use.</p></details> |  |
| **[Bayesian Spatial Binary Classification](https://arxiv.org/pdf/1406.3647v4)** | 2016-01-11 | [papers-cool](https://papers.cool/arxiv/1406.3647v4) | <details><summary>Show</summary><p>In analyses of spatially-referenced data, researchers often have one of two goals: to quantify relationships between a response variable and covariates while accounting for residual spatial dependence or to predict the value of a response variable at unobserved locations. In this second case, when the response variable is categorical, prediction can be viewed as a classification problem. Many classification methods either ignore response-variable/covariate relationships and rely only on spatially proximate observations for classification, or they ignore spatial dependence and use only the covariates for classification. The Bayesian spatial generalized linear (mixed) model offers a tool to accommodate both spatial and covariate sources of information in classification problems. In this paper, we formally define spatial classification rules based on these models. We also take a close look at two of these models that have been proposed in the literature, namely the probit versions of the spatial generalized linear model (SGLM) and the Bayesian spatial generalized linear mixed model (SGLMM). We describe the implications of the seemingly slight differences between these models for spatial classification and explore the issue of robustness to model misspecification through a simulation study. We also provide an overview of alternatives to the SGLM/SGLMM-based classifiers and illustrate the various methods using satellite-derived land cover data from Southeast Asia.</p></details> |  |
| **[Spatial Reasoning in Foundation Models: Benchmarking Object-Centric Spatial Understanding](https://arxiv.org/pdf/2509.21922v1)** | 2025-09-29 | [papers-cool](https://papers.cool/arxiv/2509.21922v1) | <details><summary>Show</summary><p>Spatial understanding is a critical capability for vision foundation models. While recent advances in large vision models or vision-language models (VLMs) have expanded recognition capabilities, most benchmarks emphasize localization accuracy rather than whether models capture how objects are arranged and related within a scene. This gap is consequential; effective scene understanding requires not only identifying objects, but reasoning about their relative positions, groupings, and depth. In this paper, we present a systematic benchmark for object-centric spatial reasoning in foundation models. Using a controlled synthetic dataset, we evaluate state-of-the-art vision models (e.g., GroundingDINO, Florence-2, OWLv2) and large VLMs (e.g., InternVL, LLaVA, GPT-4o) across three tasks: spatial localization, spatial reasoning, and downstream retrieval tasks. We find a stable trade-off: detectors such as GroundingDINO and OWLv2 deliver precise boxes with limited relational reasoning, while VLMs like SmolVLM and GPT-4o provide coarse layout cues and fluent captions but struggle with fine-grained spatial context. Our study highlights the gap between localization and true spatial understanding, and pointing toward the need for spatially-aware foundation models in the community.</p></details> | <details><summary>4 pag...</summary><p>4 pages, NeurIPS Workshop SpaVLE</p></details> |
| **[Generic Multimodal Spatially Graph Network for Spatially Embedded Network Representation Learning](https://arxiv.org/pdf/2502.00530v1)** | 2025-02-04 | [papers-cool](https://papers.cool/arxiv/2502.00530v1) | <details><summary>Show</summary><p>Spatially embedded networks (SENs) represent a special type of complex graph, whose topologies are constrained by the networks' embedded spatial environments. The graph representation of such networks is thereby influenced by the embedded spatial features of both nodes and edges. Accurate network representation of the graph structure and graph features is a fundamental task for various graph-related tasks. In this study, a Generic Multimodal Spatially Graph Convolutional Network (GMu-SGCN) is developed for efficient representation of spatially embedded networks. The developed GMu-SGCN model has the ability to learn the node connection pattern via multimodal node and edge features. In order to evaluate the developed model, a river network dataset and a power network dataset have been used as test beds. The river network represents the naturally developed SENs, whereas the power network represents a man-made network. Both types of networks are heavily constrained by the spatial environments and uncertainties from nature. Comprehensive evaluation analysis shows the developed GMu-SGCN can improve accuracy of the edge existence prediction task by 37.1\% compared to a GraphSAGE model which only considers the node's position feature in a power network test bed. Our model demonstrates the importance of considering the multidimensional spatial feature for spatially embedded network representation.</p></details> |  |
| **[Large-scale spatial variable gene atlas for spatial transcriptomics](https://arxiv.org/pdf/2510.07653v2)** | 2025-10-21 | [papers-cool](https://papers.cool/arxiv/2510.07653v2) | <details><summary>Show</summary><p>Spatial variable genes (SVGs) reveal critical information about tissue architecture, cellular interactions, and disease microenvironments. As spatial transcriptomics (ST) technologies proliferate, accurately identifying SVGs across diverse platforms, tissue types, and disease contexts has become both a major opportunity and a significant computational challenge. Here, we present a comprehensive benchmarking study of 20 state-of-the-art SVG detection methods using human slides from STimage-1K4M, a large-scale resource of ST data comprising 662 slides from more than 18 tissue types. We evaluate each method across a range of biologically and technically meaningful criteria, including recovery of pathologist-annotated domain-specific markers, cross-slide reproducibility, scalability to high-resolution data, and robustness to technical variation. Our results reveal marked differences in performance depending on tissue type, spatial resolution, and study design. Beyond benchmarking, we construct the first cross-tissue atlas of SVGs, enabling comparative analysis of spatial gene programs across cancer and normal tissues. We observe similarities between pairs of tissues that reflect developmental and functional relationships, such as high overlap between thymus and lymph node, and uncover spatial gene programs associated with metastasis, immune infiltration, and tissue-of-origin identity in cancer. Together, our work defines a framework for evaluating and interpreting spatial gene expression and establishes a reference resource for the ST community.</p></details> |  |
| **[Spatial Orchestra: Locomotion Music Instruments through Spatial Exploration](https://arxiv.org/pdf/2510.23848v1)** | 2025-10-29 | [papers-cool](https://papers.cool/arxiv/2510.23848v1) | <details><summary>Show</summary><p>Spatial Orchestra demonstrates how easy it is to play musical instruments using basic input like natural locomotion, which is accessible to most. Unlike many musical instruments, our work allows individuals of all skill levels to effortlessly create music by walking into virtual bubbles. Our Augmented Reality experience involves interacting with ever-shifting sound bubbles that the user engages with by stepping into color-coded bubbles within the assigned area using a standalone AR headset. Each bubble corresponds to a cello note, and omits sound from the center of the bubble, and lets the user hear and express in spatial audio, effectively transforming participants into musicians. This interactive element enables users to explore the intersection of spatial awareness, musical rhythm that extends to bodily expression through playful movements and dance-like gestures within the bubble-filled environment. This unique experience illuminates the intricate relationship between spatial awareness and the art of musical performance.</p></details> | <details><summary>Exten...</summary><p>Extended Abstracts (Interactivity), 5 pages. Published at the 2024 CHI Conference on Human Factors in Computing Systems</p></details> |
| **[Spatial-Slepian Transform on the Sphere](https://arxiv.org/pdf/2010.07266v1)** | 2021-09-01 | [papers-cool](https://papers.cool/arxiv/2010.07266v1) | <details><summary>Show</summary><p>We present spatial-Slepian transform~(SST) for the representation of signals on the sphere to support localized signal analysis. We use well-optimally concentrated Slepian functions, obtained by solving the Slepian spatial-spectral concentration problem of finding bandlimited and spatially optimally concentrated functions on the sphere, to formulate the proposed transform and obtain the joint spatial-Slepian domain representation of the signal. Due to the optimal energy concentration of the Slepian functions in the spatial domain, the proposed spatial-Slepian transform allows us to probe spatially localized content of the signal. Furthermore, we present an inverse transform to recover the signal from the spatial-Slepian coefficients, and show that well-optimally concentrated rotated Slepian functions form a tight frame on the sphere. We develop an algorithm for the fast computation of the spatial-Slepian transform and carry out computational complexity analysis. We present the formulation of SST for zonal Slepian functions, which are spatially optimally concentrated in the polar cap~(axisymmetric) region, and provide an illustration using the Earth topography map. To demonstrate the utility of the proposed transform, we carry out localized variation analysis; employing SST for detecting hidden localized variations in the signal.</p></details> | 10 pages |
| **[Spatial-SSRL: Enhancing Spatial Understanding via Self-Supervised Reinforcement Learning](https://arxiv.org/pdf/2510.27606v1)** | 2025-11-03 | [papers-cool](https://papers.cool/arxiv/2510.27606v1) | <details><summary>Show</summary><p>Spatial understanding remains a weakness of Large Vision-Language Models (LVLMs). Existing supervised fine-tuning (SFT) and recent reinforcement learning with verifiable rewards (RLVR) pipelines depend on costly supervision, specialized tools, or constrained environments that limit scale. We introduce Spatial-SSRL, a self-supervised RL paradigm that derives verifiable signals directly from ordinary RGB or RGB-D images. Spatial-SSRL automatically formulates five pretext tasks that capture 2D and 3D spatial structure: shuffled patch reordering, flipped patch recognition, cropped patch inpainting, regional depth ordering, and relative 3D position prediction. These tasks provide ground-truth answers that are easy to verify and require no human or LVLM annotation. Training on our tasks substantially improves spatial reasoning while preserving general visual capabilities. On seven spatial understanding benchmarks in both image and video settings, Spatial-SSRL delivers average accuracy gains of 4.63% (3B) and 3.89% (7B) over the Qwen2.5-VL baselines. Our results show that simple, intrinsic supervision enables RLVR at scale and provides a practical route to stronger spatial intelligence in LVLMs.</p></details> | preprint |
| **[Spatial CAPTCHA: Generatively Benchmarking Spatial Reasoning for Human-Machine Differentiation](https://arxiv.org/pdf/2510.03863v1)** | 2025-10-07 | [papers-cool](https://papers.cool/arxiv/2510.03863v1) | <details><summary>Show</summary><p>Online services rely on CAPTCHAs as a first line of defense against automated abuse, yet recent advances in multi-modal large language models (MLLMs) have eroded the effectiveness of conventional designs that focus on text recognition or 2D image understanding. To address this challenge, we present Spatial CAPTCHA, a novel human-verification framework that leverages fundamental differences in spatial reasoning between humans and MLLMs. Unlike existing CAPTCHAs which rely on low-level perception tasks that are vulnerable to modern AI, Spatial CAPTCHA generates dynamic questions requiring geometric reasoning, perspective-taking, occlusion handling, and mental rotation. These skills are intuitive for humans but difficult for state-of-the-art (SOTA) AI systems. The system employs a procedural generation pipeline with constraint-based difficulty control, automated correctness verification, and human-in-the-loop validation to ensure scalability, robustness, and adaptability. Evaluation on a corresponding benchmark, Spatial-CAPTCHA-Bench, demonstrates that humans vastly outperform 10 state-of-the-art MLLMs, with the best model achieving only 31.0% Pass@1 accuracy. Furthermore, we compare Spatial CAPTCHA with Google reCAPTCHA, which confirms its effectiveness as both a security mechanism and a diagnostic tool for spatial reasoning in AI.</p></details> | <details><summary>Submi...</summary><p>Submitted to ICLR 2026</p></details> |
| **[Spatial Modulation- Spatial Multiplexing in Massive MIMO](https://arxiv.org/pdf/1605.02969v1)** | 2016-05-11 | [papers-cool](https://papers.cool/arxiv/1605.02969v1) | <details><summary>Show</summary><p>Massive MIMO, a candidate for 5G technology, promises significant gains in wireless data rates and link reliability by using large numbers of antennas (more than 64) at the base transceiver station (BTS). Extra antennas help by focusing the transmission and reception of signal energy into ever-smaller regions of space. This brings huge improvements in throughput. However, it requires a large number of Radio Frequency (RF) chains (usually equal to number of transmit antennas), which is a major drawback. One approach to overcome these issues is to use Spatial Modulation (SM). In SM, an index of transmit antenna is used as an additional source of information to improve the overall spectral efficiency. In particular, a group of any number of information bits is mapped into two constellations: a signal constellation based on modulation scheme and a spatial constellation to encode the index of the transmit antenna. However, a low spectral efficiency is main drawback of SM. Therefore, a combination of SM with Spatial Multiplexing is an effective way to increase spectral efficiency with limited number of RF chains.</p></details> |  |
| **[Exploiting spatial information with the informed complex-valued spatial autoencoder for target speaker extraction](https://arxiv.org/pdf/2210.15512v2)** | 2023-06-13 | [papers-cool](https://papers.cool/arxiv/2210.15512v2) | <details><summary>Show</summary><p>In conventional multichannel audio signal enhancement, spatial and spectral filtering are often performed sequentially. In contrast, it has been shown that for neural spatial filtering a joint approach of spectro-spatial filtering is more beneficial. In this contribution, we investigate the spatial filtering performed by such a time-varying spectro-spatial filter. We extend the recently proposed complex-valued spatial autoencoder (COSPA) for the task of target speaker extraction by leveraging its interpretable structure and purposefully informing the network of the target speaker's position. We show that the resulting informed COSPA (iCOSPA) effectively and flexibly extracts a target speaker from a mixture of speakers. We also find that the proposed architecture is well capable of learning pronounced spatial selectivity patterns and show that the results depend significantly on the training target and the reference signal when computing various evaluation metrics.</p></details> | <details><summary>Accep...</summary><p>Accepted to 2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), Rhodes Island, Greece. 5 pages, 2 figures</p></details> |
| **[Bayesian Spatial Predictive Synthesis](https://arxiv.org/pdf/2203.05197v4)** | 2025-01-28 | [papers-cool](https://papers.cool/arxiv/2203.05197v4) | <details><summary>Show</summary><p>Due to spatial dependence -- often characterized as complex and non-linear -- model misspecification is a prevalent and critical issue in spatial data analysis and prediction. As the data, and thus model performance, is heterogeneous, typical model selection and ensemble methods that assume homogeneity are not suitable. We address the issue of model uncertainty for spatial data by proposing a novel Bayesian ensemble methodology that captures spatially-varying model uncertainty and performance heterogeneity of multiple spatial predictions, and synthesizes them for improved predictions, which we call Bayesian spatial predictive synthesis. Our proposal is defined by specifying a latent factor spatially-varying coefficient model as the synthesis function, which enables spatial characteristics of each model to be learned and ensemble coefficients to vary over regions to achieve flexible predictions. We derive our method from the theoretically best approximation of the data generating process, and show that it provides a finite sample theoretical guarantee for its predictive performance, specifically that the predictions are exact minimax. Two MCMC strategies are implemented for full uncertainty quantification, as well as a variational inference strategy for fast point inference. We also extend the estimation strategy for general responses. Through simulation examples and two real data applications in real estate and ecology, our proposed Bayesian spatial predictive synthesis outperforms standard spatial models and ensemble methods, and advanced machine learning methods, in terms of predictive accuracy and uncertainty quantification, while maintaining interpretability of the prediction mechanism.</p></details> | <details><summary>31 pa...</summary><p>31 pages (main) + 15 pages (supplementary material)</p></details> |
| **[Causal Spatial Quantile Regression](https://arxiv.org/pdf/2509.02294v1)** | 2025-09-03 | [papers-cool](https://papers.cool/arxiv/2509.02294v1) | <details><summary>Show</summary><p>Treatment effects in a wide range of economic, environmental, and epidemiological applications often vary across space, and understanding the heterogeneity of causal effects across space and outcome quantiles is a critical challenge in spatial causal inference. To effectively capture spatial heterogeneity in distributional treatment effects, we propose a novel semiparametric neural network-based causal framework leveraging deep spatial quantile regression and then construct a plug-in estimator for spatial quantile treatment effects (SQTE). This framework incorporates an efficient adjustment procedure to mitigate the impact of spatial hidden confounders. Extensive simulations across various scenarios demonstrate that our methodology can accurately estimate SQTE, even with the presence of spatial hidden confounders. Additionally, the spatial confounding adjustment procedure effectively reduces neighborhood spatial patterns in the residuals. We apply this method to assess the spatially varying quantile treatment effects of maternal smoking on newborn birth weight in North Carolina, United States. Our findings consistently show negative effects across all birth weight quantiles, with particularly severe impacts observed in the lower quantile regions.</p></details> |  |
| **[Fast Spatial Autocorrelation](https://arxiv.org/pdf/2010.08676v1)** | 2020-10-20 | [papers-cool](https://papers.cool/arxiv/2010.08676v1) | <details><summary>Show</summary><p>Physical or geographic location proves to be an important feature in many data science models, because many diverse natural and social phenomenon have a spatial component. Spatial autocorrelation measures the extent to which locally adjacent observations of the same phenomenon are correlated. Although statistics like Moran's $I$ and Geary's $C$ are widely used to measure spatial autocorrelation, they are slow: all popular methods run in $(n^2)$ time, rendering them unusable for large data sets, or long time-courses with moderate numbers of points. We propose a new $S_A$ statistic based on the notion that the variance observed when merging pairs of nearby clusters should increase slowly for spatially autocorrelated variables. We give a linear-time algorithm to calculate $S_A$ for a variable with an input agglomeration order (available at https://github.com/aamgalan/spatial_autocorrelation). For a typical dataset of $n \approx 63,000$ points, our $S_A$ autocorrelation measure can be computed in 1 second, versus 2 hours or more for Moran's $I$ and Geary's $C$. Through simulation studies, we demonstrate that $S_A$ identifies spatial correlations in variables generated with spatially-dependent model half an order of magnitude earlier than either Moran's $I$ or Geary's $C$. Finally, we prove several theoretical properties of $S_A$: namely that it behaves as a true correlation statistic, and is invariant under addition or multiplication by a constant.</p></details> | <details><summary>To be...</summary><p>To be published in ICDM 2020</p></details> |
| **[AI's Spatial Intelligence: Evaluating AI's Understanding of Spatial Transformations in PSVT:R and Augmented Reality](https://arxiv.org/pdf/2411.06269v4)** | 2025-03-18 | [papers-cool](https://papers.cool/arxiv/2411.06269v4) | <details><summary>Show</summary><p>Spatial intelligence is important in Architecture, Construction, Science, Technology, Engineering, and Mathematics (STEM), and Medicine. Understanding three-dimensional (3D) spatial rotations can involve verbal descriptions and visual or interactive examples, illustrating how objects change orientation in 3D space. Recent studies show Artificial Intelligence (AI) with language and vision capabilities still face limitations in spatial reasoning. In this paper, we have studied generative AI's spatial capabilities of understanding rotations of objects utilizing its image and language processing features. We examined the spatial intelligence of the GPT-4 model with vision in understanding spatial rotation process with diagrams based on the Revised Purdue Spatial Visualization Test: Visualization of Rotations (Revised PSVT:R). Next, we incorporated a layer of coordinate system axes on Revised PSVT:R to study the variations in GPT-4's performance. We also examined GPT-4's understanding of 3D rotations in Augmented Reality (AR) scenes that visualize spatial rotations of an object in 3D space and observed increased accuracy of GPT-4's understanding of the rotations by adding supplementary textual information depicting the rotation process or mathematical representations of the rotation (e.g., matrices). The results indicate that while GPT-4 as a major current Generative AI model lacks the understanding of a spatial rotation process, it has the potential to understand the rotation process with additional information that can be provided by methods such as AR. By combining the potentials in spatial intelligence of AI with AR's interactive visualization abilities, we expect to offer enhanced guidance for students' spatial learning activities. Such spatial guidance can benefit understanding spatial transformations and additionally support processes like assembly, fabrication, and manufacturing.</p></details> |  |
| **[Spatial-RAG: Spatial Retrieval Augmented Generation for Real-World Geospatial Reasoning Questions](https://arxiv.org/pdf/2502.18470v5)** | 2025-06-12 | [papers-cool](https://papers.cool/arxiv/2502.18470v5) | <details><summary>Show</summary><p>Answering real-world geospatial questions--such as finding restaurants along a travel route or amenities near a landmark--requires reasoning over both geographic relationships and semantic user intent. However, existing large language models (LLMs) lack spatial computing capabilities and access to up-to-date, ubiquitous real-world geospatial data, while traditional geospatial systems fall short in interpreting natural language. To bridge this gap, we introduce Spatial-RAG, a Retrieval-Augmented Generation (RAG) framework designed for geospatial question answering. Spatial-RAG integrates structured spatial databases with LLMs via a hybrid spatial retriever that combines sparse spatial filtering and dense semantic matching. It formulates the answering process as a multi-objective optimization over spatial and semantic relevance, identifying Pareto-optimal candidates and dynamically selecting the best response based on user intent. Experiments across multiple tourism and map-based QA datasets show that Spatial-RAG significantly improves accuracy, precision, and ranking performance over strong baselines.</p></details> |  |
| **[Spatial Models for Field Trials](https://arxiv.org/pdf/1607.08255v1)** | 2016-07-29 | [papers-cool](https://papers.cool/arxiv/1607.08255v1) | <details><summary>Show</summary><p>An important aim of the analysis of agricultural field trials is to obtain good predictions for genotypic performance, by correcting for spatial effects. In practice these corrections turn out to be complicated, since there can be different types of spatial effects; those due to management interventions applied to the field plots and those due to various kinds of erratic spatial trends. This paper presents models for field trials in which the random spatial component consists of tensor product Penalized splines (P-splines). A special ANOVA-type reformulation leads to five smooth additive spatial components, which form the basis of a mixed model with five unknown variance components. On top of this spatial field, effects of genotypes, blocks, replicates, and/or other sources of spatial variation are described by a mixed model in a standard way. We show the relation between several definitions of heritability and the effective dimension or the effective degrees of freedom associated to the genetic component. The approach is illustrated with large-scale field trial experiments. An R-package is provided.</p></details> |  |
| **[Spatial-ViLT: Enhancing Visual Spatial Reasoning through Multi-Task Learning](https://arxiv.org/pdf/2510.03441v1)** | 2025-10-07 | [papers-cool](https://papers.cool/arxiv/2510.03441v1) | <details><summary>Show</summary><p>Vision-language models (VLMs) have advanced multimodal reasoning but still face challenges in spatial reasoning for 3D scenes and complex object configurations. To address this, we introduce SpatialViLT, an enhanced VLM that integrates spatial features like depth maps, 3D coordinates, and edge maps through a multi-task learning framework. This approach enriches multimodal embeddings with spatial understanding. We propose two variants: SpatialViLT and MaskedSpatialViLT, focusing on full and masked object regions, respectively. Additionally, SpatialEnsemble combines both approaches, achieving state-of-the-art accuracy. Our models excel in spatial reasoning categories such as directional, topological, and proximity relations, as demonstrated on the challenging Visual Spatial Reasoning (VSR) dataset. This work represents a significant step in enhancing the spatial intelligence of AI systems, crucial for advanced multimodal understanding and real-world applications.</p></details> | 12 pages, 5 figures |
| **[Explainable AI in Spatial Analysis](https://arxiv.org/pdf/2505.00591v1)** | 2025-05-02 | [papers-cool](https://papers.cool/arxiv/2505.00591v1) | <details><summary>Show</summary><p>This chapter discusses the opportunities of eXplainable Artificial Intelligence (XAI) within the realm of spatial analysis. A key objective in spatial analysis is to model spatial relationships and infer spatial processes to generate knowledge from spatial data, which has been largely based on spatial statistical methods. More recently, machine learning offers scalable and flexible approaches that complement traditional methods and has been increasingly applied in spatial data science. Despite its advantages, machine learning is often criticized for being a black box, which limits our understanding of model behavior and output. Recognizing this limitation, XAI has emerged as a pivotal field in AI that provides methods to explain the output of machine learning models to enhance transparency and understanding. These methods are crucial for model diagnosis, bias detection, and ensuring the reliability of results obtained from machine learning models. This chapter introduces key concepts and methods in XAI with a focus on Shapley value-based approaches, which is arguably the most popular XAI method, and their integration with spatial analysis. An empirical example of county-level voting behaviors in the 2020 Presidential election is presented to demonstrate the use of Shapley values and spatial analysis with a comparison to multi-scale geographically weighted regression. The chapter concludes with a discussion on the challenges and limitations of current XAI techniques and proposes new directions.</p></details> |  |
| **[Spatial function-on-function regression](https://arxiv.org/pdf/2412.17327v1)** | 2024-12-24 | [papers-cool](https://papers.cool/arxiv/2412.17327v1) | <details><summary>Show</summary><p>We introduce a spatial function-on-function regression model to capture spatial dependencies in functional data by integrating spatial autoregressive techniques with functional principal component analysis. The proposed model addresses a critical gap in functional regression by enabling the analysis of functional responses influenced by spatially correlated functional predictors, a common scenario in fields such as environmental sciences, epidemiology, and socio-economic studies. The model employs a spatial functional principal component decomposition on the response and a classical functional principal component decomposition on the predictor, transforming the functional data into a finite-dimensional multivariate spatial autoregressive framework. This transformation allows efficient estimation and robust handling of spatial dependencies through least squares methods. In a series of extensive simulations, the proposed model consistently demonstrated superior performance in estimating both spatial autocorrelation and regression coefficient functions compared to some favorably existing traditional approaches, particularly under moderate to strong spatial effects. Application of the proposed model to Brazilian COVID-19 data further underscored its practical utility, revealing critical spatial patterns in confirmed cases and death rates that align with known geographic and social interactions. An R package provides a comprehensive implementation of the proposed estimation method, offering a user-friendly and efficient tool for researchers and practitioners to apply the methodology in real-world scenarios.</p></details> | <details><summary>43 pa...</summary><p>43 pages, 6 figures, 3 tables</p></details> |
| **[Learned spatial data partitioning](https://arxiv.org/pdf/2306.04846v2)** | 2023-06-21 | [papers-cool](https://papers.cool/arxiv/2306.04846v2) | <details><summary>Show</summary><p>Due to the significant increase in the size of spatial data, it is essential to use distributed parallel processing systems to efficiently analyze spatial data. In this paper, we first study learned spatial data partitioning, which effectively assigns groups of big spatial data to computers based on locations of data by using machine learning techniques. We formalize spatial data partitioning in the context of reinforcement learning and develop a novel deep reinforcement learning algorithm. Our learning algorithm leverages features of spatial data partitioning and prunes ineffective learning processes to find optimal partitions efficiently. Our experimental study, which uses Apache Sedona and real-world spatial data, demonstrates that our method efficiently finds partitions for accelerating distance join queries and reduces the workload run time by up to 59.4%.</p></details> |  |

## Time
| **Title** | **Date** | **KiMi** | **Abstract** | **Comment** |
| --- | --- | --- | --- | --- |
| **[Time for Timed Monitorability](https://arxiv.org/pdf/2504.10008v3)** | 2025-10-02 | [papers-cool](https://papers.cool/arxiv/2504.10008v3) | <details><summary>Show</summary><p>Monitoring is an important part of the verification toolbox, in particular in situations where exhaustive verification using, e.g., model-checking is infeasible. The goal of online monitoring is to determine the satisfaction or violation of a specification during runtime, i.e., based on finite execution prefixes. However, not every specification is amenable to monitoring, e.g., properties for which no finite execution can witness satisfaction or violation. Monitorability is the question of whether a given specification is amenable to monitoring, and has been extensively studied in discrete time. Here, we study the monitorability problem for real-time properties expressed as Timed Automata. For specifications given by deterministic Timed Muller Automata, we prove decidability while we show that the problem is undecidable for specifications given by nondeterministic Timed Bchi automata. Furthermore, we refine monitorability to also determine bounds on the number of events as well as the time that must pass before monitoring the property may yield an informative verdict. We prove that for deterministic Timed Muller automata, such bounds can be effectively computed. In contrast we show that for nondeterministic Timed Bchi automata such bounds are not computable.</p></details> | <details><summary>Updat...</summary><p>Updated with corrected proof of Theorem 19, fixing an incorrect characterisation of strong monitorability</p></details> |
| **[Configuring Timing Parameters to Ensure Execution-Time Opacity in Timed Automata](https://arxiv.org/pdf/2310.20392v1)** | 2023-11-01 | [papers-cool](https://papers.cool/arxiv/2310.20392v1) | <details><summary>Show</summary><p>Timing information leakage occurs whenever an attacker successfully deduces confidential internal information by observing some timed information such as events with timestamps. Timed automata are an extension of finite-state automata with a set of clocks evolving linearly and that can be tested or reset, making this formalism able to reason on systems involving concurrency and timing constraints. In this paper, we summarize a recent line of works using timed automata as the input formalism, in which we assume that the attacker has access (only) to the system execution time. First, we address the following execution-time opacity problem: given a timed system modeled by a timed automaton, given a secret location and a final location, synthesize the execution times from the initial location to the final location for which one cannot deduce whether the secret location was visited. This means that for any such execution time, the system is opaque: either the final location is not reachable, or it is reachable with that execution time for both a run visiting and a run not visiting the secret location. We also address the full execution-time opacity problem, asking whether the system is opaque for all execution times; we also study a weak counterpart. Second, we add timing parameters, which are a way to configure a system: we identify a subclass of parametric timed automata with some decidability results. In addition, we devise a semi-algorithm for synthesizing timing parameter valuations guaranteeing that the resulting system is opaque. Third, we report on problems when the secret has itself an expiration date, thus defining expiring execution-time opacity problems. We finally show that our method can also apply to program analysis with configurable internal timings.</p></details> | <details><summary>In Pr...</summary><p>In Proceedings TiCSA 2023, arXiv:2310.18720. This invited paper mainly summarizes results on opacity from two recent works published in ToSEM (2022) and at ICECCS 2023, providing unified notations and concept names for the sake of consistency. In addition, we prove a few original results absent from these works</p></details> |
| **[Average-Time Games on Timed Automata](https://arxiv.org/pdf/0910.2891v1)** | 2020-01-16 | [papers-cool](https://papers.cool/arxiv/0910.2891v1) | <details><summary>Show</summary><p>An average-time game is played on the infinite graph of configurations of a finite timed automaton. The two players, Min and Max, construct an infinite run of the automaton by taking turns to perform a timed transition. Player Min wants to minimise the average time per transition and player Max wants to maximise it. A solution of average-time games is presented using a reduction to average-price game on a finite graph. A direct consequence is an elementary proof of determinacy for average-time games. This complements our results for reachability-time games and partially solves a problem posed by Bouyer et al., to design an algorithm for solving average-price games on priced timed automata. The paper also establishes the exact computational complexity of solving average-time games: the problem is EXPTIME-complete for timed automata with at least two clocks.</p></details> |  |
| **[Cover Time and Broadcast Time](https://arxiv.org/pdf/0902.1735v1)** | 2009-02-11 | [papers-cool](https://papers.cool/arxiv/0902.1735v1) | <details><summary>Show</summary><p>We introduce a new technique for bounding the cover time of random walks by relating it to the runtime of randomized broadcast. In particular, we strongly confirm for dense graphs the intuition of Chandra et al. \cite{CRRST97} that "the cover time of the graph is an appropriate metric for the performance of certain kinds of randomized broadcast algorithms". In more detail, our results are as follows: For any graph $G=(V,E)$ of size $n$ and minimum degree $$, we have $\mathcal{R}(G)= \Oh(\frac{|E|} \cdot \log n)$, where $\mathcal{R}(G)$ denotes the quotient of the cover time and broadcast time. This bound is tight for binary trees and tight up to logarithmic factors for many graphs including hypercubes, expanders and lollipop graphs. For any $$-regular (or almost $$-regular) graph $G$ it holds that $\mathcal{R}(G) = (\frac{^2}{n} \cdot \frac{1}{\log n})$. Together with our upper bound on $\mathcal{R}(G)$, this lower bound strongly confirms the intuition of Chandra et al. for graphs with minimum degree $(n)$, since then the cover time equals the broadcast time multiplied by $n$ (neglecting logarithmic factors). Conversely, for any $$ we construct almost $$-regular graphs that satisfy $\mathcal{R}(G) = \Oh(\max \{\sqrt{n},\} \cdot \log^2 n)$. Since any regular expander satisfies $\mathcal{R}(G) = (n)$, the strong relationship given above does not hold if $$ is polynomially smaller than $n$. Our bounds also demonstrate that the relationship between cover time and broadcast time is much stronger than the known relationships between any of them and the mixing time (or the closely related spectral gap).</p></details> |  |
| **[Reachability-time games on timed automata](https://arxiv.org/pdf/0907.3414v1)** | 2020-01-16 | [papers-cool](https://papers.cool/arxiv/0907.3414v1) | <details><summary>Show</summary><p>In a reachability-time game, players Min and Max choose moves so that the time to reach a final state in a timed automaton is minimised or maximised, respectively. Asarin and Maler showed decidability of reachability-time games on strongly non-Zeno timed automata using a value iteration algorithm. This paper complements their work by providing a strategy improvement algorithm for the problem. It also generalizes their decidability result because the proposed strategy improvement algorithm solves reachability-time games on all timed automata. The exact computational complexity of solving reachability-time games is also established: the problem is EXPTIME-complete for timed automata with at least two clocks.</p></details> |  |
| **[Computing Continuous Dynamic Time Warping of Time Series in Polynomial Time](https://arxiv.org/pdf/2203.04531v4)** | 2023-04-18 | [papers-cool](https://papers.cool/arxiv/2203.04531v4) | <details><summary>Show</summary><p>Dynamic Time Warping is arguably the most popular similarity measure for time series, where we define a time series to be a one-dimensional polygonal curve. The drawback of Dynamic Time Warping is that it is sensitive to the sampling rate of the time series. The Frchet distance is an alternative that has gained popularity, however, its drawback is that it is sensitive to outliers. Continuous Dynamic Time Warping (CDTW) is a recently proposed alternative that does not exhibit the aforementioned drawbacks. CDTW combines the continuous nature of the Frchet distance with the summation of Dynamic Time Warping, resulting in a similarity measure that is robust to sampling rate and to outliers. In a recent experimental work of Brankovic et al., it was demonstrated that clustering under CDTW avoids the unwanted artifacts that appear when clustering under Dynamic Time Warping and under the Frchet distance. Despite its advantages, the major shortcoming of CDTW is that there is no exact algorithm for computing CDTW, in polynomial time or otherwise. In this work, we present the first exact algorithm for computing CDTW of one-dimensional curves. Our algorithm runs in time $O(n^5)$ for a pair of one-dimensional curves, each with complexity at most $n$. In our algorithm, we propagate continuous functions in the dynamic program for CDTW, where the main difficulty lies in bounding the complexity of the functions. We believe that our result is an important first step towards CDTW becoming a practical similarity measure between curves.</p></details> | In SoCG 2022 |
| **[Canonical time-frequency, time-scale, and frequency-scale representations of time-varying channels](https://arxiv.org/pdf/cs/0510085v1)** | 2007-07-16 | [papers-cool](https://papers.cool/arxiv/0510085v1) | <details><summary>Show</summary><p>Mobile communication channels are often modeled as linear time-varying filters or, equivalently, as time-frequency integral operators with finite support in time and frequency. Such a characterization inherently assumes the signals are narrowband and may not be appropriate for wideband signals. In this paper time-scale characterizations are examined that are useful in wideband time-varying channels, for which a time-scale integral operator is physically justifiable. A review of these time-frequency and time-scale characterizations is presented. Both the time-frequency and time-scale integral operators have a two-dimensional discrete characterization which motivates the design of time-frequency or time-scale rake receivers. These receivers have taps for both time and frequency (or time and scale) shifts of the transmitted signal. A general theory of these characterizations which generates, as specific cases, the discrete time-frequency and time-scale models is presented here. The interpretation of these models, namely, that they can be seen to arise from processing assumptions on the transmit and receive waveforms is discussed. Out of this discussion a third model arises: a frequency-scale continuous channel model with an associated discrete frequency-scale characterization.</p></details> | <details><summary>To ap...</summary><p>To appear in Communications in Information and Systems - special issue in honor of Thomas Kailath's seventieth birthday</p></details> |
| **[On the nature of time in time-dependent expansionary processes](https://arxiv.org/pdf/2106.02453v1)** | 2021-06-07 | [papers-cool](https://papers.cool/arxiv/2106.02453v1) | <details><summary>Show</summary><p>For an expansionary process, the size of the expansion space will increase. If the expansionary process is time-dependent, time (t) will increase as a function of the increase in the size of the expansion space. A statistical information entropy methodology was used to investigate the properties of time-dependent expansionary processes both in theory and through examples. The primary objective of this paper was to investigate whether there is a universal measure of time (T) and how it relates to process related time (t), that is specific to any given time-dependent expansionary process. It was found that for such time-dependent processes, time (t) can be rescaled to time (T) such that, T and the information entropy (H(T)) of the expansionary process are the same, and directly related to the increase in the size of the expansion space.</p></details> | <details><summary>18 pa...</summary><p>18 pages, 4 figures, 1 appendix</p></details> |
| **[Trainable Time Warping: Aligning Time-Series in the Continuous-Time Domain](https://arxiv.org/pdf/1903.09245v1)** | 2019-03-25 | [papers-cool](https://papers.cool/arxiv/1903.09245v1) | <details><summary>Show</summary><p>DTW calculates the similarity or alignment between two signals, subject to temporal warping. However, its computational complexity grows exponentially with the number of time-series. Although there have been algorithms developed that are linear in the number of time-series, they are generally quadratic in time-series length. The exception is generalized time warping (GTW), which has linear computational cost. Yet, it can only identify simple time warping functions. There is a need for a new fast, high-quality multisequence alignment algorithm. We introduce trainable time warping (TTW), whose complexity is linear in both the number and the length of time-series. TTW performs alignment in the continuous-time domain using a sinc convolutional kernel and a gradient-based optimization technique. We compare TTW and GTW on 85 UCR datasets in time-series averaging and classification. TTW outperforms GTW on 67.1% of the datasets for the averaging tasks, and 61.2% of the datasets for the classification tasks.</p></details> | ICASSP 2019 |
| **[Time is Not Enough: Time-Frequency based Explanation for Time-Series Black-Box Models](https://arxiv.org/pdf/2408.03636v2)** | 2024-08-13 | [papers-cool](https://papers.cool/arxiv/2408.03636v2) | <details><summary>Show</summary><p>Despite the massive attention given to time-series explanations due to their extensive applications, a notable limitation in existing approaches is their primary reliance on the time-domain. This overlooks the inherent characteristic of time-series data containing both time and frequency features. In this work, we present Spectral eXplanation (SpectralX), an XAI framework that provides time-frequency explanations for time-series black-box classifiers. This easily adaptable framework enables users to "plug-in" various perturbation-based XAI methods for any pre-trained time-series classification models to assess their impact on the explanation quality without having to modify the framework architecture. Additionally, we introduce Feature Importance Approximations (FIA), a new perturbation-based XAI method. These methods consist of feature insertion, deletion, and combination techniques to enhance computational efficiency and class-specific explanations in time-series classification tasks. We conduct extensive experiments in the generated synthetic dataset and various UCR Time-Series datasets to first compare the explanation performance of FIA and other existing perturbation-based XAI methods in both time-domain and time-frequency domain, and then show the superiority of our FIA in the time-frequency domain with the SpectralX framework. Finally, we conduct a user study to confirm the practicality of our FIA in SpectralX framework for class-specific time-frequency based time-series explanations. The source code is available in https://github.com/gustmd0121/Time_is_not_Enough</p></details> | <details><summary>Accep...</summary><p>Accepted to CIKM 2024 (10 pages, 9 figures, 9 tables)</p></details> |
| **[Timed Strategies for Real-Time Rewrite Theories](https://arxiv.org/pdf/2403.08920v1)** | 2024-03-15 | [papers-cool](https://papers.cool/arxiv/2403.08920v1) | <details><summary>Show</summary><p>In this paper we propose a language for conveniently defining a wide range of execution strategies for real-time rewrite theories, and provide Maude-strategy-implemented versions of most Real-Time Maude analysis methods, albeit with user-defined discrete and timed strategies. We also identify a new time sampling strategy that should provide both efficient and exhaustive analysis for many distributed real-time systems. We exemplify the use of our language and its analyses on a simple round trip time protocol, and compare the performance of standard Maude search with our strategy-implemented reachability analyses on the CASH scheduling algorithm benchmark.</p></details> |  |
| **[Flow Time Scheduling with Uncertain Processing Time](https://arxiv.org/pdf/2103.05604v1)** | 2021-03-10 | [papers-cool](https://papers.cool/arxiv/2103.05604v1) | <details><summary>Show</summary><p>We consider the problem of online scheduling on a single machine in order to minimize weighted flow time. The existing algorithms for this problem (STOC '01, SODA '03, FOCS '18) all require exact knowledge of the processing time of each job. This assumption is crucial, as even a slight perturbation of the processing time would lead to polynomial competitive ratio. However, this assumption very rarely holds in real-life scenarios. In this paper, we present the first algorithm for weighted flow time which do not require exact knowledge of the processing times of jobs. Specifically, we introduce the Scheduling with Predicted Processing Time (SPPT) problem, where the algorithm is given a prediction for the processing time of each job, instead of its real processing time. For the case of a constant factor distortion between the predictions and the real processing time, our algorithms match all the best known competitiveness bounds for weighted flow time -- namely $O(\log P), O(\log D)$ and $O(\log W)$, where $P,D,W$ are the maximum ratios of processing times, densities, and weights, respectively. For larger errors, the competitiveness of our algorithms degrades gracefully.</p></details> |  |
| **[TSP with Time Windows and Service Time](https://arxiv.org/pdf/1501.06158v1)** | 2015-01-27 | [papers-cool](https://papers.cool/arxiv/1501.06158v1) | <details><summary>Show</summary><p>We consider TSP with time windows and service time. In this problem we receive a sequence of requests for a service at nodes in a metric space and a time window for each request. The goal of the online algorithm is to maximize the number of requests served during their time window. The time to traverse an edge is the distance between the incident nodes of that edge. Serving a request requires unit time. We characterize the competitive ratio for each metric space separately. The competitive ratio depends on the relation between the minimum laxity (the minimum length of a time window) and the diameter of the metric space. Specifically, there is a constant competitive algorithm depending whether the laxity is larger or smaller than the diameter. In addition, we characterize the rate of convergence of the competitive ratio to $1$ as the laxity increases. Specifically, we provide a matching lower and upper bounds depending on the ratio between the laxity and the TSP of the metric space (the minimum distance to traverse all nodes). An application of our result improves the lower bound for colored packets with transition cost and matches the upper bound. In proving our lower bounds we use an interesting non-standard embedding with some special properties. This embedding may be interesting by its own.</p></details> | <details><summary>arXiv...</summary><p>arXiv admin note: substantial text overlap with arXiv:1309.0251</p></details> |
| **[Cover times, blanket times, and majorizing measures](https://arxiv.org/pdf/1004.4371v5)** | 2011-10-10 | [papers-cool](https://papers.cool/arxiv/1004.4371v5) | <details><summary>Show</summary><p>We exhibit a strong connection between cover times of graphs, Gaussian processes, and Talagrand's theory of majorizing measures. In particular, we show that the cover time of any graph $G$ is equivalent, up to universal constants, to the square of the expected maximum of the Gaussian free field on $G$, scaled by the number of edges in $G$. This allows us to resolve a number of open questions. We give a deterministic polynomial-time algorithm that computes the cover time to within an O(1) factor for any graph, answering a question of Aldous and Fill (1994). We also positively resolve the blanket time conjectures of Winkler and Zuckerman (1996), showing that for any graph, the blanket and cover times are within an O(1) factor. The best previous approximation factor for both these problems was $O((\log \log n)^2)$ for $n$-vertex graphs, due to Kahn, Kim, Lovasz, and Vu (2000).</p></details> | <details><summary>Revis...</summary><p>Revisions to Section 3; added and rearranged some material on the majorizing measures theory</p></details> |
| **[Revisiting Timed Specification Theories: A Linear-Time Perspective](https://arxiv.org/pdf/1206.4504v1)** | 2012-06-21 | [papers-cool](https://papers.cool/arxiv/1206.4504v1) | <details><summary>Show</summary><p>We consider the setting of component-based design for real-time systems with critical timing constraints. Based on our earlier work, we propose a compositional specification theory for timed automata with I/O distinction, which supports substitutive refinement. Our theory provides the operations of parallel composition for composing components at run-time, logical conjunction/disjunction for independent development, and quotient for incremental synthesis. The key novelty of our timed theory lies in a weakest congruence preserving safety as well as bounded liveness properties. We show that the congruence can be characterised by two linear-time semantics, timed-traces and timed-strategies, the latter of which is derived from a game-based interpretation of timed interaction.</p></details> |  |
| **[Timed Alignments](https://arxiv.org/pdf/2207.01870v1)** | 2022-07-06 | [papers-cool](https://papers.cool/arxiv/2207.01870v1) | <details><summary>Show</summary><p>The subject of this paper is to study conformance checking for timed models, that is, process models that consider both the sequence of events in a process as well as the timestamps at which each event is recorded. Time-aware process mining is a growing subfield of research, and as tools that seek to discover timing related properties in processes develop, so does the need for conformance checking techniques that can tackle time constraints and provide insightful quality measures for time-aware process models. In particular, one of the most useful conformance artefacts is the alignment, that is, finding the minimal changes necessary to correct a new observation to conform to a process model. In this paper, we set our problem of timed alignment and solve two cases each corresponding to a different metric over time processes. For the first, we have an algorithm whose time complexity is linear both in the size of the observed trace and the process model, while for the second we have a quadratic time algorithm for linear process models.</p></details> |  |
| **[Networks with time structure from time series](https://arxiv.org/pdf/1205.4811v1)** | 2015-06-05 | [papers-cool](https://papers.cool/arxiv/1205.4811v1) | <details><summary>Show</summary><p>We propose a method of constructing a network, in which its time structure is directly incorporated, based on a deterministic model from a time series. To construct such a network, we transform a linear model containing terms with different time delays into network topology. The terms in the model are translated into temporal nodes of the network. On each link connecting these nodes, we assign a positive real number representing the strength of relationship, or the "distance," between nodes specified by the parameters of the model. The method is demonstrated by a known system and applied to two actual time series.</p></details> | <details><summary>15 pa...</summary><p>15 pages, 5 figures, accepted to be published in Physica A</p></details> |
| **[Higher-Dimensional Timed Automata for Real-Time Concurrency](https://arxiv.org/pdf/2401.17444v4)** | 2025-02-06 | [papers-cool](https://papers.cool/arxiv/2401.17444v4) | <details><summary>Show</summary><p>We present a new language semantics for real-time concurrency. Its operational models are higher-dimensional timed automata (HDTAs), a generalization of both higher-dimensional automata and timed automata. In real-time concurrent systems, both concurrency of events and timing and duration of events are of interest. Thus, HDTAs combine the non-interleaving concurrency model of higher-dimensional automata with the real-time modeling, using clocks, of timed automata. We define languages of HDTAs as sets of interval-timed pomsets with interfaces. We show that language inclusion of HDTAs is undecidable. On the other hand, using a region construction we can show that untimings of HDTA languages have enough regularity so that untimed language inclusion is decidable. On a more practical note, we give new insights on when practical applications, like checking reachability, might benefit from using HDTAs instead of classical timed automata.</p></details> |  |
| **[Gaussian Time Machine: A Real-Time Rendering Methodology for Time-Variant Appearances](https://arxiv.org/pdf/2405.13694v1)** | 2024-05-24 | [papers-cool](https://papers.cool/arxiv/2405.13694v1) | <details><summary>Show</summary><p>Recent advancements in neural rendering techniques have significantly enhanced the fidelity of 3D reconstruction. Notably, the emergence of 3D Gaussian Splatting (3DGS) has marked a significant milestone by adopting a discrete scene representation, facilitating efficient training and real-time rendering. Several studies have successfully extended the real-time rendering capability of 3DGS to dynamic scenes. However, a challenge arises when training images are captured under vastly differing weather and lighting conditions. This scenario poses a challenge for 3DGS and its variants in achieving accurate reconstructions. Although NeRF-based methods (NeRF-W, CLNeRF) have shown promise in handling such challenging conditions, their computational demands hinder real-time rendering capabilities. In this paper, we present Gaussian Time Machine (GTM) which models the time-dependent attributes of Gaussian primitives with discrete time embedding vectors decoded by a lightweight Multi-Layer-Perceptron(MLP). By adjusting the opacity of Gaussian primitives, we can reconstruct visibility changes of objects. We further propose a decomposed color model for improved geometric consistency. GTM achieved state-of-the-art rendering fidelity on 3 datasets and is 100 times faster than NeRF-based counterparts in rendering. Moreover, GTM successfully disentangles the appearance changes and renders smooth appearance interpolation.</p></details> | 14 pages, 6 figures |
| **[Real-Time LaCAM for Real-Time MAPF](https://arxiv.org/pdf/2504.06091v2)** | 2025-07-29 | [papers-cool](https://papers.cool/arxiv/2504.06091v2) | <details><summary>Show</summary><p>The vast majority of Multi-Agent Path Finding (MAPF) methods with completeness guarantees require planning full-horizon paths. However, planning full-horizon paths can take too long and be impractical in real-world applications. Instead, real-time planning and execution, which only allows the planner a finite amount of time before executing and replanning, is more practical for real-world multi-agent systems. Several methods utilize real-time planning schemes but none are provably complete, which leads to livelock or deadlock. Our main contribution is Real-Time LaCAM, the first Real-Time MAPF method with provable completeness guarantees. We do this by leveraging LaCAM (Okumura 2023) in an incremental fashion. Our results show how we can iteratively plan for congested environments with a cutoff time of milliseconds while still maintaining the same success rate as full-horizon LaCAM. We also show how it can be used with a single-step learned MAPF policy.</p></details> | <details><summary>Publi...</summary><p>Published at the International Symposium on Combinatorial Search 2025 (SoCS 2025)</p></details> |
| **[Route to Time and Time to Route: Travel Time Estimation from Sparse Trajectories](https://arxiv.org/pdf/2206.10418v1)** | 2022-06-22 | [papers-cool](https://papers.cool/arxiv/2206.10418v1) | <details><summary>Show</summary><p>Due to the rapid development of Internet of Things (IoT) technologies, many online web apps (e.g., Google Map and Uber) estimate the travel time of trajectory data collected by mobile devices. However, in reality, complex factors, such as network communication and energy constraints, make multiple trajectories collected at a low sampling rate. In this case, this paper aims to resolve the problem of travel time estimation (TTE) and route recovery in sparse scenarios, which often leads to the uncertain label of travel time and route between continuously sampled GPS points. We formulate this problem as an inexact supervision problem in which the training data has coarsely grained labels and jointly solve the tasks of TTE and route recovery. And we argue that both two tasks are complementary to each other in the model-learning procedure and hold such a relation: more precise travel time can lead to better inference for routes, in turn, resulting in a more accurate time estimation). Based on this assumption, we propose an EM algorithm to alternatively estimate the travel time of inferred route through weak supervision in E step and retrieve the route based on estimated travel time in M step for sparse trajectories. We conducted experiments on three real-world trajectory datasets and demonstrated the effectiveness of the proposed method.</p></details> |  |
| **[On Timing Model Extraction and Hierarchical Statistical Timing Analysis](https://arxiv.org/pdf/1705.04981v1)** | 2017-05-16 | [papers-cool](https://papers.cool/arxiv/1705.04981v1) | <details><summary>Show</summary><p>In this paper, we investigate the challenges to apply Statistical Static Timing Analysis (SSTA) in hierarchical design flow, where modules supplied by IP vendors are used to hide design details for IP protection and to reduce the complexity of design and verification. For the three basic circuit types, combinational, flip-flop-based and latch-controlled, we propose methods to extract timing models which contain interfacing as well as compressed internal constraints. Using these compact timing models the runtime of full-chip timing analysis can be reduced, while circuit details from IP vendors are not exposed. We also propose a method to reconstruct the correlation between modules during full-chip timing analysis. This correlation can not be incorporated into timing models because it depends on the layout of the corresponding modules in the chip. In addition, we investigate how to apply the extracted timing models with the reconstructed correlation to evaluate the performance of the complete design. Experiments demonstrate that using the extracted timing models and reconstructed correlation full-chip timing analysis can be several times faster than applying the flattened circuit directly, while the accuracy of statistical timing analysis is still well maintained.</p></details> |  |
| **[Deep Optimal Timing Strategies for Time Series](https://arxiv.org/pdf/2310.05479v1)** | 2023-10-10 | [papers-cool](https://papers.cool/arxiv/2310.05479v1) | <details><summary>Show</summary><p>Deciding the best future execution time is a critical task in many business activities while evolving time series forecasting, and optimal timing strategy provides such a solution, which is driven by observed data. This solution has plenty of valuable applications to reduce the operation costs. In this paper, we propose a mechanism that combines a probabilistic time series forecasting task and an optimal timing decision task as a first systematic attempt to tackle these practical problems with both solid theoretical foundation and real-world flexibility. Specifically, it generates the future paths of the underlying time series via probabilistic forecasting algorithms, which does not need a sophisticated mathematical dynamic model relying on strong prior knowledge as most other common practices. In order to find the optimal execution time, we formulate the decision task as an optimal stopping problem, and employ a recurrent neural network structure (RNN) to approximate the optimal times. Github repository: \url{github.com/ChenPopper/optimal_timing_TSF}.</p></details> | <details><summary>Accep...</summary><p>Accepted by ICDM 2023</p></details> |
| **[Communicating Timed Processes with Perfect Timed Channels](https://arxiv.org/pdf/1708.05063v4)** | 2018-03-20 | [papers-cool](https://papers.cool/arxiv/1708.05063v4) | <details><summary>Show</summary><p>We introduce the model of communicating timed automata (CTA) that extends the classical models of finite-state processes communicating through FIFO perfect channels and timed automata, in the sense that the finite-state processes are replaced by timed automata, and messages inside the perfect channels are equipped with clocks representing their ages. In addition to the standard operations (resetting clocks, checking guards of clocks) each automaton can either (1) append a message to the tail of a channel with an initial age or (2) receive the message at the head of a channel if its age satisfies a set of given constraints. In this paper, we show that the reachability problem is undecidable even in the case of two timed automata connected by one unidirectional timed channel if one allows global clocks (that the two automata can check and manipulate). We prove that this undecidability still holds even for CTA consisting of three timed automata and two unidirectional timed channels (and without any global clock). However, the reachability problem becomes decidable (in $\mathsf{EXPTIME}$) in the case of two automata linked with one unidirectional timed channel and with no global clock. Finally, we consider the bounded-context case, where in each context, only one timed automaton is allowed to receive messages from one channel while being able to send messages to all the other timed channels. In this case we show that the reachability problem is decidable.</p></details> |  |
| **[Time-warping invariants of multidimensional time series](https://arxiv.org/pdf/1906.05823v2)** | 2020-10-20 | [papers-cool](https://papers.cool/arxiv/1906.05823v2) | <details><summary>Show</summary><p>In data science, one is often confronted with a time series representing measurements of some quantity of interest. Usually, as a first step, features of the time series need to be extracted. These are numerical quantities that aim to succinctly describe the data and to dampen the influence of noise. In some applications, these features are also required to satisfy some invariance properties. In this paper, we concentrate on time-warping invariants. We show that these correspond to a certain family of iterated sums of the increments of the time series, known as quasisymmetric functions in the mathematics literature. We present these invariant features in an algebraic framework, and we develop some of their basic properties.</p></details> | 18 pages, 1 figure |
| **[Execution-time opacity control for timed automata](https://arxiv.org/pdf/2409.10336v3)** | 2025-07-29 | [papers-cool](https://papers.cool/arxiv/2409.10336v3) | <details><summary>Show</summary><p>Timing leaks in timed automata (TA) can occur whenever an attacker is able to deduce a secret by observing some timed behaviour. In execution-time opacity, the attacker aims at deducing whether a private location was visited, by observing only the execution time. In earlier work, it was shown that it can be decided whether a TA is opaque in this setting. In this work, we address control, and investigate whether a TA can be controlled by a strategy at runtime to ensure opacity, by enabling or disabling some controllable actions over time. We first show that, in general, it is undecidable to determine whether such a strategy exists. Second, we show that deciding whether a meta-strategy ensuring opacity exists can be done in EXPSPACE. Such a meta-strategy is a set of strategies allowing an arbitrarily large -- yet finite -- number of strategy changes per time unit, and with only weak ordering relations between such changes. Our method is constructive, in the sense that we can exhibit such a meta-strategy. We also extend our method to the case of weak opacity, when it is harmless that the attacker deduces that the private location was not visited. Finally, we consider a variant where the attacker cannot have an infinite precision in its observations.</p></details> | <details><summary>This ...</summary><p>This is the extended version of the manuscript of the same name published in the proceedings of the 22nd International Conference on Software Engineering and Formal Methods (SEFM 2024)</p></details> |
| **[An Efficient Explicit-time Description Method for Timed Model Checking](https://arxiv.org/pdf/0912.2553v1)** | 2009-12-15 | [papers-cool](https://papers.cool/arxiv/0912.2553v1) | <details><summary>Show</summary><p>Timed model checking, the method to formally verify real-time systems, is attracting increasing attention from both the model checking community and the real-time community. Explicit-time description methods verify real-time systems using general model constructs found in standard un-timed model checkers. Lamport proposed an explicit-time description method using a clock-ticking process (Tick) to simulate the passage of time together with a group of global variables to model time requirements. Two methods, the Sync-based Explicit-time Description Method using rendezvous synchronization steps and the Semaphore-based Explicit-time Description Method using only one global variable were proposed; they both achieve better modularity than Lamport's method in modeling the real-time systems. In contrast to timed automata based model checkers like UPPAAL, explicit-time description methods can access and store the current time instant for future calculations necessary for many real-time systems, especially those with pre-emptive scheduling. However, the Tick process in the above three methods increments the time by one unit in each tick; the state spaces therefore grow relatively fast as the time parameters increase, a problem when the system's time period is relatively long. In this paper, we propose a more efficient method which enables the Tick process to leap multiple time units in one tick. Preliminary experimental results in a high performance computing environment show that this new method significantly reduces the state space and improves both the time and memory efficiency.</p></details> |  |
| **[Binary Dynamic Time Warping in Linear Time](https://arxiv.org/pdf/2101.01108v2)** | 2021-10-06 | [papers-cool](https://papers.cool/arxiv/2101.01108v2) | <details><summary>Show</summary><p>Dynamic time warping distance (DTW) is a widely used distance measure between time series $x, y \in ^n$. It was shown by Abboud, Backurs, and Williams that in the \emph{binary case}, where $|| = 2$, DTW can be computed in time $O(n^{1.87})$. We improve this running time $O(n)$. Moreover, if $x$ and $y$ are run-length encoded, then there is an algorithm running in time $\tilde{O}(k + \ell)$, where $k$ and $\ell$ are the number of runs in $x$ and $y$, respectively. This improves on the previous best bound of $O(k\ell)$ due to Dupont and Marteau.</p></details> |  |
| **[It's Time to Play Safe: Shield Synthesis for Timed Systems](https://arxiv.org/pdf/2006.16688v1)** | 2020-07-01 | [papers-cool](https://papers.cool/arxiv/2006.16688v1) | <details><summary>Show</summary><p>Erroneous behaviour in safety critical real-time systems may inflict serious consequences. In this paper, we show how to synthesize timed shields from timed safety properties given as timed automata. A timed shield enforces the safety of a running system while interfering with the system as little as possible. We present timed post-shields and timed pre-shields. A timed pre-shield is placed before the system and provides a set of safe outputs. This set restricts the choices of the system. A timed post-shield is implemented after the system. It monitors the system and corrects the system's output only if necessary. We further extend the timed post-shield construction to provide a guarantee on the recovery phase, i.e., the time between a specification violation and the point at which full control can be handed back to the system. In our experimental results, we use timed post-shields to ensure the safety in a reinforcement learning setting for controlling a platoon of cars, during the learning and execution phase, and study the effect.</p></details> | Submitted to RV2020 |
| **[The application of precision time protocol on EAST timing system](https://arxiv.org/pdf/1806.10036v1)** | 2018-07-10 | [papers-cool](https://papers.cool/arxiv/1806.10036v1) | <details><summary>Show</summary><p>The timing system focuses on synchronizing and coordinating each subsystem according to the trigger signals. A new prototype timing slave node based on precision time protocol has been developed by using ARM STM32 platform. The proposed slave timing module is tested and results show that the synchronization accuracy between slave nodes is in sub-microsecond range.</p></details> | <details><summary>4 pag...</summary><p>4 pages, 6 figures, 21st IEEE Real Time Conference</p></details> |
| **[TimeTravel: Real-time Timing Drift Attack on System Time Using Acoustic Waves](https://arxiv.org/pdf/2407.06853v1)** | 2024-07-10 | [papers-cool](https://papers.cool/arxiv/2407.06853v1) | <details><summary>Show</summary><p>Real-time Clock (RTC) has been widely used in various real-time systems to provide precise system time. In this paper, we reveal a new security vulnerability of the RTC circuit, where the internal storage time or timestamp can be arbitrarily modified forward or backward. The security threat of dynamic modifications of system time caused by this vulnerability is called TimeTravel. Based on acoustic resonance and piezoelectric effects, TimeTravel applies acoustic guide waves to the quartz crystal, thereby adjusting the characteristics of the oscillating signal transmitted into the RTC circuit. By manipulating the parameters of acoustic waves, TimeTravel can accelerate or decelerate the timing speed of system time at an adjustable rate, resulting in the relative drift of the timing, which can pose serious safety threats. To assess the severity of TimeTravel, we examine nine modules and two commercial devices under the RTC circuit. The experimental results show that TimeTravel can drift system time forward and backward at a chosen speed with a maximum 93% accuracy. Our analysis further shows that TimeTravel can maintain an attack success rate of no less than 77% under environments with typical obstacle items.</p></details> | <details><summary>Accep...</summary><p>Accepted by USENIX Security 2024 winter cycle and will appear in USENIX Security 2025</p></details> |

## Trajectory
| **Title** | **Date** | **KiMi** | **Abstract** | **Comment** |
| --- | --- | --- | --- | --- |
| **[Multi-Camera Trajectory Forecasting with Trajectory Tensors](https://arxiv.org/pdf/2108.04694v2)** | 2021-08-25 | [papers-cool](https://papers.cool/arxiv/2108.04694v2) | <details><summary>Show</summary><p>We introduce the problem of multi-camera trajectory forecasting (MCTF), which involves predicting the trajectory of a moving object across a network of cameras. While multi-camera setups are widespread for applications such as surveillance and traffic monitoring, existing trajectory forecasting methods typically focus on single-camera trajectory forecasting (SCTF), limiting their use for such applications. Furthermore, using a single camera limits the field-of-view available, making long-term trajectory forecasting impossible. We address these shortcomings of SCTF by developing an MCTF framework that simultaneously uses all estimated relative object locations from several viewpoints and predicts the object's future location in all possible viewpoints. Our framework follows a Which-When-Where approach that predicts in which camera(s) the objects appear and when and where within the camera views they appear. To this end, we propose the concept of trajectory tensors: a new technique to encode trajectories across multiple camera views and the associated uncertainties. We develop several encoder-decoder MCTF models for trajectory tensors and present extensive experiments on our own database (comprising 600 hours of video data from 15 camera views) created particularly for the MCTF task. Results show that our trajectory tensor models outperform coordinate trajectory-based MCTF models and existing SCTF methods adapted for MCTF. Code is available from: https://github.com/olly-styles/Trajectory-Tensors</p></details> | <details><summary>To ap...</summary><p>To appear in IEEE Transactions on Pattern Analysis and Machine Intelligence (tPAMI)</p></details> |
| **[Neural Trajectory Model: Implicit Neural Trajectory Representation for Trajectories Generation](https://arxiv.org/pdf/2402.01254v2)** | 2024-02-13 | [papers-cool](https://papers.cool/arxiv/2402.01254v2) | <details><summary>Show</summary><p>Trajectory planning is a fundamental problem in robotics. It facilitates a wide range of applications in navigation and motion planning, control, and multi-agent coordination. Trajectory planning is a difficult problem due to its computational complexity and real-world environment complexity with uncertainty, non-linearity, and real-time requirements. The multi-agent trajectory planning problem adds another dimension of difficulty due to inter-agent interaction. Existing solutions are either search-based or optimization-based approaches with simplified assumptions of environment, limited planning speed, and limited scalability in the number of agents. In this work, we make the first attempt to reformulate single agent and multi-agent trajectory planning problem as query problems over an implicit neural representation of trajectories. We formulate such implicit representation as Neural Trajectory Models (NTM) which can be queried to generate nearly optimal trajectory in complex environments. We conduct experiments in simulation environments and demonstrate that NTM can solve single-agent and multi-agent trajectory planning problems. In the experiments, NTMs achieve (1) sub-millisecond panning time using GPUs, (2) almost avoiding all environment collision, (3) almost avoiding all inter-agent collision, and (4) generating almost shortest paths. We also demonstrate that the same NTM framework can also be used for trajectories correction and multi-trajectory conflict resolution refining low quality and conflicting multi-agent trajectories into nearly optimal solutions efficiently. (Open source code will be available at https://github.com/laser2099/neural-trajectory-model)</p></details> |  |
| **[Central Trajectories](https://arxiv.org/pdf/1501.01822v1)** | 2015-01-09 | [papers-cool](https://papers.cool/arxiv/1501.01822v1) | <details><summary>Show</summary><p>An important task in trajectory analysis is clustering. The results of a clustering are often summarized by a single representative trajectory and an associated size of each cluster. We study the problem of computing a suitable representative of a set of similar trajectories. To this end we define a central trajectory $\mathcal{C}$, which consists of pieces of the input trajectories, switches from one entity to another only if they are within a small distance of each other, and such that at any time $t$, the point $\mathcal{C}(t)$ is as central as possible. We measure centrality in terms of the radius of the smallest disk centered at $\mathcal{C}(t)$ enclosing all entities at time $t$, and discuss how the techniques can be adapted to other measures of centrality. We first study the problem in $\mathbb{R}^1$, where we show that an optimal central trajectory $\mathcal{C}$ representing $n$ trajectories, each consisting of $$ edges, has complexity $(n^2)$ and can be computed in $O(n^2 \log n)$ time. We then consider trajectories in $\mathbb{R}^d$ with $d\geq 2$, and show that the complexity of $\mathcal{C}$ is at most $O(n^{5/2})$ and can be computed in $O(n^3)$ time.</p></details> | Full version |
| **[Attention to Trajectory: Trajectory-Aware Open-Vocabulary Tracking](https://arxiv.org/pdf/2503.08145v1)** | 2025-03-12 | [papers-cool](https://papers.cool/arxiv/2503.08145v1) | <details><summary>Show</summary><p>Open-Vocabulary Multi-Object Tracking (OV-MOT) aims to enable approaches to track objects without being limited to a predefined set of categories. Current OV-MOT methods typically rely primarily on instance-level detection and association, often overlooking trajectory information that is unique and essential for object tracking tasks. Utilizing trajectory information can enhance association stability and classification accuracy, especially in cases of occlusion and category ambiguity, thereby improving adaptability to novel classes. Thus motivated, in this paper we propose \textbf{TRACT}, an open-vocabulary tracker that leverages trajectory information to improve both object association and classification in OV-MOT. Specifically, we introduce a \textit{Trajectory Consistency Reinforcement} (\textbf{TCR}) strategy, that benefits tracking performance by improving target identity and category consistency. In addition, we present \textbf{TraCLIP}, a plug-and-play trajectory classification module. It integrates \textit{Trajectory Feature Aggregation} (\textbf{TFA}) and \textit{Trajectory Semantic Enrichment} (\textbf{TSE}) strategies to fully leverage trajectory information from visual and language perspectives for enhancing the classification results. Extensive experiments on OV-TAO show that our TRACT significantly improves tracking performance, highlighting trajectory information as a valuable asset for OV-MOT. Code will be released.</p></details> |  |
| **[Trajectory Splitting: A Distributed Formulation for Collision Avoiding Trajectory Optimization](https://arxiv.org/pdf/2111.01899v1)** | 2021-11-04 | [papers-cool](https://papers.cool/arxiv/2111.01899v1) | <details><summary>Show</summary><p>Efficient trajectory optimization is essential for avoiding collisions in unstructured environments, but it remains challenging to have both speed and quality in the solutions. One reason is that second-order optimality requires calculating Hessian matrices that can grow with $O(N^2)$ with the number of waypoints. Decreasing the waypoints can quadratically decrease computation time. Unfortunately, fewer waypoints result in lower quality trajectories that may not avoid the collision. To have both, dense waypoints and reduced computation time, we took inspiration from recent studies on consensus optimization and propose a distributed formulation of collocated trajectory optimization. It breaks a long trajectory into several segments, where each segment becomes a subproblem of a few waypoints. These subproblems are solved classically, but in parallel, and the solutions are fused into a single trajectory with a consensus constraint that enforces continuity of the segments through a consensus update. With this scheme, the quadratic complexity is distributed to each segment and enables solving for higher-quality trajectories with denser waypoints. Furthermore, the proposed formulation is amenable to using any existing trajectory optimizer for solving the subproblems. We compare the performance of our implementation of trajectory splitting against leading motion planning algorithms and demonstrate the improved computational efficiency of our method.</p></details> |  |
| **[Probability Trajectory: One New Movement Description for Trajectory Prediction](https://arxiv.org/pdf/2101.10595v2)** | 2021-03-17 | [papers-cool](https://papers.cool/arxiv/2101.10595v2) | <details><summary>Show</summary><p>Trajectory prediction is a fundamental and challenging task for numerous applications, such as autonomous driving and intelligent robots. Currently, most of existing work treat the pedestrian trajectory as a series of fixed two-dimensional coordinates. However, in real scenarios, the trajectory often exhibits randomness, and has its own probability distribution. Inspired by this observed fact, also considering other movement characteristics of pedestrians, we propose one simple and intuitive movement description, probability trajectory, which maps the coordinate points of pedestrian trajectory into two-dimensional Gaussian distribution in images. Based on this unique description, we develop one novel trajectory prediction method, called social probability. The method combines the new probability trajectory and powerful convolution recurrent neural networks together. Both the input and output of our method are probability trajectories, which provide the recurrent neural network with sufficient spatial and random information of moving pedestrians. And the social probability extracts spatio-temporal features directly on the new movement description to generate robust and accurate predicted results. The experiments on public benchmark datasets show the effectiveness of the proposed method.</p></details> | 9 pages |
| **[RT-Trajectory: Robotic Task Generalization via Hindsight Trajectory Sketches](https://arxiv.org/pdf/2311.01977v2)** | 2023-11-07 | [papers-cool](https://papers.cool/arxiv/2311.01977v2) | <details><summary>Show</summary><p>Generalization remains one of the most important desiderata for robust robot learning systems. While recently proposed approaches show promise in generalization to novel objects, semantic concepts, or visual distribution shifts, generalization to new tasks remains challenging. For example, a language-conditioned policy trained on pick-and-place tasks will not be able to generalize to a folding task, even if the arm trajectory of folding is similar to pick-and-place. Our key insight is that this kind of generalization becomes feasible if we represent the task through rough trajectory sketches. We propose a policy conditioning method using such rough trajectory sketches, which we call RT-Trajectory, that is practical, easy to specify, and allows the policy to effectively perform new tasks that would otherwise be challenging to perform. We find that trajectory sketches strike a balance between being detailed enough to express low-level motion-centric guidance while being coarse enough to allow the learned policy to interpret the trajectory sketch in the context of situational visual observations. In addition, we show how trajectory sketches can provide a useful interface to communicate with robotic policies: they can be specified through simple human inputs like drawings or videos, or through automated methods such as modern image-generating or waypoint-generating methods. We evaluate RT-Trajectory at scale on a variety of real-world robotic tasks, and find that RT-Trajectory is able to perform a wider range of tasks compared to language-conditioned and goal-conditioned policies, when provided the same training data.</p></details> | <details><summary>Evalu...</summary><p>Evaluation videos can be found at https://rt-trajectory.github.io/</p></details> |
| **[Featured Trajectory Generation for TrackPuzzle](https://arxiv.org/pdf/2203.03867v1)** | 2022-03-09 | [papers-cool](https://papers.cool/arxiv/2203.03867v1) | <details><summary>Show</summary><p>Indoor route graph learning is critically important for autonomous indoor navigation. A key problem for crowd-sourcing indoor route graph learning is featured trajectory generation. In this paper, a system is provided to generate featured trajectories by crowd-sourcing smartphone data. Firstly, we propose a more accurate PDR algorithm for the generation of trajectory motion data. This algorithm uses ADAPTIV as the step counting method and uses the step estimation algorithm o make the trajectory more accurate in length. Next, the barometer is used to segment the tracks of different floors, and the track floors are obtained by WiFi feature clustering. Finally, by finding the turning point as the feature point of the trajectory, the vertices and edges of the trajectory are extracted to reduce the noise of the long straight trajectory.</p></details> |  |
| **[Unscented Trajectory Optimization](https://arxiv.org/pdf/2405.02753v1)** | 2025-09-03 | [papers-cool](https://papers.cool/arxiv/2405.02753v1) | <details><summary>Show</summary><p>In a nutshell, unscented trajectory optimization is the generation of optimal trajectories through the use of an unscented transform. Although unscented trajectory optimization was introduced by the authors about a decade ago, it is reintroduced in this paper as a special instantiation of tychastic optimal control theory. Tychastic optimal control theory (from \textit{Tyche}, the Greek goddess of chance) avoids the use of a Brownian motion and the resulting It calculus even though it uses random variables across the entire spectrum of a problem formulation. This approach circumvents the enormous technical and numerical challenges associated with stochastic trajectory optimization. Furthermore, it is shown how a tychastic optimal control problem that involves nonlinear transformations of the expectation operator can be quickly instantiated using an unscented transform. These nonlinear transformations are particularly useful in managing trajectory dispersions be it associated with path constraints or targeted values of final-time conditions. This paper also presents a systematic and rapid process for formulating and computing the most desirable tychastic trajectory using an unscented transform. Numerical examples are used to illustrate how unscented trajectory optimization may be used for risk reduction and mission recovery caused by uncertainties and failures.</p></details> | <details><summary>21 pa...</summary><p>21 pages, 11 figures 2023 AAS/AIAA Astrodynamics Specialist Conference, Big Sky, MT, Aug 13-17, 2023</p></details> |
| **[A Spatio-temporal Graph Network Allowing Incomplete Trajectory Input for Pedestrian Trajectory Prediction](https://arxiv.org/pdf/2501.13973v1)** | 2025-01-27 | [papers-cool](https://papers.cool/arxiv/2501.13973v1) | <details><summary>Show</summary><p>Pedestrian trajectory prediction is important in the research of mobile robot navigation in environments with pedestrians. Most pedestrian trajectory prediction algorithms require the input historical trajectories to be complete. If a pedestrian is unobservable in any frame in the past, then its historical trajectory become incomplete, the algorithm will not predict its future trajectory. To address this limitation, we propose the STGN-IT, a spatio-temporal graph network allowing incomplete trajectory input, which can predict the future trajectories of pedestrians with incomplete historical trajectories. STGN-IT uses the spatio-temporal graph with an additional encoding method to represent the historical trajectories and observation states of pedestrians. Moreover, STGN-IT introduces static obstacles in the environment that may affect the future trajectories as nodes to further improve the prediction accuracy. A clustering algorithm is also applied in the construction of spatio-temporal graphs. Experiments on public datasets show that STGN-IT outperforms state of the art algorithms on these metrics.</p></details> |  |
| **[Trajectory Range Visibility](https://arxiv.org/pdf/2209.04013v5)** | 2023-02-28 | [papers-cool](https://papers.cool/arxiv/2209.04013v5) | <details><summary>Show</summary><p>Consider two entities with constant but not necessarily equal velocities, moving on two given piece-wise linear trajectories inside a simple polygon $P$. The Trajectory Range Visibility problem deals with determining the sub-trajectories on which two entities become visible to each other. A more straightforward decision version of this problem is called Trajectory Visibility, where the trajectories are line segments. The decision version specifies whether the entities can see one another. This version was studied by P. Eades et al. in 2020, where they supposed given constant velocities for the entities. However, the approach presented in this paper supports non-constant complexity trajectories. Furthermore, we report every pair of constant velocities with which the entities can see each other. In particular, for every constant velocity of a moving entity, we specify: $(1)$ All visible parts of the other entity's trajectory. $(2)$ All possible constant velocities of the other entity to become visible. Regarding line-segment trajectories, we present $\mathcal{O}(n \log n)$ running time algorithm which obtains all pairs of sub-trajectories on which the moving entities become visible to one another, where $n$ is the complexity of $P$. Regarding the general case, we provide an algorithm with $\mathcal{O}(n \log n + m(\log m + \log n))$ running time, where $m$ indicates the complexity of both trajectories. We offer $\mathcal{O}(\log n)$ query time for line segment trajectories and $\mathcal{O}(\log m + k)$ for the non-constant complexity ones s.t. $k$ is the number of velocity ranges reported in the output. Interestingly, our results require only $\mathcal{O}(n + m)$ space for non-constant complexity trajectories.</p></details> |  |
| **[A Scalable Framework for Trajectory Prediction](https://arxiv.org/pdf/1806.03582v3)** | 2019-02-28 | [papers-cool](https://papers.cool/arxiv/1806.03582v3) | <details><summary>Show</summary><p>Trajectory prediction (TP) is of great importance for a wide range of location-based applications in intelligent transport systems such as location-based advertising, route planning, traffic management, and early warning systems. In the last few years, the widespread use of GPS navigation systems and wireless communication technology enabled vehicles has resulted in huge volumes of trajectory data. The task of utilizing this data employing spatio-temporal techniques for trajectory prediction in an efficient and accurate manner is an ongoing research problem. Existing TP approaches are limited to short-term predictions. Moreover, they cannot handle a large volume of trajectory data for long-term prediction. To address these limitations, we propose a scalable clustering and Markov chain based hybrid framework, called Traj-clusiVAT-based TP, for both short-term and long-term trajectory prediction, which can handle a large number of overlapping trajectories in a dense road network. Traj-clusiVAT can also determine the number of clusters, which represent different movement behaviours in input trajectory data. In our experiments, we compare our proposed approach with a mixed Markov model (MMM)-based scheme, and a trajectory clustering, NETSCAN-based TP method for both short- and long-term trajectory predictions. We performed our experiments on two real, vehicle trajectory datasets, including a large-scale trajectory dataset consisting of 3.28 million trajectories obtained from 15,061 taxis in Singapore over a period of one month. Experimental results on two real trajectory datasets show that our proposed approach outperforms the existing approaches in terms of both short- and long-term prediction performances, based on prediction accuracy and distance error (in km).</p></details> | <details><summary>Accep...</summary><p>Accepted in IEEE Transactions on Intelligent Transportation System. Info: 15 Pages, 9 Figures, 5 Tables</p></details> |
| **[Area between trajectories: Insights into optimal group selection and trajectory heterogeneity in group-based trajectory modeling](https://arxiv.org/pdf/2506.18108v1)** | 2025-06-24 | [papers-cool](https://papers.cool/arxiv/2506.18108v1) | <details><summary>Show</summary><p>Group-based trajectory modeling (GBTM) is commonly used to identify longitudinal patterns in health outcomes among older adults, with determining the optimal number of groups being a crucial step. While statistically grounded criteria are primarily relied upon, clinical relevance is gradually emphasized in medicine to ensure that the identified trajectory heterogeneity appropriately reflects changes in a disease or symptom over time. However, such considerations are often judged through visual comparisons, without concrete approaches for their application. To address this, the Area Between Trajectories (ABTs) was introduced as insights for quantifying trajectory group differences. Using a simulated sleep quality dataset, GBTM was applied to build and compare models. Subsequently, ABTs was demonstrated to show how it works, while also highlighting its limitations and potential applications.</p></details> | <details><summary>15 pa...</summary><p>15 pages, 4 figures, 1 table</p></details> |
| **[PPQ-Trajectory: Spatio-temporal Quantization for Querying in Large Trajectory Repositories](https://arxiv.org/pdf/2010.13721v1)** | 2020-10-27 | [papers-cool](https://papers.cool/arxiv/2010.13721v1) | <details><summary>Show</summary><p>We present PPQ-trajectory, a spatio-temporal quantization based solution for querying large dynamic trajectory data. PPQ-trajectory includes a partition-wise predictive quantizer (PPQ) that generates an error-bounded codebook with autocorrelation and spatial proximity-based partitions. The codebook is indexed to run approximate and exact spatio-temporal queries over compressed trajectories. PPQ-trajectory includes a coordinate quadtree coding for the codebook with support for exact queries. An incremental temporal partition-based index is utilised to avoid full reconstruction of trajectories during queries. An extensive set of experimental results for spatio-temporal queries on real trajectory datasets is presented. PPQ-trajectory shows significant improvements over the alternatives with respect to several performance measures, including the accuracy of results when the summary is used directly to provide approximate query results, the spatial deviation with which spatio-temporal path queries can be answered when the summary is used as an index, and the time taken to construct the summary. Superior results on the quality of the summary and the compression ratio are also demonstrated.</p></details> | <details><summary>To ap...</summary><p>To appear at VLDB 2021</p></details> |
| **[Obstacle-Transformer: A Trajectory Prediction Network Based on Surrounding Trajectories](https://arxiv.org/pdf/2304.07711v1)** | 2023-04-18 | [papers-cool](https://papers.cool/arxiv/2304.07711v1) | <details><summary>Show</summary><p>Recurrent Neural Network, Long Short-Term Memory, and Transformer have made great progress in predicting the trajectories of moving objects. Although the trajectory element with the surrounding scene features has been merged to improve performance, there still exist some problems to be solved. One is that the time series processing models will increase the inference time with the increase of the number of prediction sequences. Another lies in which the features can not be extracted from the scene's image and point cloud in some situations. Therefore, this paper proposes an Obstacle-Transformer to predict trajectory in a constant inference time. An ``obstacle'' is designed by the surrounding trajectory rather than images or point clouds, making Obstacle-Transformer more applicable in a wider range of scenarios. Experiments are conducted on ETH and UCY data sets to verify the performance of our model.</p></details> | 8 pages, 4 figures |
| **[TRAJEDI: Trajectory Dissimilarity](https://arxiv.org/pdf/1803.03716v1)** | 2018-12-19 | [papers-cool](https://papers.cool/arxiv/1803.03716v1) | <details><summary>Show</summary><p>The vast increase in our ability to obtain and store trajectory data necessitates trajectory analytics techniques to extract useful information from this data. Pair-wise distance functions are a foundation building block for common operations on trajectory datasets including constrained SELECT queries, k-nearest neighbors, and similarity and diversity algorithms. The accuracy and performance of these operations depend heavily on the speed and accuracy of the underlying trajectory distance function, which is in turn affected by trajectory calibration. Current methods either require calibrated data, or perform calibration of the entire relevant dataset first, which is expensive and time consuming for large datasets. We present TRAJEDI, a calibrationaware pair-wise distance calculation scheme that outperforms naive approaches while preserving accuracy. We also provide analyses of parameter tuning to trade-off between speed and accuracy. Our scheme is usable with any diversity, similarity or k-nearest neighbor algorithm.</p></details> |  |
| **[The Entropy of Conditional Markov Trajectories](https://arxiv.org/pdf/1212.2831v2)** | 2016-11-18 | [papers-cool](https://papers.cool/arxiv/1212.2831v2) | <details><summary>Show</summary><p>To quantify the randomness of Markov trajectories with fixed initial and final states, Ekroot and Cover proposed a closed-form expression for the entropy of trajectories of an irreducible finite state Markov chain. Numerous applications, including the study of random walks on graphs, require the computation of the entropy of Markov trajectories conditioned on a set of intermediate states. However, the expression of Ekroot and Cover does not allow for computing this quantity. In this paper, we propose a method to compute the entropy of conditional Markov trajectories through a transformation of the original Markov chain into a Markov chain that exhibits the desired conditional distribution of trajectories. Moreover, we express the entropy of Markov trajectories - a global quantity - as a linear combination of local entropies associated with the Markov chain states.</p></details> | <details><summary>Accep...</summary><p>Accepted for publication in IEEE Transactions on Information Theory</p></details> |
| **[Predictability of the imitative learning trajectories](https://arxiv.org/pdf/1807.04862v3)** | 2019-01-30 | [papers-cool](https://papers.cool/arxiv/1807.04862v3) | <details><summary>Show</summary><p>The fitness landscape metaphor plays a central role on the modeling of optimizing principles in many research fields, ranging from evolutionary biology, where it was first introduced, to management research. Here we consider the ensemble of trajectories of the imitative learning search, in which agents exchange information on their fitness and imitate the fittest agent in the population aiming at reaching the global maximum of the fitness landscape. We assess the degree to which the starting and ending points determine the learning trajectories using two measures, namely, the predictability that yields the probability that two randomly chosen trajectories are the same, and the mean path divergence that gauges the dissimilarity between two learning trajectories. We find that the predictability is greater in rugged landscapes than in smooth ones. The mean path divergence, however, is strongly affected by the search parameters -- population size and imitation propensity -- that obliterate the influence of the underlying landscape. The learning trajectories become more deterministic, in the sense that there are fewer distinct trajectories and those trajectories are more similar to each other, with increasing population size and imitation propensity. In addition, we find that the roughness of the learning trajectories, which measures the deviation from additivity of the fitness function, is always greater than the roughness estimated over the entire fitness landscape.</p></details> |  |
| **[Super-Trajectory for Video Segmentation](https://arxiv.org/pdf/1702.08634v4)** | 2017-07-25 | [papers-cool](https://papers.cool/arxiv/1702.08634v4) | <details><summary>Show</summary><p>We introduce a novel semi-supervised video segmentation approach based on an efficient video representation, called as "super-trajectory". Each super-trajectory corresponds to a group of compact trajectories that exhibit consistent motion patterns, similar appearance and close spatiotemporal relationships. We generate trajectories using a probabilistic model, which handles occlusions and drifts in a robust and natural way. To reliably group trajectories, we adopt a modified version of the density peaks based clustering algorithm that allows capturing rich spatiotemporal relations among trajectories in the clustering process. The presented video representation is discriminative enough to accurately propagate the initial annotations in the first frame onto the remaining video frames. Extensive experimental analysis on challenging benchmarks demonstrate our method is capable of distinguishing the target objects from complex backgrounds and even reidentifying them after long-term occlusions.</p></details> | <details><summary>This ...</summary><p>This paper has been published in ICCV 2017</p></details> |
| **[Representing Spatial Trajectories as Distributions](https://arxiv.org/pdf/2210.01322v1)** | 2022-10-05 | [papers-cool](https://papers.cool/arxiv/2210.01322v1) | <details><summary>Show</summary><p>We introduce a representation learning framework for spatial trajectories. We represent partial observations of trajectories as probability distributions in a learned latent space, which characterize the uncertainty about unobserved parts of the trajectory. Our framework allows us to obtain samples from a trajectory for any continuous point in time, both interpolating and extrapolating. Our flexible approach supports directly modifying specific attributes of a trajectory, such as its pace, as well as combining different partial observations into single representations. Experiments show our method's advantage over baselines in prediction tasks.</p></details> | <details><summary>Accep...</summary><p>Accepted to NeurIPS 2022</p></details> |
| **[PTrajM: Efficient and Semantic-rich Trajectory Learning with Pretrained Trajectory-Mamba](https://arxiv.org/pdf/2408.04916v1)** | 2024-08-12 | [papers-cool](https://papers.cool/arxiv/2408.04916v1) | <details><summary>Show</summary><p>Vehicle trajectories provide crucial movement information for various real-world applications. To better utilize vehicle trajectories, it is essential to develop a trajectory learning approach that can effectively and efficiently extract rich semantic information, including movement behavior and travel purposes, to support accurate downstream applications. However, creating such an approach presents two significant challenges. First, movement behavior are inherently spatio-temporally continuous, making them difficult to extract efficiently from irregular and discrete trajectory points. Second, travel purposes are related to the functionalities of areas and road segments traversed by vehicles. These functionalities are not available from the raw spatio-temporal trajectory features and are hard to extract directly from complex textual features associated with these areas and road segments. To address these challenges, we propose PTrajM, a novel method capable of efficient and semantic-rich vehicle trajectory learning. To support efficient modeling of movement behavior, we introduce Trajectory-Mamba as the learnable model of PTrajM, which effectively extracts continuous movement behavior while being more computationally efficient than existing structures. To facilitate efficient extraction of travel purposes, we propose a travel purpose-aware pre-training procedure, which enables PTrajM to discern the travel purposes of trajectories without additional computational resources during its embedding process. Extensive experiments on two real-world datasets and comparisons with several state-of-the-art trajectory learning methods demonstrate the effectiveness of PTrajM. Code is available at https://anonymous.4open.science/r/PTrajM-C973.</p></details> |  |
| **[Kinodynamic Trajectory Following with STELA: Simultaneous Trajectory Estimation & Local Adaptation](https://arxiv.org/pdf/2504.20009v1)** | 2025-04-29 | [papers-cool](https://papers.cool/arxiv/2504.20009v1) | <details><summary>Show</summary><p>State estimation and control are often addressed separately, leading to unsafe execution due to sensing noise, execution errors, and discrepancies between the planning model and reality. Simultaneous control and trajectory estimation using probabilistic graphical models has been proposed as a unified solution to these challenges. Previous work, however, relies heavily on appropriate Gaussian priors and is limited to holonomic robots with linear time-varying models. The current research extends graphical optimization methods to vehicles with arbitrary dynamical models via Simultaneous Trajectory Estimation and Local Adaptation (STELA). The overall approach initializes feasible trajectories using a kinodynamic, sampling-based motion planner. Then, it simultaneously: (i) estimates the past trajectory based on noisy observations, and (ii) adapts the controls to be executed to minimize deviations from the planned, feasible trajectory, while avoiding collisions. The proposed factor graph representation of trajectories in STELA can be applied for any dynamical system given access to first or second-order state update equations, and introduces the duration of execution between two states in the trajectory discretization as an optimization variable. These features provide both generalization and flexibility in trajectory following. In addition to targeting computational efficiency, the proposed strategy performs incremental updates of the factor graph using the iSAM algorithm and introduces a time-window mechanism. This mechanism allows the factor graph to be dynamically updated to operate over a limited history and forward horizon of the planned trajectory. This enables online updates of controls at a minimum of 10Hz. Experiments demonstrate that STELA achieves at least comparable performance to previous frameworks on idealized vehicles with linear dynamics.[...]</p></details> | [Accepted] RSS 2025 |
| **[Statistically Discriminative Sub-trajectory Mining](https://arxiv.org/pdf/1905.01788v1)** | 2019-05-07 | [papers-cool](https://papers.cool/arxiv/1905.01788v1) | <details><summary>Show</summary><p>We study the problem of discriminative sub-trajectory mining. Given two groups of trajectories, the goal of this problem is to extract moving patterns in the form of sub-trajectories which are more similar to sub-trajectories of one group and less similar to those of the other. We propose a new method called Statistically Discriminative Sub-trajectory Mining (SDSM) for this problem. An advantage of the SDSM method is that the statistical significance of the extracted sub-trajectories are properly controlled in the sense that the probability of finding a false positive sub-trajectory is smaller than a specified significance threshold alpha (e.g., 0.05), which is indispensable when the method is used in scientific or social studies under noisy environment. Finding such statistically discriminative sub-trajectories from massive trajectory dataset is both computationally and statistically challenging. In the SDSM method, we resolve the difficulties by introducing a tree representation among sub-trajectories and running an efficient permutation-based statistical inference method on the tree. To the best of our knowledge, SDSM is the first method that can efficiently extract statistically discriminative sub-trajectories from massive trajectory dataset. We illustrate the effectiveness and scalability of the SDSM method by applying it to a real-world dataset with 1,000,000 trajectories which contains 16,723,602,505 sub-trajectories.</p></details> |  |
| **[Trajectory Prediction with Linguistic Representations](https://arxiv.org/pdf/2110.09741v2)** | 2022-03-10 | [papers-cool](https://papers.cool/arxiv/2110.09741v2) | <details><summary>Show</summary><p>Language allows humans to build mental models that interpret what is happening around them resulting in more accurate long-term predictions. We present a novel trajectory prediction model that uses linguistic intermediate representations to forecast trajectories, and is trained using trajectory samples with partially-annotated captions. The model learns the meaning of each of the words without direct per-word supervision. At inference time, it generates a linguistic description of trajectories which captures maneuvers and interactions over an extended time interval. This generated description is used to refine predictions of the trajectories of multiple agents. We train and validate our model on the Argoverse dataset, and demonstrate improved accuracy results in trajectory prediction. In addition, our model is more interpretable: it presents part of its reasoning in plain language as captions, which can aid model development and can aid in building confidence in the model before deploying it.</p></details> | <details><summary>Accep...</summary><p>Accepted in ICRA 2022</p></details> |
| **[Certified Human Trajectory Prediction](https://arxiv.org/pdf/2403.13778v2)** | 2025-06-10 | [papers-cool](https://papers.cool/arxiv/2403.13778v2) | <details><summary>Show</summary><p>Predicting human trajectories is essential for the safe operation of autonomous vehicles, yet current data-driven models often lack robustness in case of noisy inputs such as adversarial examples or imperfect observations. Although some trajectory prediction methods have been developed to provide empirical robustness, these methods are heuristic and do not offer guaranteed robustness. In this work, we propose a certification approach tailored for trajectory prediction that provides guaranteed robustness. To this end, we address the unique challenges associated with trajectory prediction, such as unbounded outputs and multi-modality. To mitigate the inherent performance drop through certification, we propose a diffusion-based trajectory denoiser and integrate it into our method. Moreover, we introduce new certified performance metrics to reliably measure the trajectory prediction performance. Through comprehensive experiments, we demonstrate the accuracy and robustness of the certified predictors and highlight their advantages over the non-certified ones. The code is available online: https://s-attack.github.io/.</p></details> | CVPR 2025 |
| **[Trajectory-Prediction with Vision: A Survey](https://arxiv.org/pdf/2303.13354v1)** | 2023-03-24 | [papers-cool](https://papers.cool/arxiv/2303.13354v1) | <details><summary>Show</summary><p>To plan a safe and efficient route, an autonomous vehicle should anticipate future trajectories of other agents around it. Trajectory prediction is an extremely challenging task which recently gained a lot of attention in the autonomous vehicle research community. Trajectory-prediction forecasts future state of all the dynamic agents in the scene given their current and past states. A good prediction model can prevent collisions on the road, and hence the ultimate goal for autonomous vehicles: Collision rate: collisions per Million miles. The objective of this paper is to provide an overview of the field trajectory-prediction. We categorize the relevant algorithms into different classes so that researchers can follow through the trends in the trajectory-prediction research field. Moreover we also touch upon the background knowledge required to formulate a trajectory-prediction problem.</p></details> |  |
| **[Trajectory PHD and CPHD filters](https://arxiv.org/pdf/1811.08820v3)** | 2019-10-28 | [papers-cool](https://papers.cool/arxiv/1811.08820v3) | <details><summary>Show</summary><p>This paper presents the probability hypothesis density filter (PHD) and the cardinality PHD (CPHD) filter for sets of trajectories, which are referred to as the trajectory PHD (TPHD) and trajectory CPHD (TCPHD) filters. Contrary to the PHD/CPHD filters, the TPHD/TCPHD filters are able to produce trajectory estimates from first principles. The TPHD filter is derived by recursively obtaining the best Poisson multitrajectory density approximation to the posterior density over the alive trajectories by minimising the Kullback-Leibler divergence. The TCPHD is derived in the same way but propagating an independent identically distributed (IID) cluster multitrajectory density approximation. We also propose the Gaussian mixture implementations of the TPHD and TCPHD recursions, the Gaussian mixture TPHD (GMTPHD) and the Gaussian mixture TCPHD (GMTCPHD), and the L-scan computationally efficient implementations, which only update the density of the trajectory states of the last L time steps.</p></details> | <details><summary>MATLA...</summary><p>MATLAB implementations are provided here: https://github.com/Agarciafernandez/MTT</p></details> |
| **[Bridging Traffic State and Trajectory for Dynamic Road Network and Trajectory Representation Learning](https://arxiv.org/pdf/2502.06870v1)** | 2025-02-12 | [papers-cool](https://papers.cool/arxiv/2502.06870v1) | <details><summary>Show</summary><p>Effective urban traffic management is vital for sustainable city development, relying on intelligent systems with machine learning tasks such as traffic flow prediction and travel time estimation. Traditional approaches usually focus on static road network and trajectory representation learning, and overlook the dynamic nature of traffic states and trajectories, which is crucial for downstream tasks. To address this gap, we propose TRACK, a novel framework to bridge traffic state and trajectory data for dynamic road network and trajectory representation learning. TRACK leverages graph attention networks (GAT) to encode static and spatial road segment features, and introduces a transformer-based model for trajectory representation learning. By incorporating transition probabilities from trajectory data into GAT attention weights, TRACK captures dynamic spatial features of road segments. Meanwhile, TRACK designs a traffic transformer encoder to capture the spatial-temporal dynamics of road segments from traffic state data. To further enhance dynamic representations, TRACK proposes a co-attentional transformer encoder and a trajectory-traffic state matching task. Extensive experiments on real-life urban traffic datasets demonstrate the superiority of TRACK over state-of-the-art baselines. Case studies confirm TRACK's ability to capture spatial-temporal dynamics effectively.</p></details> | 9 pages, 6 figures |
| **[Classifying Spatial Trajectories](https://arxiv.org/pdf/2209.01322v1)** | 2022-09-07 | [papers-cool](https://papers.cool/arxiv/2209.01322v1) | <details><summary>Show</summary><p>We provide the first comprehensive study on how to classify trajectories using only their spatial representations, measured on 5 real-world data sets. Our comparison considers 20 distinct classifiers arising either as a KNN classifier of a popular distance, or as a more general type of classifier using a vectorized representation of each trajectory. We additionally develop new methods for how to vectorize trajectories via a data-driven method to select the associated landmarks, and these methods prove among the most effective in our study. These vectorized approaches are simple and efficient to use, and also provide state-of-the-art accuracy on an established transportation mode classification task. In all, this study sets the standard for how to classify trajectories, including introducing new simple techniques to achieve these results, and sets a rigorous standard for the inevitable future study on this topic.</p></details> | 21 pages, 15 figures |
| **[Feature Disentanglement of Robot Trajectories](https://arxiv.org/pdf/2112.03164v1)** | 2021-12-07 | [papers-cool](https://papers.cool/arxiv/2112.03164v1) | <details><summary>Show</summary><p>Modeling trajectories generated by robot joints is complex and required for high level activities like trajectory generation, clustering, and classification. Disentagled representation learning promises advances in unsupervised learning, but they have not been evaluated in robot-generated trajectories. In this paper we evaluate three disentangling VAEs ($$-VAE, Decorr VAE, and a new $$-Decorr VAE) on a dataset of 1M robot trajectories generated from a 3 DoF robot arm. We find that the decorrelation-based formulations perform the best in terms of disentangling metrics, trajectory quality, and correlation with ground truth latent features. We expect that these results increase the use of unsupervised learning in robot control.</p></details> | <details><summary>5 pag...</summary><p>5 pages, 3 figures, 1 table, with supplementary</p></details> |
| **[A Trajectory UML profile For Modeling Trajectory Data: A Mobile Hospital Use Case](https://arxiv.org/pdf/1102.4429v1)** | 2011-02-23 | [papers-cool](https://papers.cool/arxiv/1102.4429v1) | <details><summary>Show</summary><p>A large amount of data resulting from trajectories of moving objects activities are collected thanks to localization based services and some associated automated processes. Trajectories data can be used either for transactional and analysis purposes in various domains (heath care, commerce, environment, etc.). For this reason, modeling trajectory data at the conceptual level is an important stair leading to global vision and successful implementations. However, current modeling tools fail to fulfill specific moving objects activities requirements. In this paper, we propose a new profile based on UML in order to enhance the conceptual modeling of trajectory data related to mobile objects by new stereotypes and icons. As illustration, we present a mobile hospital use case.</p></details> | 5 pages |
| **[The Mean of Multi-Object Trajectories](https://arxiv.org/pdf/2504.20391v2)** | 2025-09-19 | [papers-cool](https://papers.cool/arxiv/2504.20391v2) | <details><summary>Show</summary><p>This paper introduces the concept of a mean for trajectories and multi-object trajectories (defined as sets or multi-sets of trajectories) along with algorithms for computing them. Specifically, we use the Frchet mean, and metrics based on the optimal sub-pattern assignment (OSPA) construct, to extend the notion of average from vectors to trajectories and multi-object trajectories. Further, we develop efficient algorithms to compute these means using greedy search and Gibbs sampling. Using distributed multi-object tracking as an application, we demonstrate that the Frchet mean approach to multi-object trajectory consensus significantly outperforms state-of-the-art distributed multi-object tracking methods.</p></details> |  |
| **[A survey on trajectory clustering analysis](https://arxiv.org/pdf/1802.06971v1)** | 2018-02-21 | [papers-cool](https://papers.cool/arxiv/1802.06971v1) | <details><summary>Show</summary><p>This paper comprehensively surveys the development of trajectory clustering. Considering the critical role of trajectory data mining in modern intelligent systems for surveillance security, abnormal behavior detection, crowd behavior analysis, and traffic control, trajectory clustering has attracted growing attention. Existing trajectory clustering methods can be grouped into three categories: unsupervised, supervised and semi-supervised algorithms. In spite of achieving a certain level of development, trajectory clustering is limited in its success by complex conditions such as application scenarios and data dimensions. This paper provides a holistic understanding and deep insight into trajectory clustering, and presents a comprehensive analysis of representative methods and promising future directions.</p></details> |  |
| **[Disease Trajectory Maps](https://arxiv.org/pdf/1606.09184v1)** | 2016-06-30 | [papers-cool](https://papers.cool/arxiv/1606.09184v1) | <details><summary>Show</summary><p>Medical researchers are coming to appreciate that many diseases are in fact complex, heterogeneous syndromes composed of subpopulations that express different variants of a related complication. Time series data extracted from individual electronic health records (EHR) offer an exciting new way to study subtle differences in the way these diseases progress over time. In this paper, we focus on answering two questions that can be asked using these databases of time series. First, we want to understand whether there are individuals with similar disease trajectories and whether there are a small number of degrees of freedom that account for differences in trajectories across the population. Second, we want to understand how important clinical outcomes are associated with disease trajectories. To answer these questions, we propose the Disease Trajectory Map (DTM), a novel probabilistic model that learns low-dimensional representations of sparse and irregularly sampled time series. We propose a stochastic variational inference algorithm for learning the DTM that allows the model to scale to large modern medical datasets. To demonstrate the DTM, we analyze data collected on patients with the complex autoimmune disease, scleroderma. We find that DTM learns meaningful representations of disease trajectories and that the representations are significantly associated with important clinical outcomes.</p></details> |  |
| **[Planning Optimal Trajectories for Mobile Manipulators under End-effector Trajectory Continuity Constraint](https://arxiv.org/pdf/2309.12251v2)** | 2024-03-07 | [papers-cool](https://papers.cool/arxiv/2309.12251v2) | <details><summary>Show</summary><p>Mobile manipulators have been employed in many applications that are traditionally performed by either multiple fixed-base robots or a large robotic system. This capability is enabled by the mobility of the mobile base. However, the mobile base also brings redundancy to the system, which makes mobile manipulator motion planning more challenging. In this paper, we tackle the mobile manipulator motion planning problem under the end-effector trajectory continuity constraint in which the end-effector is required to traverse a continuous task-space trajectory (time-parametrized path), such as in mobile printing or spraying applications. Our method decouples the problem into: (1) planning an optimal base trajectory subject to geometric task constraints, end-effector trajectory continuity constraint, collision avoidance, and base velocity constraint; which ensures that (2) a manipulator trajectory is computed subsequently based on the obtained base trajectory. To validate our method, we propose a discrete optimal base trajectory planning algorithm to solve several mobile printing tasks in hardware experiment and simulations.</p></details> | <details><summary>Accep...</summary><p>Accepted for ICRA 2024</p></details> |
| **[Quantifying Intrinsic Value of Information of Trajectories](https://arxiv.org/pdf/2108.12450v2)** | 2021-09-09 | [papers-cool](https://papers.cool/arxiv/2108.12450v2) | <details><summary>Show</summary><p>A trajectory, defined as a sequence of location measurements, contains valuable information about movements of an individual. Its value of information (VOI) may change depending on the specific application. However, in a variety of applications, knowing the intrinsic VOI of a trajectory is important to guide other subsequent tasks or decisions. This work aims to find a principled framework to quantify the intrinsic VOI of trajectories from the owner's perspective. This is a challenging problem because an appropriate framework needs to take into account various characteristics of the trajectory, prior knowledge, and different types of trajectory degradation. We propose a framework based on information gain (IG) as a principled approach to solve this problem. Our IG framework transforms a trajectory with discrete-time measurements to a canonical representation, i.e., continuous in time with continuous mean and variance estimates, and then quantifies the reduction of uncertainty about the locations of the owner over a period of time as the VOI of the trajectory. Qualitative and extensive quantitative evaluation show that the IG framework is capable of effectively capturing important characteristics contributing to the VOI of trajectories.</p></details> | <details><summary>10 pa...</summary><p>10 pages, SIGSPATIAL'21</p></details> |
| **[Evolution-Preserving Dense Trajectory Descriptors](https://arxiv.org/pdf/1702.04037v1)** | 2017-02-15 | [papers-cool](https://papers.cool/arxiv/1702.04037v1) | <details><summary>Show</summary><p>Recently Trajectory-pooled Deep-learning Descriptors were shown to achieve state-of-the-art human action recognition results on a number of datasets. This paper improves their performance by applying rank pooling to each trajectory, encoding the temporal evolution of deep learning features computed along the trajectory. This leads to Evolution-Preserving Trajectory (EPT) descriptors, a novel type of video descriptor that significantly outperforms Trajectory-pooled Deep-learning Descriptors. EPT descriptors are defined based on dense trajectories, and they provide complimentary benefits to video descriptors that are not based on trajectories. In particular, we show that the combination of EPT descriptors and VideoDarwin leads to state-of-the-art performance on Hollywood2 and UCF101 datasets.</p></details> |  |
| **[Distribution-Based Trajectory Clustering](https://arxiv.org/pdf/2310.05123v2)** | 2023-10-31 | [papers-cool](https://papers.cool/arxiv/2310.05123v2) | <details><summary>Show</summary><p>Trajectory clustering enables the discovery of common patterns in trajectory data. Current methods of trajectory clustering rely on a distance measure between two points in order to measure the dissimilarity between two trajectories. The distance measures employed have two challenges: high computational cost and low fidelity. Independent of the distance measure employed, existing clustering algorithms have another challenge: either effectiveness issues or high time complexity. In this paper, we propose to use a recent Isolation Distributional Kernel (IDK) as the main tool to meet all three challenges. The new IDK-based clustering algorithm, called TIDKC, makes full use of the distributional kernel for trajectory similarity measuring and clustering. TIDKC identifies non-linearly separable clusters with irregular shapes and varied densities in linear time. It does not rely on random initialisation and is robust to outliers. An extensive evaluation on 7 large real-world trajectory datasets confirms that IDK is more effective in capturing complex structures in trajectories than traditional and deep learning-based distance measures. Furthermore, the proposed TIDKC has superior clustering performance and efficiency to existing trajectory clustering algorithms.</p></details> |  |
| **[Manipulating Trajectory Prediction with Backdoors](https://arxiv.org/pdf/2312.13863v2)** | 2024-01-04 | [papers-cool](https://papers.cool/arxiv/2312.13863v2) | <details><summary>Show</summary><p>Autonomous vehicles ought to predict the surrounding agents' trajectories to allow safe maneuvers in uncertain and complex traffic situations. As companies increasingly apply trajectory prediction in the real world, security becomes a relevant concern. In this paper, we focus on backdoors - a security threat acknowledged in other fields but so far overlooked for trajectory prediction. To this end, we describe and investigate four triggers that could affect trajectory prediction. We then show that these triggers (for example, a braking vehicle), when correlated with a desired output (for example, a curve) during training, cause the desired output of a state-of-the-art trajectory prediction model. In other words, the model has good benign performance but is vulnerable to backdoors. This is the case even if the trigger maneuver is performed by a non-casual agent behind the target vehicle. As a side-effect, our analysis reveals interesting limitations within trajectory prediction models. Finally, we evaluate a range of defenses against backdoors. While some, like simple offroad checks, do not enable detection for all triggers, clustering is a promising candidate to support manual inspection to find backdoors.</p></details> | 9 pages, 7 figures |
| **[E.T. the Exceptional Trajectories: Text-to-camera-trajectory generation with character awareness](https://arxiv.org/pdf/2407.01516v1)** | 2024-07-02 | [papers-cool](https://papers.cool/arxiv/2407.01516v1) | <details><summary>Show</summary><p>Stories and emotions in movies emerge through the effect of well-thought-out directing decisions, in particular camera placement and movement over time. Crafting compelling camera trajectories remains a complex iterative process, even for skilful artists. To tackle this, in this paper, we propose a dataset called the Exceptional Trajectories (E.T.) with camera trajectories along with character information and textual captions encompassing descriptions of both camera and character. To our knowledge, this is the first dataset of its kind. To show the potential applications of the E.T. dataset, we propose a diffusion-based approach, named DIRECTOR, which generates complex camera trajectories from textual captions that describe the relation and synchronisation between the camera and characters. To ensure robust and accurate evaluations, we train on the E.T. dataset CLaTr, a Contrastive Language-Trajectory embedding for evaluation metrics. We posit that our proposed dataset and method significantly advance the democratization of cinematography, making it more accessible to common users.</p></details> | <details><summary>ECCV ...</summary><p>ECCV 2024. Project page: https://www.lix.polytechnique.fr/vista/projects/2024_et_courant/</p></details> |
| **[Optimizing Vessel Trajectory Compression](https://arxiv.org/pdf/2005.05418v1)** | 2020-05-13 | [papers-cool](https://papers.cool/arxiv/2005.05418v1) | <details><summary>Show</summary><p>In previous work we introduced a trajectory detection module that can provide summarized representations of vessel trajectories by consuming AIS positional messages online. This methodology can provide reliable trajectory synopses with little deviations from the original course by discarding at least 70% of the raw data as redundant. However, such trajectory compression is very sensitive to parametrization. In this paper, our goal is to fine-tune the selection of these parameter values. We take into account the type of each vessel in order to provide a suitable configuration that can yield improved trajectory synopses, both in terms of approximation error and compression ratio. Furthermore, we employ a genetic algorithm converging to a suitable configuration per vessel type. Our tests against a publicly available AIS dataset have shown that compression efficiency is comparable or even better than the one with default parametrization without resorting to a laborious data inspection.</p></details> |  |
| **[Probabilistic Trajectory Prediction with Structural Constraints](https://arxiv.org/pdf/2107.04193v1)** | 2021-07-12 | [papers-cool](https://papers.cool/arxiv/2107.04193v1) | <details><summary>Show</summary><p>This work addresses the problem of predicting the motion trajectories of dynamic objects in the environment. Recent advances in predicting motion patterns often rely on machine learning techniques to extrapolate motion patterns from observed trajectories, with no mechanism to directly incorporate known rules. We propose a novel framework, which combines probabilistic learning and constrained trajectory optimisation. The learning component of our framework provides a distribution over future motion trajectories conditioned on observed past coordinates. This distribution is then used as a prior to a constrained optimisation problem which enforces chance constraints on the trajectory distribution. This results in constraint-compliant trajectory distributions which closely resemble the prior. In particular, we focus our investigation on collision constraints, such that extrapolated future trajectory distributions conform to the environment structure. We empirically demonstrate on real-world and simulated datasets the ability of our framework to learn complex probabilistic motion trajectories for motion data, while directly enforcing constraints to improve generalisability, producing more robust and higher quality trajectory distributions.</p></details> | <details><summary>To ap...</summary><p>To appear at IROS 2021</p></details> |
| **[Efficient and Private Federated Trajectory Matching](https://arxiv.org/pdf/2312.12012v1)** | 2023-12-20 | [papers-cool](https://papers.cool/arxiv/2312.12012v1) | <details><summary>Show</summary><p>Federated Trajectory Matching (FTM) is gaining increasing importance in big trajectory data analytics, supporting diverse applications such as public health, law enforcement, and emergency response. FTM retrieves trajectories that match with a query trajectory from a large-scale trajectory database, while safeguarding the privacy of trajectories in both the query and the database. A naive solution to FTM is to process the query through Secure Multi-Party Computation (SMC) across the entire database, which is inherently secure yet inevitably slow due to the massive secure operations. A promising acceleration strategy is to filter irrelevant trajectories from the database based on the query, thus reducing the SMC operations. However, a key challenge is how to publish the query in a way that both preserves privacy and enables efficient trajectory filtering. In this paper, we design GIST, a novel framework for efficient Federated Trajectory Matching. GIST is grounded in Geo-Indistinguishability, a privacy criterion dedicated to locations. It employs a new privacy mechanism for the query that facilitates efficient trajectory filtering. We theoretically prove the privacy guarantee of the mechanism and the accuracy of the filtering strategy of GIST. Extensive evaluations on five real datasets show that GIST is significantly faster and incurs up to 3 orders of magnitude lower communication cost than the state-of-the-arts.</p></details> | 14 pages |
| **[Adversarially Learned Abnormal Trajectory Classifier](https://arxiv.org/pdf/1903.11040v2)** | 2019-04-05 | [papers-cool](https://papers.cool/arxiv/1903.11040v2) | <details><summary>Show</summary><p>We address the problem of abnormal event detection from trajectory data. In this paper, a new adversarial approach is proposed for building a deep neural network binary classifier, trained in an unsupervised fashion, that can distinguish normal from abnormal trajectory-based events without the need for setting manual detection threshold. Inspired by the generative adversarial network (GAN) framework, our GAN version is a discriminative one in which the discriminator is trained to distinguish normal and abnormal trajectory reconstruction errors given by a deep autoencoder. With urban traffic videos and their associated trajectories, our proposed method gives the best accuracy for abnormal trajectory detection. In addition, our model can easily be generalized for abnormal trajectory-based event detection and can still yield the best behavioural detection results as demonstrated on the CAVIAR dataset.</p></details> | <details><summary>Accep...</summary><p>Accepted for the 16th Conference on Computer and Robot Vision (CRV) 2019</p></details> |
| **[Pattern Ensembling for Spatial Trajectory Reconstruction](https://arxiv.org/pdf/2101.09844v1)** | 2021-01-26 | [papers-cool](https://papers.cool/arxiv/2101.09844v1) | <details><summary>Show</summary><p>Digital sensing provides an unprecedented opportunity to assess and understand mobility. However, incompleteness, missing information, possible inaccuracies, and temporal heterogeneity in the geolocation data can undermine its applicability. As mobility patterns are often repeated, we propose a method to use similar trajectory patterns from the local vicinity and probabilistically ensemble them to robustly reconstruct missing or unreliable observations. We evaluate the proposed approach in comparison with traditional functional trajectory interpolation using a case of sea vessel trajectory data provided by The Automatic Identification System (AIS). By effectively leveraging the similarities in real-world trajectories, our pattern ensembling method helps to reconstruct missing trajectory segments of extended length and complex geometry. It can be used for locating mobile objects when temporary unobserved as well as for creating an evenly sampled trajectory interpolation useful for further trajectory mining.</p></details> | 11 pages, 5 figures |
| **[Revisiting CNNs for Trajectory Similarity Learning](https://arxiv.org/pdf/2405.19761v2)** | 2024-11-06 | [papers-cool](https://papers.cool/arxiv/2405.19761v2) | <details><summary>Show</summary><p>Similarity search is a fundamental but expensive operator in querying trajectory data, due to its quadratic complexity of distance computation. To mitigate the computational burden for long trajectories, neural networks have been widely employed for similarity learning and each trajectory is encoded as a high-dimensional vector for similarity search with linear complexity. Given the sequential nature of trajectory data, previous efforts have been primarily devoted to the utilization of RNNs or Transformers. In this paper, we argue that the common practice of treating trajectory as sequential data results in excessive attention to capturing long-term global dependency between two sequences. Instead, our investigation reveals the pivotal role of local similarity, prompting a revisit of simple CNNs for trajectory similarity learning. We introduce ConvTraj, incorporating both 1D and 2D convolutions to capture sequential and geo-distribution features of trajectories, respectively. In addition, we conduct a series of theoretical analyses to justify the effectiveness of ConvTraj. Experimental results on four real-world large-scale datasets demonstrate that ConvTraj achieves state-of-the-art accuracy in trajectory similarity search. Owing to the simple network structure of ConvTraj, the training and inference speed on the Porto dataset with 1.6 million trajectories are increased by at least $240$x and $2.16$x, respectively. The source code and dataset can be found at \textit{\url{https://github.com/Proudc/ConvTraj}}.</p></details> |  |
| **[Streaming Flow Policy: Simplifying diffusion/flow-matching policies by treating action trajectories as flow trajectories](https://arxiv.org/pdf/2505.21851v2)** | 2025-09-26 | [papers-cool](https://papers.cool/arxiv/2505.21851v2) | <details><summary>Show</summary><p>Recent advances in diffusion$/$flow-matching policies have enabled imitation learning of complex, multi-modal action trajectories. However, they are computationally expensive because they sample a trajectory of trajectories: a diffusion$/$flow trajectory of action trajectories. They discard intermediate action trajectories, and must wait for the sampling process to complete before any actions can be executed on the robot. We simplify diffusion$/$flow policies by treating action trajectories as flow trajectories. Instead of starting from pure noise, our algorithm samples from a narrow Gaussian around the last action. Then, it incrementally integrates a velocity field learned via flow matching to produce a sequence of actions that constitute a single trajectory. This enables actions to be streamed to the robot on-the-fly during the flow sampling process, and is well-suited for receding horizon policy execution. Despite streaming, our method retains the ability to model multi-modal behavior. We train flows that stabilize around demonstration trajectories to reduce distribution shift and improve imitation learning performance. Streaming flow policy outperforms prior methods while enabling faster policy execution and tighter sensorimotor loops for learning-based robot control. Project website: https://streaming-flow-policy.github.io/</p></details> | <details><summary>Confe...</summary><p>Conference on Robot Learning (CoRL) 2025</p></details> |
| **[Enhancing motion trajectory segmentation of rigid bodies using a novel screw-based trajectory-shape representation](https://arxiv.org/pdf/2309.11413v1)** | 2024-10-28 | [papers-cool](https://papers.cool/arxiv/2309.11413v1) | <details><summary>Show</summary><p>Trajectory segmentation refers to dividing a trajectory into meaningful consecutive sub-trajectories. This paper focuses on trajectory segmentation for 3D rigid-body motions. Most segmentation approaches in the literature represent the body's trajectory as a point trajectory, considering only its translation and neglecting its rotation. We propose a novel trajectory representation for rigid-body motions that incorporates both translation and rotation, and additionally exhibits several invariant properties. This representation consists of a geometric progress rate and a third-order trajectory-shape descriptor. Concepts from screw theory were used to make this representation time-invariant and also invariant to the choice of body reference point. This new representation is validated for a self-supervised segmentation approach, both in simulation and using real recordings of human-demonstrated pouring motions. The results show a more robust detection of consecutive submotions with distinct features and a more consistent segmentation compared to conventional representations. We believe that other existing segmentation methods may benefit from using this trajectory representation to improve their invariance.</p></details> | <details><summary>This ...</summary><p>This work has been submitted to the IEEE International Conference on Robotics and Automation (ICRA) for possible publication</p></details> |
| **[Constrained Stein Variational Trajectory Optimization](https://arxiv.org/pdf/2308.12110v3)** | 2024-07-24 | [papers-cool](https://papers.cool/arxiv/2308.12110v3) | <details><summary>Show</summary><p>We present Constrained Stein Variational Trajectory Optimization (CSVTO), an algorithm for performing trajectory optimization with constraints on a set of trajectories in parallel. We frame constrained trajectory optimization as a novel form of constrained functional minimization over trajectory distributions, which avoids treating the constraints as a penalty in the objective and allows us to generate diverse sets of constraint-satisfying trajectories. Our method uses Stein Variational Gradient Descent (SVGD) to find a set of particles that approximates a distribution over low-cost trajectories while obeying constraints. CSVTO is applicable to problems with differentiable equality and inequality constraints and includes a novel particle re-sampling step to escape local minima. By explicitly generating diverse sets of trajectories, CSVTO is better able to avoid poor local minima and is more robust to initialization. We demonstrate that CSVTO outperforms baselines in challenging highly-constrained tasks, such as a 7DoF wrench manipulation task, where CSVTO outperforms all baselines both in success and constraint satisfaction.</p></details> | <details><summary>18 pa...</summary><p>18 pages, 10 figures, 3 tables</p></details> |
| **[Gaussian Process for Trajectories](https://arxiv.org/pdf/2110.03712v1)** | 2021-10-11 | [papers-cool](https://papers.cool/arxiv/2110.03712v1) | <details><summary>Show</summary><p>The Gaussian process is a powerful and flexible technique for interpolating spatiotemporal data, especially with its ability to capture complex trends and uncertainty from the input signal. This chapter describes Gaussian processes as an interpolation technique for geospatial trajectories. A Gaussian process models measurements of a trajectory as coming from a multidimensional Gaussian, and it produces for each timestamp a Gaussian distribution as a prediction. We discuss elements that need to be considered when applying Gaussian process to trajectories, common choices for those elements, and provide a concrete example of implementing a Gaussian process.</p></details> | <details><summary>Spati...</summary><p>SpatialGems workshop 2021, 7 pages</p></details> |
| **[Computing Similarity between a Pair of Trajectories](https://arxiv.org/pdf/1303.1585v1)** | 2013-03-08 | [papers-cool](https://papers.cool/arxiv/1303.1585v1) | <details><summary>Show</summary><p>With recent advances in sensing and tracking technology, trajectory data is becoming increasingly pervasive and analysis of trajectory data is becoming exceedingly important. A fundamental problem in analyzing trajectory data is that of identifying common patterns between pairs or among groups of trajectories. In this paper, we consider the problem of identifying similar portions between a pair of trajectories, each observed as a sequence of points sampled from it. We present new measures of trajectory similarity --- both local and global --- between a pair of trajectories to distinguish between similar and dissimilar portions. Our model is robust under noise and outliers, it does not make any assumptions on the sampling rates on either trajectory, and it works even if they are partially observed. Additionally, the model also yields a scalar similarity score which can be used to rank multiple pairs of trajectories according to similarity, e.g. in clustering applications. We also present efficient algorithms for computing the similarity under our measures; the worst-case running time is quadratic in the number of sample points. Finally, we present an extensive experimental study evaluating the effectiveness of our approach on real datasets, comparing with it with earlier approaches, and illustrating many issues that arise in trajectory data. Our experiments show that our approach is highly accurate in distinguishing similar and dissimilar portions as compared to earlier methods even with sparse sampling.</p></details> |  |
| **[Trajectory Synthesis for Fisher Information Maximization](https://arxiv.org/pdf/1709.03426v1)** | 2017-09-12 | [papers-cool](https://papers.cool/arxiv/1709.03426v1) | <details><summary>Show</summary><p>Estimation of model parameters in a dynamic system can be significantly improved with the choice of experimental trajectory. For general, nonlinear dynamic systems, finding globally "best" trajectories is typically not feasible; however, given an initial estimate of the model parameters and an initial trajectory, we present a continuous-time optimization method that produces a locally optimal trajectory for parameter estimation in the presence of measurement noise. The optimization algorithm is formulated to find system trajectories that improve a norm on the Fisher information matrix. A double-pendulum cart apparatus is used to numerically and experimentally validate this technique. In simulation, the optimized trajectory increases the minimum eigenvalue of the Fisher information matrix by three orders of magnitude compared to the initial trajectory. Experimental results show that this optimized trajectory translates to an order of magnitude improvement in the parameter estimate error in practice.</p></details> | 12 pages |
| **[Deep Trajectory for Recognition of Human Behaviours](https://arxiv.org/pdf/1905.10357v1)** | 2019-05-27 | [papers-cool](https://papers.cool/arxiv/1905.10357v1) | <details><summary>Show</summary><p>Identifying human actions in complex scenes is widely considered as a challenging research problem due to the unpredictable behaviors and variation of appearances and postures. For extracting variations in motion and postures, trajectories provide meaningful way. However, simple trajectories are normally represented by vector of spatial coordinates. In order to identify human actions, we must exploit structural relationship between different trajectories. In this paper, we propose a method that divides the video into N number of segments and then for each segment we extract trajectories. We then compute trajectory descriptor for each segment which capture the structural relationship among different trajectories in the video segment. For trajectory descriptor, we project all extracted trajectories on the canvas. This will result in texture image which can store the relative motion and structural relationship among the trajectories. We then train Convolution Neural Network (CNN) to capture and learn the representation from dense trajectories. . Experimental results shows that our proposed method out performs state of the art methods by 90.01% on benchmark data set.</p></details> |  |
| **[Universal Retrieval for Multimodal Trajectory Modeling](https://arxiv.org/pdf/2506.22056v1)** | 2025-06-30 | [papers-cool](https://papers.cool/arxiv/2506.22056v1) | <details><summary>Show</summary><p>Trajectory data, capturing human actions and environmental states across various modalities, holds significant potential for enhancing AI agent capabilities, particularly in GUI environments. However, how to model the representation of trajectory-level data presents a significant challenge that has not been systematically addressed amid explosive trajectory data growth. In this work, we introduce Multimodal Trajectory Retrieval, bridging the gap between universal retrieval and agent-centric trajectory modeling. We construct the Unified Agent Trajectory Dataset (UATD) from annotated demonstrations and states across diverse real-world scenarios. Based on this, we present GAE-Bench, a benchmark containing a large number of trajectory-based retrieval pairs. In addition, we propose GAE-Retriever, a multimodal retrieval framework that adopts vision-language models and incorporates optimized contrastive learning through a token selection and the GradCache mechanism. Comprehensive evaluations across multiple datasets show that GAE-Retriever consistently outperforms strong baselines in retrieval recall, highlighting its effectiveness in advancing multimodal trajectory retrieval.</p></details> | <details><summary>18 pa...</summary><p>18 pages, 3 figures, accepted by Workshop on Computer-use Agents @ ICML 2025</p></details> |
| **[TISIS : Trajectory Indexing for SImilarity Search](https://arxiv.org/pdf/2409.11301v2)** | 2024-09-23 | [papers-cool](https://papers.cool/arxiv/2409.11301v2) | <details><summary>Show</summary><p>Social media platforms enable users to share diverse types of information, including geolocation data that captures their movement patterns. Such geolocation data can be leveraged to reconstruct the trajectory of a user's visited Points of Interest (POIs). A key requirement in numerous applications is the ability to measure the similarity between such trajectories, as this facilitates the retrieval of trajectories that are similar to a given reference trajectory. This is the main focus of our work. Existing methods predominantly rely on applying a similarity function to each candidate trajectory to identify those that are sufficiently similar. However, this approach becomes computationally expensive when dealing with large-scale datasets. To mitigate this challenge, we propose TISIS, an efficient method that uses trajectory indexing to quickly find similar trajectories that share common POIs in the same order. Furthermore, to account for scenarios where POIs in trajectories may not exactly match but are contextually similar, we introduce TISIS*, a variant of TISIS that incorporates POI embeddings. This extension allows for more comprehensive retrieval of similar trajectories by considering semantic similarities between POIs, beyond mere exact matches. Extensive experimental evaluations demonstrate that the proposed approach significantly outperforms a baseline method based on the well-known Longest Common SubSequence (LCSS) algorithm, yielding substantial performance improvements across various real-world datasets.</p></details> |  |
| **[On the Discovery of Success Trajectories of Authors](https://arxiv.org/pdf/1602.01904v1)** | 2016-02-08 | [papers-cool](https://papers.cool/arxiv/1602.01904v1) | <details><summary>Show</summary><p>Understanding the qualitative patterns of research endeavor of scientific authors in terms of publication count and their impact (citation) is important in order to quantify success trajectories. Here, we examine the career profile of authors in computer science and physics domains and discover at least six different success trajectories in terms of normalized citation count in longitudinal scale. Initial observations of individual trajectories lead us to characterize the authors in each category. We further leverage this trajectory information to build a two-stage stratification model to predict future success of an author at the early stage of her career. Our model outperforms the baseline with an average improvement of 15.68% for both the datasets.</p></details> | <details><summary>2 pag...</summary><p>2 pages, 1 figure in 25rd International World Wide Web Conference WWW 2016</p></details> |
| **[Multi-Camera Trajectory Forecasting: Pedestrian Trajectory Prediction in a Network of Cameras](https://arxiv.org/pdf/2005.00282v1)** | 2020-05-04 | [papers-cool](https://papers.cool/arxiv/2005.00282v1) | <details><summary>Show</summary><p>We introduce the task of multi-camera trajectory forecasting (MCTF), where the future trajectory of an object is predicted in a network of cameras. Prior works consider forecasting trajectories in a single camera view. Our work is the first to consider the challenging scenario of forecasting across multiple non-overlapping camera views. This has wide applicability in tasks such as re-identification and multi-target multi-camera tracking. To facilitate research in this new area, we release the Warwick-NTU Multi-camera Forecasting Database (WNMF), a unique dataset of multi-camera pedestrian trajectories from a network of 15 synchronized cameras. To accurately label this large dataset (600 hours of video footage), we also develop a semi-automated annotation method. An effective MCTF model should proactively anticipate where and when a person will re-appear in the camera network. In this paper, we consider the task of predicting the next camera a pedestrian will re-appear after leaving the view of another camera, and present several baseline approaches for this. The labeled database is available online: https://github.com/olly-styles/Multi-Camera-Trajectory-Forecasting.</p></details> | <details><summary>CVPR ...</summary><p>CVPR 2020 Precognition workshop</p></details> |

## City
| **Title** | **Date** | **KiMi** | **Abstract** | **Comment** |
| --- | --- | --- | --- | --- |
| **[IDEAL-CITIES: A Trustworthy and Sustainable Framework for Circular Smart Cities](https://arxiv.org/pdf/1907.11042v1)** | 2019-07-26 | [papers-cool](https://papers.cool/arxiv/1907.11042v1) | <details><summary>Show</summary><p>Reflecting upon the sustainability challenges cities will be facing in the near future and the recent technological developments allowing cities to become "smart", we introduce IDEAL-CITIES; a framework aiming to provide an architecture for cyber-physical systems to deliver a data-driven Circular Economy model in a city context. In the IDEAL-CITIES ecosystem, the city's finite resources as well as citizens will form the pool of intelligent assets in order to contribute to high utilization through crowdsourcing and real-time decision making and planning. We describe two use cases as a vehicle to demonstrate how a smart city can serve the Circular Economy paradigm.</p></details> |  |
| **[City Brain, a New Architecture of Smart City Based on the Internet Brain](https://arxiv.org/pdf/1710.04123v3)** | 2018-03-19 | [papers-cool](https://papers.cool/arxiv/1710.04123v3) | <details><summary>Show</summary><p>In the ten years after the Smart City was put forward, there are still problems like unclear concept, lack of top-down design and information island. With the further development of the Internet, the brain-like architecture of the Internet is becoming clearer and clearer. As a product of combination of city buildings and the Internet, the Smart City will also have a new architecture, and the city brain thus appears. Based on the Internet Brain, this paper describes how to construct the Smart City in the form of brain-like tissue, and how to evaluate the construction level of the Smart City (City IQ) relying on the Big SNS (city neural networks) and city cloud reflex arcs.</p></details> | <details><summary>12pag...</summary><p>12pages, 5 figures,25conference</p></details> |
| **[Smart Cities and Villages: Concept Review and Implementation Perspectives in Developing Cities](https://arxiv.org/pdf/2402.09284v1)** | 2024-02-15 | [papers-cool](https://papers.cool/arxiv/2402.09284v1) | <details><summary>Show</summary><p>The "Smart City" (SC) concept has been around for decades with deployment scenarios revealed in major cities of developed countries. However, while SC has enhanced the living conditions of city dwellers in the developed world, the concept is still either missing or poorly deployed in the developing world. This paper presents a review of the SC concept from the perspective of its application to cities in developing nations, the opportunities it avails, and challenges related to its applicability to these cities. Building upon a systematic review of literature, this paper shows that there are neither canonical definitions, models or frameworks of references for the SC concept. This paper also aims to bridge the gap between the "smart city" and "smart village" concepts, with the expectation of providing a holistic approach to solving common issues in cities around the world. Drawing inspiration from other authors, we propose a conceptual model for a SC initiative in Africa and demonstrate the need to prioritize research and capacity development. We also discuss the potential opportunities for such SC implementations in sub-Saharan Africa. As a case study, we consider the city of Lubumbashi in the Democratic Republic of Congo and discuss ways of making it a smart city by building around successful smart city initiatives. It is our belief that for Lubumbashi, as with any other city in Sub-Saharan Africa, the first step to developing a smart city is to build knowledge and create an intellectual capital.</p></details> | <details><summary>22 Pa...</summary><p>22 Pages, 4 figures, 4 Tables</p></details> |
| **[ABE-Cities: An Attribute-Based Encryption System for Smart Cities](https://arxiv.org/pdf/1807.11793v1)** | 2018-08-08 | [papers-cool](https://papers.cool/arxiv/1807.11793v1) | <details><summary>Show</summary><p>In the near future, a technological revolution will involve our cities, where a variety of smart services based on the Internet of Things will be developed to facilitate the needs of the citizens. Sensing devices are already being deployed in urban environments, and they will generate huge amounts of data. Such data are typically outsourced to some cloud storage because this lowers capital and operating expenses and guarantees high availability. However, cloud storage may have incentives to release stored data to unauthorized entities. In this work we present ABE-Cities, an encryption scheme for urban sensing which solves the above problems while ensuring fine-grained access control on data by means of Attribute-Based Encryption (ABE). Basically, ABE-Cities encrypts data before storing it in the cloud and provides users with keys able to decrypt only those portions of data the user is authorized to access. In ABE-Cities, the sensing devices perform only lightweight symmetric cryptography operations, thus they can also be resource-constrained. ABE-Cities provides planned expiration of keys, as well as their unplanned revocation. We propose methods to make the key revocation efficient, and we show by simulations the overall efficiency of ABE-Cities.</p></details> |  |
| **[Smart Cities: The Hopes and Hypes](https://arxiv.org/pdf/1907.05702v1)** | 2019-07-15 | [papers-cool](https://papers.cool/arxiv/1907.05702v1) | <details><summary>Show</summary><p>Smart cities are being planned for several advanced applications and services for the inhabitants. Smart cities initiative promise many new services which are not possible in the traditional city frameworks. In the smart city framework, the basic aim is to provide all the essential services through sensor based systems which does not need much human intervention. This system is designed to operate on its own in a self-organizing manner. Therefore, the hopes are really big from the smart cities to enhance the quality of lives and the economy. However, some of the promises in the smart cities are very much over hyped. In this article, we analyse the realities of the smart cities and their practical significances based on the technological aspects of these projects. We also address the false promises that are around which are just the hypes. We clarify these hypes with appropriate logical explanations.</p></details> | Conference paper |
| **[Amman City, Jordan: Toward a Sustainable City from the Ground Up](https://arxiv.org/pdf/2408.01454v1)** | 2024-08-06 | [papers-cool](https://papers.cool/arxiv/2408.01454v1) | <details><summary>Show</summary><p>The idea of smart cities (SCs) has gained substantial attention in recent years. The SC paradigm aims to improve citizens' quality of life and protect the city's environment. As we enter the age of next-generation SCs, it is important to explore all relevant aspects of the SC paradigm. In recent years, the advancement of Information and Communication Technologies (ICT) has produced a trend of supporting daily objects with smartness, targeting to make human life easier and more comfortable. The paradigm of SCs appears as a response to the purpose of building the city of the future with advanced features. SCs still face many challenges in their implementation, but increasingly more studies regarding SCs are implemented. Nowadays, different cities are employing SC features to enhance services or the residents quality of life. This work provides readers with useful and important information about Amman Smart City.</p></details> | <details><summary>12 pa...</summary><p>12 pages, 3 figures, 6 tables, 56 references</p></details> |
| **[MatrixCity: A Large-scale City Dataset for City-scale Neural Rendering and Beyond](https://arxiv.org/pdf/2309.16553v1)** | 2023-09-29 | [papers-cool](https://papers.cool/arxiv/2309.16553v1) | <details><summary>Show</summary><p>Neural radiance fields (NeRF) and its subsequent variants have led to remarkable progress in neural rendering. While most of recent neural rendering works focus on objects and small-scale scenes, developing neural rendering methods for city-scale scenes is of great potential in many real-world applications. However, this line of research is impeded by the absence of a comprehensive and high-quality dataset, yet collecting such a dataset over real city-scale scenes is costly, sensitive, and technically difficult. To this end, we build a large-scale, comprehensive, and high-quality synthetic dataset for city-scale neural rendering researches. Leveraging the Unreal Engine 5 City Sample project, we develop a pipeline to easily collect aerial and street city views, accompanied by ground-truth camera poses and a range of additional data modalities. Flexible controls over environmental factors like light, weather, human and car crowd are also available in our pipeline, supporting the need of various tasks covering city-scale neural rendering and beyond. The resulting pilot dataset, MatrixCity, contains 67k aerial images and 452k street images from two city maps of total size $28km^2$. On top of MatrixCity, a thorough benchmark is also conducted, which not only reveals unique challenges of the task of city-scale neural rendering, but also highlights potential improvements for future works. The dataset and code will be publicly available at our project page: https://city-super.github.io/matrixcity/.</p></details> | <details><summary>Accep...</summary><p>Accepted to ICCV 2023. Project page: $\href{https://city-super.github.io/matrixcity/}{this\, https\, URL}$</p></details> |
| **[City-LEO: Toward Transparent City Management Using LLM with End-to-End Optimization](https://arxiv.org/pdf/2406.10958v2)** | 2024-06-19 | [papers-cool](https://papers.cool/arxiv/2406.10958v2) | <details><summary>Show</summary><p>Existing operations research (OR) models and tools play indispensable roles in smart-city operations, yet their practical implementation is limited by the complexity of modeling and deficiencies in optimization proficiency. To generate more relevant and accurate solutions to users' requirements, we propose a large language model (LLM)-based agent ("City-LEO") that enhances the efficiency and transparency of city management through conversational interactions. Specifically, to accommodate diverse users' requirements and enhance computational tractability, City-LEO leverages LLM's logical reasoning capabilities on prior knowledge to scope down large-scale optimization problems efficiently. In the human-like decision process, City-LEO also incorporates End-to-end (E2E) model to synergize the prediction and optimization. The E2E framework be conducive to coping with environmental uncertainties and involving more query-relevant features, and then facilitates transparent and interpretable decision-making process. In case study, we employ City-LEO in the operations management of e-bike sharing (EBS) system. The numerical results demonstrate that City-LEO has superior performance when benchmarks against the full-scale optimization problem. With less computational time, City-LEO generates more satisfactory and relevant solutions to the users' requirements, and achieves lower global suboptimality without significantly compromising accuracy. In a broader sense, our proposed agent offers promise to develop LLM-embedded OR tools for smart-city operations management.</p></details> | <details><summary>26 pa...</summary><p>26 pages, 8 figures, 5 tables</p></details> |
| **[Human diffusion and city influence](https://arxiv.org/pdf/1501.07788v2)** | 2015-07-24 | [papers-cool](https://papers.cool/arxiv/1501.07788v2) | <details><summary>Show</summary><p>Cities are characterized by concentrating population, economic activity and services. However, not all cities are equal and a natural hierarchy at local, regional or global scales spontaneously emerges. In this work, we introduce a method to quantify city influence using geolocated tweets to characterize human mobility. Rome and Paris appear consistently as the cities attracting most diverse visitors. The ratio between locals and non-local visitors turns out to be fundamental for a city to truly be global. Focusing only on urban residents' mobility flows, a city to city network can be constructed. This network allows us to analyze centrality measures at different scales. New York and London play a predominant role at the global scale, while urban rankings suffer substantial changes if the focus is set at a regional level.</p></details> | <details><summary>9 pag...</summary><p>9 pages, 7 figures + appendix</p></details> |
| **[Procedural city modeling](https://arxiv.org/pdf/2507.18899v1)** | 2025-07-28 | [papers-cool](https://papers.cool/arxiv/2507.18899v1) | <details><summary>Show</summary><p>We propose a method to procedurally generate a familiar yet complex human artifact: the city. We are not trying to reproduce existing cities, but to generate artificial cities that are convincing and plausible by capturing developmental behavior. In addition, our results are meant to build upon themselves, such that they ought to look compelling at any point along the transition from village to metropolis. Our approach largely focuses upon land usage and building distribution for creating realistic city environments, whereas previous attempts at city modeling have mainly focused on populating road networks. Finally, we want our model to be self automated to the point that the only necessary input is a terrain description, but other high-level and low-level parameters can be specified to support artistic contributions. With the aid of agent based simulation we are generating a system of agents and behaviors that interact with one another through their effects upon a simulated environment. Our philosophy is that as each agent follows a simple behavioral rule set, a more complex behavior will tend to emerge out of the interactions between the agents and their differing rule sets. By confining our model to a set of simple rules for each class of agents, we hope to make our model extendible not only in regard to the types of structures that are produced, but also in describing the social and cultural influences prevalent in all cities</p></details> |  |
| **[When Circular Economy Meets the Smart City Ecosystem: Defining the Smart and Circular City](https://arxiv.org/pdf/2410.22012v1)** | 2024-10-30 | [papers-cool](https://papers.cool/arxiv/2410.22012v1) | <details><summary>Show</summary><p>Smart cities have been a very active research area in the past 20 years, while continuously adapting to new technological advancements and keeping up with the times regarding sustainability and climate change. In this context, there have been numerous proposals to expand the scope of smart cities, focusing on resilience and sustainability, among other aspects, resulting in terms like smart sustainable cities. At the same time, there is an ongoing discussion regarding the degree in which smart cities put people at their centre. In this work, we argue toward expanding the current smart city definition by integrating the circular economy as one of its central pillars and adopting the term smart (and) circular city. We discuss the ways a smart and circular city encompasses both sustainability and smartness in an integral manner, while also being well-positioned to foster novel business activity and models and helping to place citizens at the heart of the smart city. In this sense, we also argue that previous research in smart cities and technologies, such as those related to Industry 4.0, can serve as a cornerstone to implement circular economy activities within cities, at a scale that exceeds current activities that are based on more conventional approaches. We also outline current open challenges in this domain and research questions that still need to be addressed.</p></details> | <details><summary>Prepr...</summary><p>Preprint submitted to the 10th IEEE International Smart Cities Conference 2024 (ISC2 2024)</p></details> |
| **[An Evolutionary Note on Smart City Development in China](https://arxiv.org/pdf/2203.13169v1)** | 2022-03-25 | [papers-cool](https://papers.cool/arxiv/2203.13169v1) | <details><summary>Show</summary><p>In response to challenges posed by urbanization, David Bollier from the University of Southern California raised a new idea for city planning: a comprehensive network and applications of information technologies. IBM later echoed the idea and initiated its Smart Planet vision in 2008. After that, the smart city concept was quickly adopted by major cities throughout the world, and it has gradually evolved into a strategic choice by ambitious cities. This paper looks into the smart city trend by reviewing how the concept of smart city was proposed and what the essence of a smart city is. More specifically, the driving forces of the smart city development in China are investigated, and the key differences of smart cities between China and other countries are summarized. Finally, four big challenges to build future smart cities are discussed.</p></details> | 10 pages, 6 figures |
| **[Hypergraphs and City Street Networks](https://arxiv.org/pdf/1106.0297v1)** | 2011-06-03 | [papers-cool](https://papers.cool/arxiv/1106.0297v1) | <details><summary>Show</summary><p>The map of a city's streets constitutes a particular case of spatial complex network. However a city is not limited to its topology: it is above all a geometrical object whose particularity is to organize into short and long axes called streets. In this article we present and discuss two algorithms aiming at recovering the notion of street from a graph representation of a city. Then we show that the length of the so-called streets scales logarithmically. This phenomenon leads to assume that a city is shaped into a logic of extension and division of space.</p></details> |  |
| **[Factors Influencing Cities' Publishing Efficiency](https://arxiv.org/pdf/1805.03423v1)** | 2018-05-10 | [papers-cool](https://papers.cool/arxiv/1805.03423v1) | <details><summary>Show</summary><p>Recently, a vast number of scientific publications have been produced in cities in emerging countries. It has long been observed that the publication output of Beijing has exceeded that of any other city in the world, including such leading centres of science as Boston, New York, London, Paris, and Tokyo. Researchers have suggested that, instead of focusing on cities' total publication output, the quality of the output in terms of the number of highly cited papers should be examined. However, in the period from 2014 to 2016, Beijing produced as many highly cited papers as Boston, London, or New York. In this paper, I propose another method to measure cities' publishing performance; I focus on cities' publishing efficiency (i.e., the ratio of highly cited articles to all articles produced in that city). First, I rank 554 cities based on their publishing efficiency, then I reveal some general factors influencing cities' publishing efficiency. The general factors examined in this paper are as follows: the linguistic environment, cities' economic development level, the location of excellent organisations, cities' international collaboration patterns, and the productivity of scientific disciplines.</p></details> |  |
| **[Great cities look small](https://arxiv.org/pdf/1507.05458v1)** | 2015-07-21 | [papers-cool](https://papers.cool/arxiv/1507.05458v1) | <details><summary>Show</summary><p>Great cities connect people; failed cities isolate people. Despite the fundamental importance of physical, face-to-face social-ties in the functioning of cities, these connectivity networks are not explicitly observed in their entirety. Attempts at estimating them often rely on unrealistic over-simplifications such as the assumption of spatial homogeneity. Here we propose a mathematical model of human interactions in terms of a local strategy of maximising the number of beneficial connections attainable under the constraint of limited individual travelling-time budgets. By incorporating census and openly-available online multi-modal transport data, we are able to characterise the connectivity of geometrically and topologically complex cities. Beyond providing a candidate measure of greatness, this model allows one to quantify and assess the impact of transport developments, population growth, and other infrastructure and demographic changes on a city. Supported by validations of GDP and HIV infection rates across United States metropolitan areas, we illustrate the effect of changes in local and city-wide connectivities by considering the economic impact of two contemporary inter- and intra-city transport developments in the United Kingdom: High Speed Rail 2 and London Crossrail. This derivation of the model suggests that the scaling of different urban indicators with population size has an explicitly mechanistic origin.</p></details> | 19 pages, 8 figures |
| **[A city of cities: Measuring how 15-minutes urban accessibility shapes human mobility in Barcelona](https://arxiv.org/pdf/2103.15638v1)** | 2021-06-09 | [papers-cool](https://papers.cool/arxiv/2103.15638v1) | <details><summary>Show</summary><p>As cities expand, human mobility has become a central focus of urban planning and policy making to make cities more inclusive and sustainable. Initiatives such as the "15-minutes city" have been put in place to shift the attention from monocentric city configurations to polycentric structures, increasing the availability and diversity of local urban amenities. Ultimately they expect to increase local walkability and increase mobility within residential areas. While we know how urban amenities influence human mobility at the city level, little is known about spatial variations in this relationship. Here, we use mobile phone, census, and volunteered geographical data to measure geographic variations in the relationship between origin-destination flows and local urban accessibility in Barcelona. Using a Negative Binomial Geographically Weighted Regression model, we show that, globally, people tend to visit neighborhoods with better access to education and retail. Locally, these and other features change in sign and magnitude through the different neighborhoods of the city in ways that are not explained by administrative boundaries, and that provide deeper insights regarding urban characteristics such as rental prices. In conclusion, our work suggests that the qualities of a 15-minutes city can be measured at scale, delivering actionable insights on the polycentric structure of cities, and how people use and access this structure.</p></details> | 32 pages, 7 figures |
| **[CV-Cities: Advancing Cross-View Geo-Localization in Global Cities](https://arxiv.org/pdf/2411.12431v1)** | 2024-11-20 | [papers-cool](https://papers.cool/arxiv/2411.12431v1) | <details><summary>Show</summary><p>Cross-view geo-localization (CVGL), which involves matching and retrieving satellite images to determine the geographic location of a ground image, is crucial in GNSS-constrained scenarios. However, this task faces significant challenges due to substantial viewpoint discrepancies, the complexity of localization scenarios, and the need for global localization. To address these issues, we propose a novel CVGL framework that integrates the vision foundational model DINOv2 with an advanced feature mixer. Our framework introduces the symmetric InfoNCE loss and incorporates near-neighbor sampling and dynamic similarity sampling strategies, significantly enhancing localization accuracy. Experimental results show that our framework surpasses existing methods across multiple public and self-built datasets. To further improve globalscale performance, we have developed CV-Cities, a novel dataset for global CVGL. CV-Cities includes 223,736 ground-satellite image pairs with geolocation data, spanning sixteen cities across six continents and covering a wide range of complex scenarios, providing a challenging benchmark for CVGL. The framework trained with CV-Cities demonstrates high localization accuracy in various test cities, highlighting its strong globalization and generalization capabilities. Our datasets and codes are available at https://github.com/GaoShuang98/CVCities.</p></details> | <details><summary>Datas...</summary><p>Datasets and codes are available, accepted by IEEE JSTARS</p></details> |
| **[Multi-Layered Diagnostics for Smart Cities](https://arxiv.org/pdf/2107.09284v1)** | 2021-07-21 | [papers-cool](https://papers.cool/arxiv/2107.09284v1) | <details><summary>Show</summary><p>Smart cities use technology to improve traffic patterns, energy distribution, air quality and more. The elements of a smart city can also increase the convenience for its citizens, by integrating IT technology into many aspects of citizen interaction such as simplifying access to many of the city services. The fields of healthcare, education, culture, and shopping can all be integrated into the core of a smart city to create an infrastructure that allows citizens to live more conveniently. Actual deployment cases exist in U.S., Europe, Singapore, and South Korea. With this environment, we need to think ahead about cybersecurity and prepare countermeasures as the cyberattacks in a smart city can threaten the lives of its citizens. In this paper, we examine smart city security threats from a multilayered perspective, targeting representative elements that make up a smart city. A summary of attack scenarios and threat countermeasures are also described.</p></details> | 1 figure, 4 tables |
| **[Urban Pulse: Capturing the Rhythm of Cities](https://arxiv.org/pdf/1608.06949v2)** | 2018-01-01 | [papers-cool](https://papers.cool/arxiv/1608.06949v2) | <details><summary>Show</summary><p>Cities are inherently dynamic. Interesting patterns of behavior typically manifest at several key areas of a city over multiple temporal resolutions. Studying these patterns can greatly help a variety of experts ranging from city planners and architects to human behavioral experts. Recent technological innovations have enabled the collection of enormous amounts of data that can help in these studies. However, techniques using these data sets typically focus on understanding the data in the context of the city, thus failing to capture the dynamic aspects of the city. The goal of this work is to instead understand the city in the context of multiple urban data sets. To do so, we define the concept of an "urban pulse" which captures the spatio-temporal activity in a city across multiple temporal resolutions. The prominent pulses in a city are obtained using the topology of the data sets, and are characterized as a set of beats. The beats are then used to analyze and compare different pulses. We also design a visual exploration framework that allows users to explore the pulses within and across multiple cities under different conditions. Finally, we present three case studies carried out by experts from two different domains that demonstrate the utility of our framework.</p></details> | <details><summary>10 pa...</summary><p>10 pages, 10 figures, 1 table. Demo video: https://www.youtube.com/watch?v=J70-Ns0cFnQ . Github project: https://github.com/ViDA-NYU/urban-pulse ; Added github link</p></details> |
| **[Semantic Trails of City Explorations: How Do We Live a City](https://arxiv.org/pdf/1812.04367v2)** | 2020-01-01 | [papers-cool](https://papers.cool/arxiv/1812.04367v2) | <details><summary>Show</summary><p>The knowledge of city exploration trails of people is in short supply because of the complexity in defining meaningful trails representative of individual behaviours and in the access to actionable data. Existing datasets have only recorded isolated check-ins of activities featured by opaque venue types. In this paper, we fill the gaps in defining what is a semantic trail of city exploration and how it can be generated by integrating different data sources. Furthermore, we publicly release two datasets holding millions of semantic trails each and we discuss their most salient characteristics. We finally present an application using these datasets to build a recommender system meant to guide tourists while exploring a city.</p></details> | 10 pages, 4 figures |
| **[Cities beyond proximity](https://arxiv.org/pdf/2411.12335v1)** | 2024-11-20 | [papers-cool](https://papers.cool/arxiv/2411.12335v1) | <details><summary>Show</summary><p>The concept of `proximity-based cities' has gained attention as a new urban organizational model. Most prominently, the 15-minute city contends that cities can function more effectively, equitably and sustainably if essential, everyday services and key amenities are within a 15-minute walk or cycle. However, focusing solely on travel time risks overlooking disparities in service quality, as the proximity paradigm tends to emphasize the mere presence of an element in a location rather than bringing up more complex questions of identity, diversity, quality, value or relationships. Transitioning to value-based cities by considering more than just proximity can enhance local identity, resilience and urban democracy. Fostering bottom-up initiatives can create a culture of local care and value, while predominantly top-down governing strategies can lead to large inequalities. Balancing these approaches can maximize resilience, health and sustainability. This equilibrium has the potential to accompany sustainable growth, by encouraging the creation of innovative urban solutions and reducing inequalities.</p></details> | <details><summary>This ...</summary><p>This article is part of the theme issue 'Cocreating the future: participatory cities and digital governance', an opinion piece in Phil. Trans. R. Soc. A</p></details> |
| **[KIGLIS: Smart Networks for Smart Cities](https://arxiv.org/pdf/2106.04549v3)** | 2022-03-15 | [papers-cool](https://papers.cool/arxiv/2106.04549v3) | <details><summary>Show</summary><p>Smart cities will be characterized by a variety of intelligent and networked services, each with specific requirements for the underlying network infrastructure. While smart city architectures and services have been studied extensively, little attention has been paid to the network technology. The KIGLIS research project, consisting of a consortium of companies, universities and research institutions, focuses on artificial intelligence for optimizing fiber-optic networks of a smart city, with a special focus on future mobility applications, such as automated driving. In this paper, we present early results on our process of collecting smart city requirements for communication networks, which will lead towards reference infrastructure and architecture solutions. Finally, we suggest directions in which artificial intelligence will improve smart city networks.</p></details> | <details><summary>Accep...</summary><p>Accepted for publication at ISC2 2021</p></details> |
| **[IF-City: Intelligible Fair City Planning to Measure, Explain and Mitigate Inequality](https://arxiv.org/pdf/2202.07349v1)** | 2022-02-16 | [papers-cool](https://papers.cool/arxiv/2202.07349v1) | <details><summary>Show</summary><p>With the increasing pervasiveness of Artificial Intelligence (AI), many visual analytics tools have been proposed to examine fairness, but they mostly focus on data scientist users. Instead, tackling fairness must be inclusive and involve domain experts with specialized tools and workflows. Thus, domain-specific visualizations are needed for algorithmic fairness. Furthermore, while much work on AI fairness has focused on predictive decisions, less has been done for fair allocation and planning, which require human expertise and iterative design to integrate myriad constraints. We propose the Intelligible Fair Allocation (IF-Alloc) Framework that leverages explanations of causal attribution (Why), contrastive (Why Not) and counterfactual reasoning (What If, How To) to aid domain experts to assess and alleviate unfairness in allocation problems. We apply the framework to fair urban planning for designing cities that provide equal access to amenities and benefits for diverse resident types. Specifically, we propose an interactive visual tool, Intelligible Fair City Planner (IF-City), to help urban planners to perceive inequality across groups, identify and attribute sources of inequality, and mitigate inequality with automatic allocation simulations and constraint-satisfying recommendations. We demonstrate and evaluate the usage and usefulness of IF-City on a real neighborhood in New York City, US, with practicing urban planners from multiple countries, and discuss generalizing our findings, application, and framework to other use cases and applications of fair allocation.</p></details> | <details><summary>18 pa...</summary><p>18 pages including references and bios, 11 figures, submitted to IEEE Transactions on Visualization and Computer Graphics</p></details> |
| **[Improving Acoustic Scene Classification with City Features](https://arxiv.org/pdf/2503.16862v2)** | 2025-06-16 | [papers-cool](https://papers.cool/arxiv/2503.16862v2) | <details><summary>Show</summary><p>Acoustic scene recordings are often collected from a diverse range of cities. Most existing acoustic scene classification (ASC) approaches focus on identifying common acoustic scene patterns across cities to enhance generalization. However, the potential acoustic differences introduced by city-specific environmental and cultural factors are overlooked. In this paper, we hypothesize that the city-specific acoustic features are beneficial for the ASC task rather than being treated as noise or bias. To this end, we propose City2Scene, a novel framework that leverages city features to improve ASC. Unlike conventional approaches that may discard or suppress city information, City2Scene transfers the city-specific knowledge from pre-trained city classification models to scene classification model using knowledge distillation. We evaluate City2Scene on three datasets of DCASE Challenge Task 1, which include both scene and city labels. Experimental results demonstrate that city features provide valuable information for classifying scenes. By distilling city-specific knowledge, City2Scene effectively improves accuracy across a variety of lightweight CNN backbones, achieving competitive performance to the top-ranked solutions of DCASE Challenge in recent years.</p></details> |  |
| **[Impact Of Bike Sharing In New York City](https://arxiv.org/pdf/1808.06606v1)** | 2018-08-22 | [papers-cool](https://papers.cool/arxiv/1808.06606v1) | <details><summary>Show</summary><p>The Citi Bike deployment changes the landscape of urban mobility in New York City and provides an example of a scalable solution that many other large cities are already adopting around the world. Urban stakeholders who are considering a similar deployment would largely benefit from a quantitative assessment of the impact of bike sharing on urban transportation, as well as associated economic, social and environmental implications. While the Citi Bike usage data is publicly available, the main challenge of such an assessment is to provide an adequate baseline scenario of what would have happened in the city without the Citi Bike system. Existing efforts, including the reports of Citi Bike itself, largely imply arbitrary and often unrealistic assumptions about the alternative transportation mode people would have used otherwise (e.g. by comparing bike trips against driving). The present paper offers a balanced baseline scenario based on a transportation choice model to describe projected customer behavior in the absence of the Citi Bike system. The model also acknowledges the fact that Citi Bike might be used for recreational purposes and, therefore, not all the trips would have been actually performed, if Citi Bike would not be available. The model is trained using open Citi Bike and other urban transportation data and it is applied to assess direct benefits of Citi Bike trips for the end users, as well as for urban stakeholders across different boroughs of New York City and the nearby Jersey City. Besides estimating the travel time and cost savings, the model also reports the associated gas savings, emissions cut and additional exercise for the customers, covering all three areas of anticipated impacts - economic, social and environmental.</p></details> | 26 pages, 8 figures |
| **[LearningCity: Knowledge Generation for Smart Cities](https://arxiv.org/pdf/2104.05286v1)** | 2021-04-13 | [papers-cool](https://papers.cool/arxiv/2104.05286v1) | <details><summary>Show</summary><p>Although we have reached new levels in smart city installations and systems, efforts so far have focused on providing diverse sources of data to smart city services consumers while neglecting to provide ways to simplify making good use of them. In this context, one first step that will bring added value to smart cities is knowledge creation in smart cities through anomaly detection and data annotation, supported in both an automated and a crowdsourced manner. We present here LearningCity, our solution that has been validated over an existing smart city deployment in Santander, and the OrganiCity experimentation-as-a-service ecosystem. We discuss key challenges along with characteristic use cases, and report on our design and implementation, together with some preliminary results derived from combining large smart city datasets with machine learning.</p></details> | <details><summary>Prepr...</summary><p>Preprint of chapter submitted to "Smart Cities Performability, Cognition, & Security". EAI/Springer Innovations in Communication and Computing. Springer, Cham. arXiv admin note: text overlap with arXiv:2103.16998</p></details> |
| **[Monocentric or polycentric city? An empirical perspective](https://arxiv.org/pdf/2403.07624v1)** | 2024-03-13 | [papers-cool](https://papers.cool/arxiv/2403.07624v1) | <details><summary>Show</summary><p>Do cities have just one or several centers? Studies performing radial or monocentric analyses of cities are usually criticised by researchers stating that cities are actually polycentric, and this has been well known for a long time. Reversely, when cities are studied independently of any center, other researchers will wonder how the variables of interest evolve with the distance to the center, because this distance is known to be a major determinant at the intra-urban scale. Both monocentric and polycentric formalisms have been introduced centuries (respectively, decades) ago for the study of urban areas, and used both on the empirical and the theoretical side in different disciplines (economics, geography, complex systems, physics...). The present work performs a synthesis of both viewpoints on cities, regarding their use in the literature, and explores with data on European urban areas how some cities considered to be the most polycentric in Europe compare to more standard cities when studied through a combination of radial analysis and scaling laws.</p></details> | <details><summary>Compe...</summary><p>Compendium of Urban Complexity. Chapter 7. 16 pages</p></details> |
| **[The Role of Cloud of Things in Smart Cities](https://arxiv.org/pdf/1704.07905v1)** | 2017-04-27 | [papers-cool](https://papers.cool/arxiv/1704.07905v1) | <details><summary>Show</summary><p>The recent demographic trends indicate towards a rapidly increasing population growth and a significant portion of this increased population now prefer to live mostly in cities. In connection with this, it has become the responsibility of the government to ensure a quality standard of living in the cities and also make sure that these facilities trickle down to the next generation. A program named Smart City Mission has been started for this purpose. With an extremely diverse population, that is only second to China in the world in terms of size, the Indian government has engaged in serious thinking for a better city planning and providing numerous opportunities for the citizenry. It was, therefore, planned that the Smart City Mission program will be able to provide a highly responsive infrastructure, network security, a good living environment and the like. Internet of things (IoT) application in smart cities turns out to be the most challenging in this phase. The information available in the internet has made accessible to many devices through IoT and it also aware the citizen in many aspects. But with the increasing number of devices and information, it is now becoming increasingly difficult to depend on IoT to manage things in the internet space with a similar degree of ease. As a result, cloud-based technologies have given preferences over the existing one and IoT has been replaced by the newly introduced Cloud of Things (CoT) paradigm. This paper intends to connect different smart city applications for the betterment of city life with the Cloud of Things (CoT). Our proposed smart city architecture is based on Cloud of Things, and the focus is also given to identify the existing as well as the forthcoming challenges for the concerned program of the government. By identifying the difficulties it is expected that the project will be materialized with a great success.</p></details> | 16 pages, 14 figures |
| **[Urban DNA for cities evolutions. Cities as physical expression of dynamic equilibriums between competitive and cooperative forces](https://arxiv.org/pdf/1408.2874v3)** | 2015-10-28 | [papers-cool](https://papers.cool/arxiv/1408.2874v3) | <details><summary>Show</summary><p>Cities are physical manifestations of our competitive and cooperative behaviours. The tension between these two forces generates dynamic equilibriums whose material expressions are cities and their evolutions. In a Darwinian cooperative view, as Darwinism does not involve only competition, the public benefit obtained by cooperation, return in terms of private benefit too. An urban genetic code is proposed, according to which cities emerge connecting nature and urbanity, and as sum of multiuse, independent micro-areas, each one with its centrality, job locations, parks and daily shops-services and amenities. This mechanism, called Isobenefit Urbanism, is not static and pre-designed, but allows infinitely dynamic changes and expansions. Rather than describing The ideal city, which doesn't exist outside our own minds, Isobenefit Urbanism describes what a city should avoid to be in order to not become an unideal city. Its six principles are the urban DNA which does not give predetermined forms but indications to follow according to contexts and times. From an environmental angle, Isobenefit cities are resilient, low carbon, adaptive.</p></details> | <details><summary>http:...</summary><p>http://www.urem.eu/isobenefit/</p></details> |
| **[The 4th AI City Challenge](https://arxiv.org/pdf/2004.14619v1)** | 2020-05-01 | [papers-cool](https://papers.cool/arxiv/2004.14619v1) | <details><summary>Show</summary><p>The AI City Challenge was created to accelerate intelligent video analysis that helps make cities smarter and safer. Transportation is one of the largest segments that can benefit from actionable insights derived from data captured by sensors, where computer vision and deep learning have shown promise in achieving large-scale practical deployment. The 4th annual edition of the AI City Challenge has attracted 315 participating teams across 37 countries, who leveraged city-scale real traffic data and high-quality synthetic data to compete in four challenge tracks. Track 1 addressed video-based automatic vehicle counting, where the evaluation is conducted on both algorithmic effectiveness and computational efficiency. Track 2 addressed city-scale vehicle re-identification with augmented synthetic data to substantially increase the training set for the task. Track 3 addressed city-scale multi-target multi-camera vehicle tracking. Track 4 addressed traffic anomaly detection. The evaluation system shows two leader boards, in which a general leader board shows all submitted results, and a public leader board shows results limited to our contest participation rules, that teams are not allowed to use external data in their work. The public leader board shows results more close to real-world situations where annotated data are limited. Our results show promise that AI technology can enable smarter and safer transportation systems.</p></details> | <details><summary>Organ...</summary><p>Organization summary of the 4th AI City Challenge Workshop @ CVPR 2020</p></details> |
| **[The 5th AI City Challenge](https://arxiv.org/pdf/2104.12233v2)** | 2021-05-26 | [papers-cool](https://papers.cool/arxiv/2104.12233v2) | <details><summary>Show</summary><p>The AI City Challenge was created with two goals in mind: (1) pushing the boundaries of research and development in intelligent video analysis for smarter cities use cases, and (2) assessing tasks where the level of performance is enough to cause real-world adoption. Transportation is a segment ripe for such adoption. The fifth AI City Challenge attracted 305 participating teams across 38 countries, who leveraged city-scale real traffic data and high-quality synthetic data to compete in five challenge tracks. Track 1 addressed video-based automatic vehicle counting, where the evaluation being conducted on both algorithmic effectiveness and computational efficiency. Track 2 addressed city-scale vehicle re-identification with augmented synthetic data to substantially increase the training set for the task. Track 3 addressed city-scale multi-target multi-camera vehicle tracking. Track 4 addressed traffic anomaly detection. Track 5 was a new track addressing vehicle retrieval using natural language descriptions. The evaluation system shows a general leader board of all submitted results, and a public leader board of results limited to the contest participation rules, where teams are not allowed to use external data in their work. The public leader board shows results more close to real-world situations where annotated data is limited. Results show the promise of AI in Smarter Transportation. State-of-the-art performance for some tasks shows that these technologies are ready for adoption in real-world systems.</p></details> | <details><summary>Summa...</summary><p>Summary of the 5th AI City Challenge Workshop in conjunction with CVPR 2021</p></details> |
| **[Socioeconomic centers in cities worldwide](https://arxiv.org/pdf/2503.06445v1)** | 2025-03-11 | [papers-cool](https://papers.cool/arxiv/2503.06445v1) | <details><summary>Show</summary><p>Urban centers serve as engines of regional development, yet accurately defining and identifying the socioeconomic centers of cities globally remains a big challenge. Existing mapping efforts are often limited to large cities in developed regions and rely on data sources that are unavailable in many developing countries. This data scarcity hinders the establishment of consistent urban indicators, such as accessibility, to assess progress towards the United Nations Sustainable Development Goals (SDGs). Here, we develop and validate a global map of the socioeconomic centers of cities for 2020 by integrating nighttime light and population density data within an advanced geospatial modeling framework. Our analysis reveals that monocentric cities -- the standard urban model -- still dominate our planet, accounting for over 80% of cities worldwide. However, these monocentric cities encompass only approximately 20% of the total urbanized area, urban population, and nighttime light intensity; this 80/20 pattern underscores significant disparities in urban development. Further analysis, combined with socioeconomic datasets, reveals a marked difference between developed and developing regions: high-income countries exhibit greater polycentricity than low-income countries, demonstrating a positive correlation between urban sprawl and economic growth. Our global dataset and findings provide critical insights into urban structure and development, with important implications for urban planning, policymaking, and the formulation of indicators for urban sustainability assessment.</p></details> |  |
| **[Ghost Cities Analysis Based on Positioning Data in China](https://arxiv.org/pdf/1510.08505v2)** | 2015-11-29 | [papers-cool](https://papers.cool/arxiv/1510.08505v2) | <details><summary>Show</summary><p>Real estate projects are developed excessively in China in this decade. Many new housing districts are built, but they far exceed the actual demand in some cities. These cities with a high housing vacancy rate are called ghost cities. The real situation of vacant housing areas in China has not been studied in previous research. This study, using Baidu positioning data, presents the spatial distribution of the vacant housing areas in China and classifies cities with a large vacant housing area as cities or tourism sites. To the best of our knowledge, it is the first time that we detected and analyzed the ghost cities in China at such fine scale. To understand the human dynamic in ghost cities, we select one city and one tourism sites as cases to analyze the features of human dynamics. This study illustrates the capability of big data in sensing our cities objectively and comprehensively.</p></details> | <details><summary>added...</summary><p>added references for Case Study; corrected typos; revised argument in Introduction; added a sentence to explain the second-tier and third tier cities in Result; added two sentences to introduce the background of the study in Conclusion; added two people in the Acknowledgements; added a coauthor for his contribution in designing the algorithms of home-work detection and migration calculation</p></details> |
| **[The Contact and Mobility Networks of Mexico City](https://arxiv.org/pdf/2007.14596v3)** | 2022-08-24 | [papers-cool](https://papers.cool/arxiv/2007.14596v3) | <details><summary>Show</summary><p>Mexico City, the largest city in Mexico, is also one of the largest cities in the world. It has over 9 million inhabitants and concentrates the vast majority of government and business centers. In this work we describe algorithms that use anonymized location data from mobile devices to construct Mexico City's contact and mobility networks aiming to help the analysis of the city's complexity by understanding movement and physical interaction patterns between its inhabitants. We show the effectiveness and usefulness of our approach by building networks with data collected in February 2020 and performing a general descriptive analysis on them. We found that contact networks in Mexico City are very sparse, characterized by a largest connected component, and with a heavy-tailed degree distribution. On the other hand, we observed that paths conformed by the highest-degrree nodes of mobility networks resemble Mexico City's street network; moreover, we found interesting qualitative differences in the degree distribution of these networks between weekends and weekdays. We present these results along with the release of contact and mobility networks.</p></details> |  |
| **[Data Analytics for Smart cities: Challenges and Promises](https://arxiv.org/pdf/2109.05581v1)** | 2021-09-14 | [papers-cool](https://papers.cool/arxiv/2109.05581v1) | <details><summary>Show</summary><p>The explosion of advancements in artificial intelligence, sensor technologies, and wireless communication activates ubiquitous sensing through distributed sensors. These sensors are various domains of networks that lead us to smart systems in healthcare, transportation, environment, and other relevant branches/networks. Having collaborative interaction among the smart systems connects end-user devices to each other which enables achieving a new integrated entity called Smart Cities. The goal of this study is to provide a comprehensive survey of data analytics in smart cities. In this paper, we aim to focus on one of the smart cities important branches, namely Smart Mobility, and its positive ample impact on the smart cities decision-making process. Intelligent decision-making systems in smart mobility offer many advantages such as saving energy, relaying city traffic, and more importantly, reducing air pollution by offering real-time useful information and imperative knowledge. Making a decision in smart cities in time is challenging due to various and high dimensional factors and parameters, which are not frequently collected. In this paper, we first address current challenges in smart cities and provide an overview of potential solutions to these challenges. Then, we offer a framework of these solutions, called universal smart cities decision making, with three main sections of data capturing, data analysis, and decision making to optimize the smart mobility within smart cities. With this framework, we elaborate on fundamental concepts of big data, machine learning, and deep leaning algorithms that have been applied to smart cities and discuss the role of these algorithms in decision making for smart mobility in smart cities.</p></details> | 12 pages, 2 figures |
| **[Cities through the Prism of People's Spending Behavior](https://arxiv.org/pdf/1505.03854v1)** | 2016-04-27 | [papers-cool](https://papers.cool/arxiv/1505.03854v1) | <details><summary>Show</summary><p>Scientific studies of society increasingly rely on digital traces produced by various aspects of human activity. In this paper, we use a relatively unexplored source of data, anonymized records of bank card transactions collected in Spain by a big European bank, in order to propose a new classification scheme of cities based on the economic behavior of their residents. First, we study how individual spending behavior is qualitatively and quantitatively affected by various factors such as customer's age, gender, and size of a home city. We show that, similar to other socioeconomic urban quantities, individual spending activity exhibits a statistically significant superlinear scaling with city size. With respect to the general trends, we quantify the distinctive signature of each city in terms of residents' spending behavior, independently from the effects of scale and demographic heterogeneity. Based on the comparison of city signatures, we build a novel classification of cities across Spain in three categories. That classification is, with few exceptions, stable over different ways of city definition and connects with a meaningful socioeconomic interpretation. Furthermore, it appears to be related with the ability of cities to attract foreign visitors, which is a particularly remarkable finding given that the classification was based exclusively on the behavioral patterns of city residents. This highlights the far-reaching applicability of the presented classification approach and its ability to discover patterns that go beyond the quantities directly involved in it.</p></details> |  |
| **[City2City: Translating Place Representations across Cities](https://arxiv.org/pdf/1911.12143v1)** | 2019-11-28 | [papers-cool](https://papers.cool/arxiv/1911.12143v1) | <details><summary>Show</summary><p>Large mobility datasets collected from various sources have allowed us to observe, analyze, predict and solve a wide range of important urban challenges. In particular, studies have generated place representations (or embeddings) from mobility patterns in a similar manner to word embeddings to better understand the functionality of different places within a city. However, studies have been limited to generating such representations of cities in an individual manner and has lacked an inter-city perspective, which has made it difficult to transfer the insights gained from the place representations across different cities. In this study, we attempt to bridge this research gap by treating \textit{cities} and \textit{languages} analogously. We apply methods developed for unsupervised machine language translation tasks to translate place representations across different cities. Real world mobility data collected from mobile phone users in 2 cities in Japan are used to test our place representation translation methods. Translated place representations are validated using landuse data, and results show that our methods were able to accurately translate place representations from one city to another.</p></details> | <details><summary>A sho...</summary><p>A short 4-page version of this work was accepted in ACM SIGSPATIAL Conference 2019. This is the full version with details. In Proceedings of the 27th ACM SIGSPATIAL International Conference on Advances in Geographic Information Systems. ACM</p></details> |
| **[Blockchain for the Cybersecurity of Smart City Applications](https://arxiv.org/pdf/2206.02760v1)** | 2022-06-07 | [papers-cool](https://papers.cool/arxiv/2206.02760v1) | <details><summary>Show</summary><p>Cybersecurity is an inherent characteristic that should be addressed before the large deployment of smart city applications. Recently, Blockchain appears as a promising technology to provide several cybersecurity aspects of smart city applications. This paper provides a comprehensive review of the existing blockchain-based solutions for the cybersecurity of the main smart city applications, namely smart healthcare, smart transportation, smart agriculture, supply chain management, smart grid, and smart homes. We describe the existing solutions and we discuss their merits and limits. Moreover, we define the security requirements of each smart city application and we give a mapping of the studied solutions to these defined requirements. Additionally, future directions are given. We believe that the present survey is a good starting point for every researcher in the fields of cybersecurity, blockchain, and smart cities.</p></details> | <details><summary>65 pa...</summary><p>65 pages, 6 figures, 37 tables</p></details> |
| **[Musical Smart City: Perspectives on Ubiquitous Sonification](https://arxiv.org/pdf/2006.12305v1)** | 2020-06-23 | [papers-cool](https://papers.cool/arxiv/2006.12305v1) | <details><summary>Show</summary><p>Smart cities are urban areas with sensor networks that collect data used towards efficient management. As a source of ubiquitous data, smart city initiatives present opportunities to enhance inhabitants' urban awareness. However, making sense of smart city data is challenging and there is a gap between available data and end-user applications. Sonification emerges as a promising method for the interpretation of smart city data and the production of novel musical experiences. In this paper, we first present the smart city paradigm. We then cover the topics of ubiquitous and mobile music, followed by an overview of sonification research. Finally, we propose an approach entitled ubiquitous sonification and present the initial design of a speculative use case for musical smart city systems, leveraging user and urban data to inform behaviour.</p></details> |  |
| **[AutoEncoding Tree for City Generation and Applications](https://arxiv.org/pdf/2309.15941v1)** | 2023-09-29 | [papers-cool](https://papers.cool/arxiv/2309.15941v1) | <details><summary>Show</summary><p>City modeling and generation have attracted an increased interest in various applications, including gaming, urban planning, and autonomous driving. Unlike previous works focused on the generation of single objects or indoor scenes, the huge volumes of spatial data in cities pose a challenge to the generative models. Furthermore, few publicly available 3D real-world city datasets also hinder the development of methods for city generation. In this paper, we first collect over 3,000,000 geo-referenced objects for the city of New York, Zurich, Tokyo, Berlin, Boston and several other large cities. Based on this dataset, we propose AETree, a tree-structured auto-encoder neural network, for city generation. Specifically, we first propose a novel Spatial-Geometric Distance (SGD) metric to measure the similarity between building layouts and then construct a binary tree over the raw geometric data of building based on the SGD metric. Next, we present a tree-structured network whose encoder learns to extract and merge spatial information from bottom-up iteratively. The resulting global representation is reversely decoded for reconstruction or generation. To address the issue of long-dependency as the level of the tree increases, a Long Short-Term Memory (LSTM) Cell is employed as a basic network element of the proposed AETree. Moreover, we introduce a novel metric, Overlapping Area Ratio (OAR), to quantitatively evaluate the generation results. Experiments on the collected dataset demonstrate the effectiveness of the proposed model on 2D and 3D city generation. Furthermore, the latent features learned by AETree can serve downstream urban planning applications.</p></details> |  |
| **[Smart Cities and Digital Twins in Lower Austria](https://arxiv.org/pdf/2307.06743v1)** | 2023-07-14 | [papers-cool](https://papers.cool/arxiv/2307.06743v1) | <details><summary>Show</summary><p>Smart city solutions require innovative governance approaches together with the smart use of technology, such as digital twins, by city managers and policymakers to manage the big societal challenges. The project Smart Cities aNd Digital Twins in Lower Austria (SCiNDTiLA) extends the state of the art of research in several contributing disciplines and uses the foundations of complexity theory and computational social science methods to develop a digital-twin-based smart city model. The project will also apply a novel transdisciplinary process to conceptualise sustainable smart cities and validate the smart city generic model. The outcomes will be translated into a roadmap highlighting methodologies, guidelines and policy recommendations for tackling societal challenges in smart cities with a focus on rescaling the entire framework to be transferred to regions, smaller towns and non-urban environments, such as rural areas and smart villages, in ways that fit the respective local governance, ethical and operational capacity context.</p></details> | 2 pages |
| **[A physiology-inspired framework for holistic city simulations](https://arxiv.org/pdf/2108.00825v2)** | 2021-10-18 | [papers-cool](https://papers.cool/arxiv/2108.00825v2) | <details><summary>Show</summary><p>Life, services and activities within cities have commonly been studied by separate disciplines, each one independent from the others. One such approach is the computer simulation, which enables in-depth modelling and cost-effective evaluation of city phenomena. However, the adoption of integrated city simulations faces several barriers, such as managerial, social, and technical, despite its potential to support city planning and policymaking. This paper introduces the City Physiology: a new conceptual framework to facilitate the integration of city layers when designing holistic simulators. The physiology is introduced and applied through a process of three steps. Firstly, a literature review is offered in order to study the terminology and the progress already made towards integrated modelling of different urban systems. Secondly, interactions between urban systems are extracted from the approaches studied before. Finally, the pipeline to carry out the integration strategy is described. In addition to providing a conceptual tool for holistic simulations, the framework enables the discovery of new research lines generated by previously unseen connections between city layers. Being an open framework, available to all researchers to use and broaden, the authors of this paper envisage that it will be a valuable resource in establishing an exact science of cities.</p></details> | <details><summary>34 pa...</summary><p>34 pages (main content: 25 pages), 5 figures</p></details> |
| **[Smart City Development with Urban Transfer Learning](https://arxiv.org/pdf/1808.01552v2)** | 2022-05-31 | [papers-cool](https://papers.cool/arxiv/1808.01552v2) | <details><summary>Show</summary><p>Nowadays, the smart city development levels of different cities are still unbalanced. For a large number of cities which just started development, the governments will face a critical cold-start problem: 'how to develop a new smart city service with limited data?'. To address this problem, transfer learning can be leveraged to accelerate the smart city development, which we term the urban transfer learning paradigm. This article investigates the common process of urban transfer learning, aiming to provide city planners and relevant practitioners with guidelines on how to apply this novel learning paradigm. Our guidelines include common transfer strategies to take, general steps to follow, and case studies in public safety, transportation management, etc. We also summarize a few research opportunities and expect this article can attract more researchers to study urban transfer learning.</p></details> |  |
| **[Universities Scale Like Cities](https://arxiv.org/pdf/1211.5124v1)** | 2015-06-12 | [papers-cool](https://papers.cool/arxiv/1211.5124v1) | <details><summary>Show</summary><p>Recent studies of urban scaling show that important socioeconomic city characteristics such as wealth and innovation capacity exhibit a nonlinear, particularly a power law scaling with population size. These nonlinear effects are common to all cities, with similar power law exponents. These findings mean that the larger the city, the more disproportionally they are places of wealth and innovation. Local properties of cities cause a deviation from the expected behavior as predicted by the power law scaling. In this paper we demonstrate that universities show a similar behavior as cities in the distribution of the gross university income in terms of total number of citations over size in terms of total number of publications. Moreover, the power law exponents for university scaling are comparable to those for urban scaling. We find that deviations from the expected behavior can indeed be explained by specific local properties of universities, particularly the field-specific composition of a university, and its quality in terms of field-normalized citation impact. By studying both the set of the 500 largest universities worldwide and a specific subset of these 500 universities -- the top-100 European universities -- we are also able to distinguish between properties of universities with as well as without selection of one specific local property, the quality of a university in terms of its average field-normalized citation impact. It also reveals an interesting observation concerning the working of a crucial property in networked systems, preferential attachment.</p></details> | 16 pages, 17 figures |
| **[Detecting cities with high intermediacy in the African urban network](https://arxiv.org/pdf/2110.12142v1)** | 2021-10-26 | [papers-cool](https://papers.cool/arxiv/2110.12142v1) | <details><summary>Show</summary><p>Cities play different roles depending on their location within the transport network. Two cities of similar size might have distinct characteristics if one is located on a corridor between two capitals and the other is near a barrier, such as a mountain range. The level of intermediacy is a property of cities that characterises their position in the urban network. We measure the level of intermediacy of African cities by constructing the road infrastructure network obtained from OpenStreetMap. The infrastructure network allows defining city metrics such as degree and centrality. A proxy for the number of journeys that flow through each network edge is approximated using a mathematical model based on the level of attraction or gravity between all pairs of cities. Our model considers the extra time of crossing an international border as a parameter that enables us to proxy the cost of having fragmented regions with costly political barriers. Our results show that small cities have a wide range of intermediacy. We detect a phase transition where cities with less than one million inhabitants have a centrality that depends on the size and degree. For cities above one million inhabitants, centrality tends to be larger and depending primarily on city size rather than degree.</p></details> |  |
| **[Deep Visual City Recognition Visualization](https://arxiv.org/pdf/1905.01932v1)** | 2019-05-07 | [papers-cool](https://papers.cool/arxiv/1905.01932v1) | <details><summary>Show</summary><p>Understanding how cities visually differ from each others is interesting for planners, residents, and historians. We investigate the interpretation of deep features learned by convolutional neural networks (CNNs) for city recognition. Given a trained city recognition network, we first generate weighted masks using the known Grad-CAM technique and to select the most discriminate regions in the image. Since the image classification label is the city name, it contains no information of objects that are class-discriminate, we investigate the interpretability of deep representations with two methods. (i) Unsupervised method is used to cluster the objects appearing in the visual explanations. (ii) A pretrained semantic segmentation model is used to label objects in pixel level, and then we introduce statistical measures to quantitatively evaluate the interpretability of discriminate objects. The influence of network architectures and random initializations in training, is studied on the interpretability of CNN features for city recognition. The results suggest that network architectures would affect the interpretability of learned visual representations greater than different initializations.</p></details> | <details><summary>CVPR-...</summary><p>CVPR-19 workshop on Explainable AI</p></details> |
| **[Triangle-mapping Analysis on Spatial Competition and Cooperation of Chinese Cities](https://arxiv.org/pdf/1801.00641v1)** | 2018-01-03 | [papers-cool](https://papers.cool/arxiv/1801.00641v1) | <details><summary>Show</summary><p>In this paper, we empirically analyze the spatial distribution of Chinese cities using a method based on triangle transition. This method uses a regular triangle mapping from the observed cities and its three neighboring cities to analyze their distribution of mapping positions. We find that obvious center-gathering tendency for the relationship between cities and its nearest three cities, indicating the spatial competition between cities. Moreover, we observed the competitive trends between neighboring cities with similar economic volume, and the remarkable cooperative tendency between neighboring cities with large difference on economy. The threshold of the ratio of the two cities' economic volume on the transition from competition to cooperation is about 1.2. These findings are helpful in the understanding of the cities economic relationship, especially in the study of competition and cooperation between cities.</p></details> | <details><summary>The 4...</summary><p>The 43rd Annual Conference of the IEEE Industrial Electronics Society</p></details> |
| **[Crowdsensing and privacy in smart city applications](https://arxiv.org/pdf/1806.07534v1)** | 2018-06-21 | [papers-cool](https://papers.cool/arxiv/1806.07534v1) | <details><summary>Show</summary><p>Smartness in smart cities is achieved by sensing phenomena of interest and using them to make smart decisions. Since the decision makers may not own all the necessary sensing infrastructures, crowdsourced sensing, can help collect important information of the city in near real-time. However, involving people brings of the risk of exposing their private information.This chapter explores crowdsensing in smart city applications and its privacy implications.</p></details> | <details><summary>Prepr...</summary><p>Preprint submitted to Book: Smart Cities, Cybersecurity and Privacy, Elsevier</p></details> |

